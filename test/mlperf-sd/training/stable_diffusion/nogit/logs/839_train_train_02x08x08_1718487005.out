pyxis: imported docker image: cr.ai.nebius.cloud#examples/stable_diffusion_h100
pyxis: imported docker image: cr.ai.nebius.cloud#examples/stable_diffusion_h100
STARTING TIMING RUN AT 2024-06-15 09:40:13 PM
STARTING TIMING RUN AT 2024-06-15 09:40:13 PM
STARTING TIMING RUN AT 2024-06-15 09:40:13 PM
STARTING TIMING RUN AT 2024-06-15 09:40:13 PM
STARTING TIMING RUN AT 2024-06-15 09:40:13 PM
STARTING TIMING RUN AT 2024-06-15 09:40:13 PM
STARTING TIMING RUN AT 2024-06-15 09:40:13 PM
STARTING TIMING RUN AT 2024-06-15 09:40:14 PM
STARTING TIMING RUN AT 2024-06-15 09:40:16 PM
STARTING TIMING RUN AT 2024-06-15 09:40:16 PM
STARTING TIMING RUN AT 2024-06-15 09:40:16 PM
STARTING TIMING RUN AT 2024-06-15 09:40:16 PM
STARTING TIMING RUN AT 2024-06-15 09:40:16 PM
STARTING TIMING RUN AT 2024-06-15 09:40:16 PM
STARTING TIMING RUN AT 2024-06-15 09:40:16 PM
STARTING TIMING RUN AT 2024-06-15 09:40:16 PM
:::MLLOG {"namespace": "", "time_ms": 1718487620051, "event_type": "POINT_IN_TIME", "key": "cache_clear", "value": true, "metadata": {"file": "<string>", "lineno": 4}}
:::MLLOG {"namespace": "", "time_ms": 1718487620054, "event_type": "POINT_IN_TIME", "key": "cache_clear", "value": true, "metadata": {"file": "<string>", "lineno": 4}}
:::MLLOG {"namespace": "", "time_ms": 1718487620294, "event_type": "POINT_IN_TIME", "key": "cache_clear", "value": true, "metadata": {"file": "<string>", "lineno": 4}}
:::MLLOG {"namespace": "", "time_ms": 1718487620352, "event_type": "POINT_IN_TIME", "key": "cache_clear", "value": true, "metadata": {"file": "<string>", "lineno": 4}}
:::MLLOG {"namespace": "", "time_ms": 1718487620455, "event_type": "POINT_IN_TIME", "key": "cache_clear", "value": true, "metadata": {"file": "<string>", "lineno": 4}}
:::MLLOG {"namespace": "", "time_ms": 1718487622645, "event_type": "POINT_IN_TIME", "key": "cache_clear", "value": true, "metadata": {"file": "<string>", "lineno": 4}}
:::MLLOG {"namespace": "", "time_ms": 1718487622900, "event_type": "POINT_IN_TIME", "key": "cache_clear", "value": true, "metadata": {"file": "<string>", "lineno": 4}}
:::MLLOG {"namespace": "", "time_ms": 1718487623191, "event_type": "POINT_IN_TIME", "key": "cache_clear", "value": true, "metadata": {"file": "<string>", "lineno": 4}}
:::MLLOG {"namespace": "", "time_ms": 1718487623612, "event_type": "POINT_IN_TIME", "key": "cache_clear", "value": true, "metadata": {"file": "<string>", "lineno": 4}}
:::MLLOG {"namespace": "", "time_ms": 1718487623898, "event_type": "POINT_IN_TIME", "key": "cache_clear", "value": true, "metadata": {"file": "<string>", "lineno": 4}}
:::MLLOG {"namespace": "", "time_ms": 1718487624011, "event_type": "POINT_IN_TIME", "key": "cache_clear", "value": true, "metadata": {"file": "<string>", "lineno": 4}}
:::MLLOG {"namespace": "", "time_ms": 1718487625454, "event_type": "POINT_IN_TIME", "key": "cache_clear", "value": true, "metadata": {"file": "<string>", "lineno": 4}}
:::MLLOG {"namespace": "", "time_ms": 1718487625625, "event_type": "POINT_IN_TIME", "key": "cache_clear", "value": true, "metadata": {"file": "<string>", "lineno": 4}}
:::MLLOG {"namespace": "", "time_ms": 1718487625874, "event_type": "POINT_IN_TIME", "key": "cache_clear", "value": true, "metadata": {"file": "<string>", "lineno": 4}}
:::MLLOG {"namespace": "", "time_ms": 1718487627121, "event_type": "POINT_IN_TIME", "key": "submission_benchmark", "value": "stable_diffusion", "metadata": {"file": "mlperf_logging_utils.py", "lineno": 72}}
:::MLLOG {"namespace": "", "time_ms": 1718487627148, "event_type": "POINT_IN_TIME", "key": "submission_division", "value": "closed", "metadata": {"file": "mlperf_logging_utils.py", "lineno": 73}}
:::MLLOG {"namespace": "", "time_ms": 1718487627149, "event_type": "POINT_IN_TIME", "key": "submission_org", "value": "reference_implementation", "metadata": {"file": "mlperf_logging_utils.py", "lineno": 74}}
:::MLLOG {"namespace": "", "time_ms": 1718487627151, "event_type": "POINT_IN_TIME", "key": "submission_platform", "value": "DGX-A100", "metadata": {"file": "mlperf_logging_utils.py", "lineno": 75}}
:::MLLOG {"namespace": "", "time_ms": 1718487627152, "event_type": "POINT_IN_TIME", "key": "submission_poc_name", "value": "Ahmad Kiswani", "metadata": {"file": "mlperf_logging_utils.py", "lineno": 76}}
:::MLLOG {"namespace": "", "time_ms": 1718487627154, "event_type": "POINT_IN_TIME", "key": "submission_poc_email", "value": "akiswani@nvidia.com", "metadata": {"file": "mlperf_logging_utils.py", "lineno": 77}}
:::MLLOG {"namespace": "", "time_ms": 1718487627155, "event_type": "POINT_IN_TIME", "key": "submission_status", "value": "onprem", "metadata": {"file": "mlperf_logging_utils.py", "lineno": 78}}
:::MLLOG {"namespace": "", "time_ms": 1718487627156, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "main.py", "lineno": 383}}
:::MLLOG {"namespace": "", "time_ms": 1718487627136, "event_type": "POINT_IN_TIME", "key": "submission_benchmark", "value": "stable_diffusion", "metadata": {"file": "mlperf_logging_utils.py", "lineno": 72}}
:::MLLOG {"namespace": "", "time_ms": 1718487627160, "event_type": "POINT_IN_TIME", "key": "seed", "value": 2666444545, "metadata": {"file": "main.py", "lineno": 450}}
:::MLLOG {"namespace": "", "time_ms": 1718487627159, "event_type": "POINT_IN_TIME", "key": "submission_division", "value": "closed", "metadata": {"file": "mlperf_logging_utils.py", "lineno": 73}}
[rank: 12] Global seed set to 2666444545
:::MLLOG {"namespace": "", "time_ms": 1718487627162, "event_type": "POINT_IN_TIME", "key": "submission_org", "value": "reference_implementation", "metadata": {"file": "mlperf_logging_utils.py", "lineno": 74}}
:::MLLOG {"namespace": "", "time_ms": 1718487627163, "event_type": "POINT_IN_TIME", "key": "submission_platform", "value": "DGX-A100", "metadata": {"file": "mlperf_logging_utils.py", "lineno": 75}}
:::MLLOG {"namespace": "", "time_ms": 1718487627164, "event_type": "POINT_IN_TIME", "key": "submission_poc_name", "value": "Ahmad Kiswani", "metadata": {"file": "mlperf_logging_utils.py", "lineno": 76}}
:::MLLOG {"namespace": "", "time_ms": 1718487627165, "event_type": "POINT_IN_TIME", "key": "submission_poc_email", "value": "akiswani@nvidia.com", "metadata": {"file": "mlperf_logging_utils.py", "lineno": 77}}
:::MLLOG {"namespace": "", "time_ms": 1718487627167, "event_type": "POINT_IN_TIME", "key": "submission_status", "value": "onprem", "metadata": {"file": "mlperf_logging_utils.py", "lineno": 78}}
:::MLLOG {"namespace": "", "time_ms": 1718487627168, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "main.py", "lineno": 383}}
:::MLLOG {"namespace": "", "time_ms": 1718487627172, "event_type": "POINT_IN_TIME", "key": "seed", "value": 912576944, "metadata": {"file": "main.py", "lineno": 450}}
[rank: 10] Global seed set to 912576944
:::MLLOG {"namespace": "", "time_ms": 1718487627385, "event_type": "POINT_IN_TIME", "key": "submission_benchmark", "value": "stable_diffusion", "metadata": {"file": "mlperf_logging_utils.py", "lineno": 72}}
:::MLLOG {"namespace": "", "time_ms": 1718487627407, "event_type": "POINT_IN_TIME", "key": "submission_division", "value": "closed", "metadata": {"file": "mlperf_logging_utils.py", "lineno": 73}}
:::MLLOG {"namespace": "", "time_ms": 1718487627411, "event_type": "POINT_IN_TIME", "key": "submission_org", "value": "reference_implementation", "metadata": {"file": "mlperf_logging_utils.py", "lineno": 74}}
:::MLLOG {"namespace": "", "time_ms": 1718487627412, "event_type": "POINT_IN_TIME", "key": "submission_platform", "value": "DGX-A100", "metadata": {"file": "mlperf_logging_utils.py", "lineno": 75}}
:::MLLOG {"namespace": "", "time_ms": 1718487627413, "event_type": "POINT_IN_TIME", "key": "submission_poc_name", "value": "Ahmad Kiswani", "metadata": {"file": "mlperf_logging_utils.py", "lineno": 76}}
:::MLLOG {"namespace": "", "time_ms": 1718487627414, "event_type": "POINT_IN_TIME", "key": "submission_poc_email", "value": "akiswani@nvidia.com", "metadata": {"file": "mlperf_logging_utils.py", "lineno": 77}}
:::MLLOG {"namespace": "", "time_ms": 1718487627415, "event_type": "POINT_IN_TIME", "key": "submission_status", "value": "onprem", "metadata": {"file": "mlperf_logging_utils.py", "lineno": 78}}
:::MLLOG {"namespace": "", "time_ms": 1718487627416, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "main.py", "lineno": 383}}
:::MLLOG {"namespace": "", "time_ms": 1718487627419, "event_type": "POINT_IN_TIME", "key": "seed", "value": 2529196808, "metadata": {"file": "main.py", "lineno": 450}}
[rank: 8] Global seed set to 2529196808
:::MLLOG {"namespace": "", "time_ms": 1718487627772, "event_type": "POINT_IN_TIME", "key": "submission_benchmark", "value": "stable_diffusion", "metadata": {"file": "mlperf_logging_utils.py", "lineno": 72}}
:::MLLOG {"namespace": "", "time_ms": 1718487627798, "event_type": "POINT_IN_TIME", "key": "submission_division", "value": "closed", "metadata": {"file": "mlperf_logging_utils.py", "lineno": 73}}
:::MLLOG {"namespace": "", "time_ms": 1718487627800, "event_type": "POINT_IN_TIME", "key": "submission_org", "value": "reference_implementation", "metadata": {"file": "mlperf_logging_utils.py", "lineno": 74}}
:::MLLOG {"namespace": "", "time_ms": 1718487627803, "event_type": "POINT_IN_TIME", "key": "submission_platform", "value": "DGX-A100", "metadata": {"file": "mlperf_logging_utils.py", "lineno": 75}}
:::MLLOG {"namespace": "", "time_ms": 1718487627805, "event_type": "POINT_IN_TIME", "key": "submission_poc_name", "value": "Ahmad Kiswani", "metadata": {"file": "mlperf_logging_utils.py", "lineno": 76}}
:::MLLOG {"namespace": "", "time_ms": 1718487627806, "event_type": "POINT_IN_TIME", "key": "submission_poc_email", "value": "akiswani@nvidia.com", "metadata": {"file": "mlperf_logging_utils.py", "lineno": 77}}
:::MLLOG {"namespace": "", "time_ms": 1718487627814, "event_type": "POINT_IN_TIME", "key": "submission_status", "value": "onprem", "metadata": {"file": "mlperf_logging_utils.py", "lineno": 78}}
:::MLLOG {"namespace": "", "time_ms": 1718487627816, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "main.py", "lineno": 383}}
:::MLLOG {"namespace": "", "time_ms": 1718487627821, "event_type": "POINT_IN_TIME", "key": "seed", "value": 1664490200, "metadata": {"file": "main.py", "lineno": 450}}
[rank: 14] Global seed set to 1664490200
:::MLLOG {"namespace": "", "time_ms": 1718487627875, "event_type": "POINT_IN_TIME", "key": "submission_benchmark", "value": "stable_diffusion", "metadata": {"file": "mlperf_logging_utils.py", "lineno": 72}}
:::MLLOG {"namespace": "", "time_ms": 1718487627897, "event_type": "POINT_IN_TIME", "key": "submission_division", "value": "closed", "metadata": {"file": "mlperf_logging_utils.py", "lineno": 73}}
:::MLLOG {"namespace": "", "time_ms": 1718487627899, "event_type": "POINT_IN_TIME", "key": "submission_org", "value": "reference_implementation", "metadata": {"file": "mlperf_logging_utils.py", "lineno": 74}}
:::MLLOG {"namespace": "", "time_ms": 1718487627900, "event_type": "POINT_IN_TIME", "key": "submission_platform", "value": "DGX-A100", "metadata": {"file": "mlperf_logging_utils.py", "lineno": 75}}
:::MLLOG {"namespace": "", "time_ms": 1718487627901, "event_type": "POINT_IN_TIME", "key": "submission_poc_name", "value": "Ahmad Kiswani", "metadata": {"file": "mlperf_logging_utils.py", "lineno": 76}}
:::MLLOG {"namespace": "", "time_ms": 1718487627902, "event_type": "POINT_IN_TIME", "key": "submission_poc_email", "value": "akiswani@nvidia.com", "metadata": {"file": "mlperf_logging_utils.py", "lineno": 77}}
:::MLLOG {"namespace": "", "time_ms": 1718487627908, "event_type": "POINT_IN_TIME", "key": "submission_status", "value": "onprem", "metadata": {"file": "mlperf_logging_utils.py", "lineno": 78}}
:::MLLOG {"namespace": "", "time_ms": 1718487627909, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "main.py", "lineno": 383}}
:::MLLOG {"namespace": "", "time_ms": 1718487627912, "event_type": "POINT_IN_TIME", "key": "seed", "value": 1439472685, "metadata": {"file": "main.py", "lineno": 450}}
[rank: 15] Global seed set to 1439472685
:::MLLOG {"namespace": "", "time_ms": 1718487628255, "event_type": "POINT_IN_TIME", "key": "cache_clear", "value": true, "metadata": {"file": "<string>", "lineno": 4}}
:::MLLOG {"namespace": "", "time_ms": 1718487628349, "event_type": "POINT_IN_TIME", "key": "cache_clear", "value": true, "metadata": {"file": "<string>", "lineno": 4}}
:::MLLOG {"namespace": "", "time_ms": 1718487629546, "event_type": "POINT_IN_TIME", "key": "submission_benchmark", "value": "stable_diffusion", "metadata": {"file": "mlperf_logging_utils.py", "lineno": 72}}
:::MLLOG {"namespace": "", "time_ms": 1718487629569, "event_type": "POINT_IN_TIME", "key": "submission_division", "value": "closed", "metadata": {"file": "mlperf_logging_utils.py", "lineno": 73}}
:::MLLOG {"namespace": "", "time_ms": 1718487629572, "event_type": "POINT_IN_TIME", "key": "submission_org", "value": "reference_implementation", "metadata": {"file": "mlperf_logging_utils.py", "lineno": 74}}
:::MLLOG {"namespace": "", "time_ms": 1718487629573, "event_type": "POINT_IN_TIME", "key": "submission_platform", "value": "DGX-A100", "metadata": {"file": "mlperf_logging_utils.py", "lineno": 75}}
:::MLLOG {"namespace": "", "time_ms": 1718487629574, "event_type": "POINT_IN_TIME", "key": "submission_poc_name", "value": "Ahmad Kiswani", "metadata": {"file": "mlperf_logging_utils.py", "lineno": 76}}
:::MLLOG {"namespace": "", "time_ms": 1718487629575, "event_type": "POINT_IN_TIME", "key": "submission_poc_email", "value": "akiswani@nvidia.com", "metadata": {"file": "mlperf_logging_utils.py", "lineno": 77}}
:::MLLOG {"namespace": "", "time_ms": 1718487629579, "event_type": "POINT_IN_TIME", "key": "submission_status", "value": "onprem", "metadata": {"file": "mlperf_logging_utils.py", "lineno": 78}}
:::MLLOG {"namespace": "", "time_ms": 1718487629580, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "main.py", "lineno": 383}}
:::MLLOG {"namespace": "", "time_ms": 1718487629584, "event_type": "POINT_IN_TIME", "key": "seed", "value": 286234108, "metadata": {"file": "main.py", "lineno": 450}}
[rank: 7] Global seed set to 286234108
:::MLLOG {"namespace": "", "time_ms": 1718487630198, "event_type": "POINT_IN_TIME", "key": "submission_benchmark", "value": "stable_diffusion", "metadata": {"file": "mlperf_logging_utils.py", "lineno": 72}}
:::MLLOG {"namespace": "", "time_ms": 1718487630221, "event_type": "POINT_IN_TIME", "key": "submission_division", "value": "closed", "metadata": {"file": "mlperf_logging_utils.py", "lineno": 73}}
:::MLLOG {"namespace": "", "time_ms": 1718487630224, "event_type": "POINT_IN_TIME", "key": "submission_org", "value": "reference_implementation", "metadata": {"file": "mlperf_logging_utils.py", "lineno": 74}}
:::MLLOG {"namespace": "", "time_ms": 1718487630225, "event_type": "POINT_IN_TIME", "key": "submission_platform", "value": "DGX-A100", "metadata": {"file": "mlperf_logging_utils.py", "lineno": 75}}
:::MLLOG {"namespace": "", "time_ms": 1718487630227, "event_type": "POINT_IN_TIME", "key": "submission_poc_name", "value": "Ahmad Kiswani", "metadata": {"file": "mlperf_logging_utils.py", "lineno": 76}}
:::MLLOG {"namespace": "", "time_ms": 1718487630227, "event_type": "POINT_IN_TIME", "key": "submission_poc_email", "value": "akiswani@nvidia.com", "metadata": {"file": "mlperf_logging_utils.py", "lineno": 77}}
:::MLLOG {"namespace": "", "time_ms": 1718487630228, "event_type": "POINT_IN_TIME", "key": "submission_status", "value": "onprem", "metadata": {"file": "mlperf_logging_utils.py", "lineno": 78}}
:::MLLOG {"namespace": "", "time_ms": 1718487630229, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "main.py", "lineno": 383}}
Using base config ['./configs/train_02x08x08.yaml']
:::MLLOG {"namespace": "", "time_ms": 1718487630233, "event_type": "POINT_IN_TIME", "key": "seed", "value": 3234298782, "metadata": {"file": "main.py", "lineno": 450}}
[rank: 0] Global seed set to 3234298782
Using ckpt_path = /checkpoints/sd/512-base-ema.ckpt
:::MLLOG {"namespace": "", "time_ms": 1718487630544, "event_type": "POINT_IN_TIME", "key": "submission_benchmark", "value": "stable_diffusion", "metadata": {"file": "mlperf_logging_utils.py", "lineno": 72}}
:::MLLOG {"namespace": "", "time_ms": 1718487630570, "event_type": "POINT_IN_TIME", "key": "submission_division", "value": "closed", "metadata": {"file": "mlperf_logging_utils.py", "lineno": 73}}
:::MLLOG {"namespace": "", "time_ms": 1718487630572, "event_type": "POINT_IN_TIME", "key": "submission_org", "value": "reference_implementation", "metadata": {"file": "mlperf_logging_utils.py", "lineno": 74}}
:::MLLOG {"namespace": "", "time_ms": 1718487630574, "event_type": "POINT_IN_TIME", "key": "submission_platform", "value": "DGX-A100", "metadata": {"file": "mlperf_logging_utils.py", "lineno": 75}}
:::MLLOG {"namespace": "", "time_ms": 1718487630575, "event_type": "POINT_IN_TIME", "key": "submission_poc_name", "value": "Ahmad Kiswani", "metadata": {"file": "mlperf_logging_utils.py", "lineno": 76}}
:::MLLOG {"namespace": "", "time_ms": 1718487630576, "event_type": "POINT_IN_TIME", "key": "submission_poc_email", "value": "akiswani@nvidia.com", "metadata": {"file": "mlperf_logging_utils.py", "lineno": 77}}
:::MLLOG {"namespace": "", "time_ms": 1718487630578, "event_type": "POINT_IN_TIME", "key": "submission_status", "value": "onprem", "metadata": {"file": "mlperf_logging_utils.py", "lineno": 78}}
:::MLLOG {"namespace": "", "time_ms": 1718487630580, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "main.py", "lineno": 383}}
:::MLLOG {"namespace": "", "time_ms": 1718487630585, "event_type": "POINT_IN_TIME", "key": "seed", "value": 3425774915, "metadata": {"file": "main.py", "lineno": 450}}
[rank: 3] Global seed set to 3425774915
:::MLLOG {"namespace": "", "time_ms": 1718487630843, "event_type": "POINT_IN_TIME", "key": "submission_benchmark", "value": "stable_diffusion", "metadata": {"file": "mlperf_logging_utils.py", "lineno": 72}}
:::MLLOG {"namespace": "", "time_ms": 1718487630888, "event_type": "POINT_IN_TIME", "key": "submission_division", "value": "closed", "metadata": {"file": "mlperf_logging_utils.py", "lineno": 73}}
:::MLLOG {"namespace": "", "time_ms": 1718487630894, "event_type": "POINT_IN_TIME", "key": "submission_org", "value": "reference_implementation", "metadata": {"file": "mlperf_logging_utils.py", "lineno": 74}}
:::MLLOG {"namespace": "", "time_ms": 1718487630896, "event_type": "POINT_IN_TIME", "key": "submission_platform", "value": "DGX-A100", "metadata": {"file": "mlperf_logging_utils.py", "lineno": 75}}
:::MLLOG {"namespace": "", "time_ms": 1718487630897, "event_type": "POINT_IN_TIME", "key": "submission_poc_name", "value": "Ahmad Kiswani", "metadata": {"file": "mlperf_logging_utils.py", "lineno": 76}}
:::MLLOG {"namespace": "", "time_ms": 1718487630900, "event_type": "POINT_IN_TIME", "key": "submission_poc_email", "value": "akiswani@nvidia.com", "metadata": {"file": "mlperf_logging_utils.py", "lineno": 77}}
:::MLLOG {"namespace": "", "time_ms": 1718487630901, "event_type": "POINT_IN_TIME", "key": "submission_status", "value": "onprem", "metadata": {"file": "mlperf_logging_utils.py", "lineno": 78}}
:::MLLOG {"namespace": "", "time_ms": 1718487630903, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "main.py", "lineno": 383}}
:::MLLOG {"namespace": "", "time_ms": 1718487630907, "event_type": "POINT_IN_TIME", "key": "seed", "value": 784250613, "metadata": {"file": "main.py", "lineno": 450}}
[rank: 2] Global seed set to 784250613
LatentDiffusion: Running in v-prediction mode
:::MLLOG {"namespace": "", "time_ms": 1718487631506, "event_type": "POINT_IN_TIME", "key": "submission_benchmark", "value": "stable_diffusion", "metadata": {"file": "mlperf_logging_utils.py", "lineno": 72}}
:::MLLOG {"namespace": "", "time_ms": 1718487631526, "event_type": "POINT_IN_TIME", "key": "submission_division", "value": "closed", "metadata": {"file": "mlperf_logging_utils.py", "lineno": 73}}
:::MLLOG {"namespace": "", "time_ms": 1718487631527, "event_type": "POINT_IN_TIME", "key": "submission_org", "value": "reference_implementation", "metadata": {"file": "mlperf_logging_utils.py", "lineno": 74}}
:::MLLOG {"namespace": "", "time_ms": 1718487631528, "event_type": "POINT_IN_TIME", "key": "submission_platform", "value": "DGX-A100", "metadata": {"file": "mlperf_logging_utils.py", "lineno": 75}}
:::MLLOG {"namespace": "", "time_ms": 1718487631529, "event_type": "POINT_IN_TIME", "key": "submission_poc_name", "value": "Ahmad Kiswani", "metadata": {"file": "mlperf_logging_utils.py", "lineno": 76}}
:::MLLOG {"namespace": "", "time_ms": 1718487631530, "event_type": "POINT_IN_TIME", "key": "submission_poc_email", "value": "akiswani@nvidia.com", "metadata": {"file": "mlperf_logging_utils.py", "lineno": 77}}
:::MLLOG {"namespace": "", "time_ms": 1718487631531, "event_type": "POINT_IN_TIME", "key": "submission_status", "value": "onprem", "metadata": {"file": "mlperf_logging_utils.py", "lineno": 78}}
:::MLLOG {"namespace": "", "time_ms": 1718487631533, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "main.py", "lineno": 383}}
:::MLLOG {"namespace": "", "time_ms": 1718487631516, "event_type": "POINT_IN_TIME", "key": "submission_benchmark", "value": "stable_diffusion", "metadata": {"file": "mlperf_logging_utils.py", "lineno": 72}}
:::MLLOG {"namespace": "", "time_ms": 1718487631535, "event_type": "POINT_IN_TIME", "key": "submission_division", "value": "closed", "metadata": {"file": "mlperf_logging_utils.py", "lineno": 73}}
:::MLLOG {"namespace": "", "time_ms": 1718487631536, "event_type": "POINT_IN_TIME", "key": "seed", "value": 1384795041, "metadata": {"file": "main.py", "lineno": 450}}
:::MLLOG {"namespace": "", "time_ms": 1718487631537, "event_type": "POINT_IN_TIME", "key": "submission_org", "value": "reference_implementation", "metadata": {"file": "mlperf_logging_utils.py", "lineno": 74}}
[rank: 4] Global seed set to 1384795041
:::MLLOG {"namespace": "", "time_ms": 1718487631539, "event_type": "POINT_IN_TIME", "key": "submission_platform", "value": "DGX-A100", "metadata": {"file": "mlperf_logging_utils.py", "lineno": 75}}
:::MLLOG {"namespace": "", "time_ms": 1718487631540, "event_type": "POINT_IN_TIME", "key": "submission_poc_name", "value": "Ahmad Kiswani", "metadata": {"file": "mlperf_logging_utils.py", "lineno": 76}}
:::MLLOG {"namespace": "", "time_ms": 1718487631541, "event_type": "POINT_IN_TIME", "key": "submission_poc_email", "value": "akiswani@nvidia.com", "metadata": {"file": "mlperf_logging_utils.py", "lineno": 77}}
:::MLLOG {"namespace": "", "time_ms": 1718487631542, "event_type": "POINT_IN_TIME", "key": "submission_status", "value": "onprem", "metadata": {"file": "mlperf_logging_utils.py", "lineno": 78}}
:::MLLOG {"namespace": "", "time_ms": 1718487631548, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "main.py", "lineno": 383}}
:::MLLOG {"namespace": "", "time_ms": 1718487631553, "event_type": "POINT_IN_TIME", "key": "seed", "value": 2431098013, "metadata": {"file": "main.py", "lineno": 450}}
[rank: 5] Global seed set to 2431098013
:::MLLOG {"namespace": "", "time_ms": 1718487638570, "event_type": "POINT_IN_TIME", "key": "submission_benchmark", "value": "stable_diffusion", "metadata": {"file": "mlperf_logging_utils.py", "lineno": 72}}
:::MLLOG {"namespace": "", "time_ms": 1718487638613, "event_type": "POINT_IN_TIME", "key": "submission_division", "value": "closed", "metadata": {"file": "mlperf_logging_utils.py", "lineno": 73}}
:::MLLOG {"namespace": "", "time_ms": 1718487638615, "event_type": "POINT_IN_TIME", "key": "submission_org", "value": "reference_implementation", "metadata": {"file": "mlperf_logging_utils.py", "lineno": 74}}
:::MLLOG {"namespace": "", "time_ms": 1718487638616, "event_type": "POINT_IN_TIME", "key": "submission_platform", "value": "DGX-A100", "metadata": {"file": "mlperf_logging_utils.py", "lineno": 75}}
:::MLLOG {"namespace": "", "time_ms": 1718487638617, "event_type": "POINT_IN_TIME", "key": "submission_poc_name", "value": "Ahmad Kiswani", "metadata": {"file": "mlperf_logging_utils.py", "lineno": 76}}
:::MLLOG {"namespace": "", "time_ms": 1718487638618, "event_type": "POINT_IN_TIME", "key": "submission_poc_email", "value": "akiswani@nvidia.com", "metadata": {"file": "mlperf_logging_utils.py", "lineno": 77}}
:::MLLOG {"namespace": "", "time_ms": 1718487638619, "event_type": "POINT_IN_TIME", "key": "submission_status", "value": "onprem", "metadata": {"file": "mlperf_logging_utils.py", "lineno": 78}}
:::MLLOG {"namespace": "", "time_ms": 1718487638620, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "main.py", "lineno": 383}}
:::MLLOG {"namespace": "", "time_ms": 1718487638624, "event_type": "POINT_IN_TIME", "key": "seed", "value": 2078658137, "metadata": {"file": "main.py", "lineno": 450}}
[rank: 9] Global seed set to 2078658137
:::MLLOG {"namespace": "", "time_ms": 1718487638745, "event_type": "POINT_IN_TIME", "key": "submission_benchmark", "value": "stable_diffusion", "metadata": {"file": "mlperf_logging_utils.py", "lineno": 72}}
:::MLLOG {"namespace": "", "time_ms": 1718487638786, "event_type": "POINT_IN_TIME", "key": "submission_division", "value": "closed", "metadata": {"file": "mlperf_logging_utils.py", "lineno": 73}}
:::MLLOG {"namespace": "", "time_ms": 1718487638789, "event_type": "POINT_IN_TIME", "key": "submission_org", "value": "reference_implementation", "metadata": {"file": "mlperf_logging_utils.py", "lineno": 74}}
:::MLLOG {"namespace": "", "time_ms": 1718487638790, "event_type": "POINT_IN_TIME", "key": "submission_platform", "value": "DGX-A100", "metadata": {"file": "mlperf_logging_utils.py", "lineno": 75}}
:::MLLOG {"namespace": "", "time_ms": 1718487638791, "event_type": "POINT_IN_TIME", "key": "submission_poc_name", "value": "Ahmad Kiswani", "metadata": {"file": "mlperf_logging_utils.py", "lineno": 76}}
:::MLLOG {"namespace": "", "time_ms": 1718487638792, "event_type": "POINT_IN_TIME", "key": "submission_poc_email", "value": "akiswani@nvidia.com", "metadata": {"file": "mlperf_logging_utils.py", "lineno": 77}}
:::MLLOG {"namespace": "", "time_ms": 1718487638793, "event_type": "POINT_IN_TIME", "key": "submission_status", "value": "onprem", "metadata": {"file": "mlperf_logging_utils.py", "lineno": 78}}
:::MLLOG {"namespace": "", "time_ms": 1718487638795, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "main.py", "lineno": 383}}
:::MLLOG {"namespace": "", "time_ms": 1718487638799, "event_type": "POINT_IN_TIME", "key": "seed", "value": 1290533972, "metadata": {"file": "main.py", "lineno": 450}}
[rank: 11] Global seed set to 1290533972
building MemoryEfficientAttnBlock with 512 in_channels...
Working with z of shape (1, 4, 32, 32) = 4096 dimensions.
building MemoryEfficientAttnBlock with 512 in_channels...
:::MLLOG {"namespace": "", "time_ms": 1718487639609, "event_type": "POINT_IN_TIME", "key": "submission_benchmark", "value": "stable_diffusion", "metadata": {"file": "mlperf_logging_utils.py", "lineno": 72}}
:::MLLOG {"namespace": "", "time_ms": 1718487639642, "event_type": "POINT_IN_TIME", "key": "submission_division", "value": "closed", "metadata": {"file": "mlperf_logging_utils.py", "lineno": 73}}
:::MLLOG {"namespace": "", "time_ms": 1718487639645, "event_type": "POINT_IN_TIME", "key": "submission_org", "value": "reference_implementation", "metadata": {"file": "mlperf_logging_utils.py", "lineno": 74}}
:::MLLOG {"namespace": "", "time_ms": 1718487639646, "event_type": "POINT_IN_TIME", "key": "submission_platform", "value": "DGX-A100", "metadata": {"file": "mlperf_logging_utils.py", "lineno": 75}}
:::MLLOG {"namespace": "", "time_ms": 1718487639647, "event_type": "POINT_IN_TIME", "key": "submission_poc_name", "value": "Ahmad Kiswani", "metadata": {"file": "mlperf_logging_utils.py", "lineno": 76}}
:::MLLOG {"namespace": "", "time_ms": 1718487639648, "event_type": "POINT_IN_TIME", "key": "submission_poc_email", "value": "akiswani@nvidia.com", "metadata": {"file": "mlperf_logging_utils.py", "lineno": 77}}
:::MLLOG {"namespace": "", "time_ms": 1718487639649, "event_type": "POINT_IN_TIME", "key": "submission_status", "value": "onprem", "metadata": {"file": "mlperf_logging_utils.py", "lineno": 78}}
:::MLLOG {"namespace": "", "time_ms": 1718487639651, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "main.py", "lineno": 383}}
:::MLLOG {"namespace": "", "time_ms": 1718487639655, "event_type": "POINT_IN_TIME", "key": "seed", "value": 3547194125, "metadata": {"file": "main.py", "lineno": 450}}
[rank: 13] Global seed set to 3547194125
:::MLLOG {"namespace": "", "time_ms": 1718487641490, "event_type": "POINT_IN_TIME", "key": "submission_benchmark", "value": "stable_diffusion", "metadata": {"file": "mlperf_logging_utils.py", "lineno": 72}}
:::MLLOG {"namespace": "", "time_ms": 1718487641532, "event_type": "POINT_IN_TIME", "key": "submission_division", "value": "closed", "metadata": {"file": "mlperf_logging_utils.py", "lineno": 73}}
:::MLLOG {"namespace": "", "time_ms": 1718487641533, "event_type": "POINT_IN_TIME", "key": "submission_org", "value": "reference_implementation", "metadata": {"file": "mlperf_logging_utils.py", "lineno": 74}}
:::MLLOG {"namespace": "", "time_ms": 1718487641534, "event_type": "POINT_IN_TIME", "key": "submission_platform", "value": "DGX-A100", "metadata": {"file": "mlperf_logging_utils.py", "lineno": 75}}
:::MLLOG {"namespace": "", "time_ms": 1718487641501, "event_type": "POINT_IN_TIME", "key": "submission_benchmark", "value": "stable_diffusion", "metadata": {"file": "mlperf_logging_utils.py", "lineno": 72}}
:::MLLOG {"namespace": "", "time_ms": 1718487641535, "event_type": "POINT_IN_TIME", "key": "submission_poc_name", "value": "Ahmad Kiswani", "metadata": {"file": "mlperf_logging_utils.py", "lineno": 76}}
:::MLLOG {"namespace": "", "time_ms": 1718487641537, "event_type": "POINT_IN_TIME", "key": "submission_division", "value": "closed", "metadata": {"file": "mlperf_logging_utils.py", "lineno": 73}}
:::MLLOG {"namespace": "", "time_ms": 1718487641538, "event_type": "POINT_IN_TIME", "key": "submission_poc_email", "value": "akiswani@nvidia.com", "metadata": {"file": "mlperf_logging_utils.py", "lineno": 77}}
:::MLLOG {"namespace": "", "time_ms": 1718487641539, "event_type": "POINT_IN_TIME", "key": "submission_org", "value": "reference_implementation", "metadata": {"file": "mlperf_logging_utils.py", "lineno": 74}}
:::MLLOG {"namespace": "", "time_ms": 1718487641540, "event_type": "POINT_IN_TIME", "key": "submission_status", "value": "onprem", "metadata": {"file": "mlperf_logging_utils.py", "lineno": 78}}
:::MLLOG {"namespace": "", "time_ms": 1718487641540, "event_type": "POINT_IN_TIME", "key": "submission_platform", "value": "DGX-A100", "metadata": {"file": "mlperf_logging_utils.py", "lineno": 75}}
:::MLLOG {"namespace": "", "time_ms": 1718487641541, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "main.py", "lineno": 383}}
:::MLLOG {"namespace": "", "time_ms": 1718487641543, "event_type": "POINT_IN_TIME", "key": "submission_poc_name", "value": "Ahmad Kiswani", "metadata": {"file": "mlperf_logging_utils.py", "lineno": 76}}
:::MLLOG {"namespace": "", "time_ms": 1718487641545, "event_type": "POINT_IN_TIME", "key": "submission_poc_email", "value": "akiswani@nvidia.com", "metadata": {"file": "mlperf_logging_utils.py", "lineno": 77}}
:::MLLOG {"namespace": "", "time_ms": 1718487641546, "event_type": "POINT_IN_TIME", "key": "seed", "value": 1497686907, "metadata": {"file": "main.py", "lineno": 450}}
:::MLLOG {"namespace": "", "time_ms": 1718487641546, "event_type": "POINT_IN_TIME", "key": "submission_status", "value": "onprem", "metadata": {"file": "mlperf_logging_utils.py", "lineno": 78}}
[rank: 6] Global seed set to 1497686907
:::MLLOG {"namespace": "", "time_ms": 1718487641550, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "main.py", "lineno": 383}}
:::MLLOG {"namespace": "", "time_ms": 1718487641554, "event_type": "POINT_IN_TIME", "key": "seed", "value": 3948419655, "metadata": {"file": "main.py", "lineno": 450}}
[rank: 1] Global seed set to 3948419655
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is None and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is 1024 and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is None and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is 1024 and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is None and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is 1024 and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is None and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is 1024 and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is None and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is 1024 and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is None and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is 1024 and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is None and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is 1024 and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is None and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is 1024 and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is None and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is 1024 and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is None and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is 1024 and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is None and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is 1024 and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is None and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is 1024 and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is None and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is 1024 and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is None and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is 1024 and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is None and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is 1024 and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is None and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is 1024 and using 5 heads.
:::MLLOG {"namespace": "", "time_ms": 1718487686742, "event_type": "POINT_IN_TIME", "key": "train_samples", "value": 1, "metadata": {"file": "main.py", "lineno": 613}}
:::MLLOG {"namespace": "", "time_ms": 1718487686744, "event_type": "POINT_IN_TIME", "key": "eval_samples", "value": 30000, "metadata": {"file": "main.py", "lineno": 614}}
:::MLLOG {"namespace": "", "time_ms": 1718487686745, "event_type": "POINT_IN_TIME", "key": "gradient_accumulation_steps", "value": 1, "metadata": {"file": "main.py", "lineno": 622}}
:::MLLOG {"namespace": "", "time_ms": 1718487686747, "event_type": "POINT_IN_TIME", "key": "global_batch_size", "value": 128, "metadata": {"file": "main.py", "lineno": 633}}
:::MLLOG {"namespace": "", "time_ms": 1718487686748, "event_type": "INTERVAL_END", "key": "init_stop", "value": null, "metadata": {"file": "main.py", "lineno": 666}}
[rank: 7] Global seed set to 286234108
Initializing distributed: GLOBAL_RANK: 7, MEMBER: 8/16
ModelCheckpoint(save_last=True, save_top_k=-1, monitor=None) will duplicate the last checkpoint saved.
Using 16bit None Automatic Mixed Precision (AMP)
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is None and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is 1024 and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is None and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is 1024 and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is None and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is 1024 and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is None and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is 1024 and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is None and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is 1024 and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is None and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is 1024 and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is None and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is 1024 and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is None and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is 1024 and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is None and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is 1024 and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is None and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is 1024 and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is None and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is 1024 and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is None and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is 1024 and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is None and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is 1024 and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is None and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is 1024 and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is None and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is 1024 and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is None and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is 1024 and using 5 heads.
:::MLLOG {"namespace": "", "time_ms": 1718487686815, "event_type": "POINT_IN_TIME", "key": "train_samples", "value": 1, "metadata": {"file": "main.py", "lineno": 613}}
:::MLLOG {"namespace": "", "time_ms": 1718487686816, "event_type": "POINT_IN_TIME", "key": "eval_samples", "value": 30000, "metadata": {"file": "main.py", "lineno": 614}}
:::MLLOG {"namespace": "", "time_ms": 1718487686817, "event_type": "POINT_IN_TIME", "key": "gradient_accumulation_steps", "value": 1, "metadata": {"file": "main.py", "lineno": 622}}
:::MLLOG {"namespace": "", "time_ms": 1718487686818, "event_type": "POINT_IN_TIME", "key": "global_batch_size", "value": 128, "metadata": {"file": "main.py", "lineno": 633}}
Setting learning rate to 1.60e-05 = 1 (accumulate_grad_batches) * 16 (num_gpus) * 8 (local_batch_size) * 1.25e-07 (base_lr)
:::MLLOG {"namespace": "", "time_ms": 1718487686819, "event_type": "INTERVAL_END", "key": "init_stop", "value": null, "metadata": {"file": "main.py", "lineno": 666}}
[rank: 0] Global seed set to 3234298782
Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/16
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is None and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is 1024 and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is None and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is 1024 and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is None and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is 1024 and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is None and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is 1024 and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is None and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is 1024 and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is None and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is 1024 and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is None and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is 1024 and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is None and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is 1024 and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is None and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is 1024 and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is None and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is 1024 and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is None and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is 1024 and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is None and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is 1024 and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is None and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is 1024 and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is None and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is 1024 and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is None and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is 1024 and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is None and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is 1024 and using 5 heads.
:::MLLOG {"namespace": "", "time_ms": 1718487687114, "event_type": "POINT_IN_TIME", "key": "train_samples", "value": 1, "metadata": {"file": "main.py", "lineno": 613}}
:::MLLOG {"namespace": "", "time_ms": 1718487687119, "event_type": "POINT_IN_TIME", "key": "eval_samples", "value": 30000, "metadata": {"file": "main.py", "lineno": 614}}
:::MLLOG {"namespace": "", "time_ms": 1718487687120, "event_type": "POINT_IN_TIME", "key": "gradient_accumulation_steps", "value": 1, "metadata": {"file": "main.py", "lineno": 622}}
:::MLLOG {"namespace": "", "time_ms": 1718487687122, "event_type": "POINT_IN_TIME", "key": "global_batch_size", "value": 128, "metadata": {"file": "main.py", "lineno": 633}}
:::MLLOG {"namespace": "", "time_ms": 1718487687123, "event_type": "INTERVAL_END", "key": "init_stop", "value": null, "metadata": {"file": "main.py", "lineno": 666}}
[rank: 2] Global seed set to 784250613
Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/16
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is None and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is 1024 and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is None and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is 1024 and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is None and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is 1024 and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is None and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is 1024 and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is None and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is 1024 and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is None and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is 1024 and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is None and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is 1024 and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is None and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is 1024 and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is None and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is 1024 and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is None and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is 1024 and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is None and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is 1024 and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is None and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is 1024 and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is None and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is 1024 and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is None and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is 1024 and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is None and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is 1024 and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is None and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is 1024 and using 5 heads.
:::MLLOG {"namespace": "", "time_ms": 1718487687132, "event_type": "POINT_IN_TIME", "key": "train_samples", "value": 1, "metadata": {"file": "main.py", "lineno": 613}}
:::MLLOG {"namespace": "", "time_ms": 1718487687133, "event_type": "POINT_IN_TIME", "key": "eval_samples", "value": 30000, "metadata": {"file": "main.py", "lineno": 614}}
:::MLLOG {"namespace": "", "time_ms": 1718487687134, "event_type": "POINT_IN_TIME", "key": "gradient_accumulation_steps", "value": 1, "metadata": {"file": "main.py", "lineno": 622}}
:::MLLOG {"namespace": "", "time_ms": 1718487687135, "event_type": "POINT_IN_TIME", "key": "global_batch_size", "value": 128, "metadata": {"file": "main.py", "lineno": 633}}
:::MLLOG {"namespace": "", "time_ms": 1718487687137, "event_type": "INTERVAL_END", "key": "init_stop", "value": null, "metadata": {"file": "main.py", "lineno": 666}}
[rank: 3] Global seed set to 3425774915
Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/16
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is None and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is 1024 and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is None and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is 1024 and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is None and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is 1024 and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is None and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is 1024 and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is None and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is 1024 and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is None and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is 1024 and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is None and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is 1024 and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is None and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is 1024 and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is None and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is 1024 and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is None and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is 1024 and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is None and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is 1024 and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is None and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is 1024 and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is None and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is 1024 and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is None and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is 1024 and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is None and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is 1024 and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is None and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is 1024 and using 5 heads.
:::MLLOG {"namespace": "", "time_ms": 1718487687148, "event_type": "POINT_IN_TIME", "key": "train_samples", "value": 1, "metadata": {"file": "main.py", "lineno": 613}}
:::MLLOG {"namespace": "", "time_ms": 1718487687149, "event_type": "POINT_IN_TIME", "key": "eval_samples", "value": 30000, "metadata": {"file": "main.py", "lineno": 614}}
:::MLLOG {"namespace": "", "time_ms": 1718487687151, "event_type": "POINT_IN_TIME", "key": "gradient_accumulation_steps", "value": 1, "metadata": {"file": "main.py", "lineno": 622}}
:::MLLOG {"namespace": "", "time_ms": 1718487687152, "event_type": "POINT_IN_TIME", "key": "global_batch_size", "value": 128, "metadata": {"file": "main.py", "lineno": 633}}
:::MLLOG {"namespace": "", "time_ms": 1718487687153, "event_type": "INTERVAL_END", "key": "init_stop", "value": null, "metadata": {"file": "main.py", "lineno": 666}}
[rank: 4] Global seed set to 1384795041
Initializing distributed: GLOBAL_RANK: 4, MEMBER: 5/16
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is None and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is 1024 and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is None and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is 1024 and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is None and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is 1024 and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is None and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is 1024 and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is None and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is 1024 and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is None and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is 1024 and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is None and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is 1024 and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is None and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is 1024 and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is None and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is 1024 and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is None and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is 1024 and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is None and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is 1024 and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is None and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is 1024 and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is None and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is 1024 and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is None and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is 1024 and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is None and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is 1024 and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is None and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is 1024 and using 5 heads.
:::MLLOG {"namespace": "", "time_ms": 1718487687211, "event_type": "POINT_IN_TIME", "key": "train_samples", "value": 1, "metadata": {"file": "main.py", "lineno": 613}}
:::MLLOG {"namespace": "", "time_ms": 1718487687212, "event_type": "POINT_IN_TIME", "key": "eval_samples", "value": 30000, "metadata": {"file": "main.py", "lineno": 614}}
:::MLLOG {"namespace": "", "time_ms": 1718487687213, "event_type": "POINT_IN_TIME", "key": "gradient_accumulation_steps", "value": 1, "metadata": {"file": "main.py", "lineno": 622}}
:::MLLOG {"namespace": "", "time_ms": 1718487687214, "event_type": "POINT_IN_TIME", "key": "global_batch_size", "value": 128, "metadata": {"file": "main.py", "lineno": 633}}
:::MLLOG {"namespace": "", "time_ms": 1718487687216, "event_type": "INTERVAL_END", "key": "init_stop", "value": null, "metadata": {"file": "main.py", "lineno": 666}}
[rank: 5] Global seed set to 2431098013
Initializing distributed: GLOBAL_RANK: 5, MEMBER: 6/16
Missing logger folder: /results/2024-06-15T21-40-30_train_02x08x08/diff_tb
Missing logger folder: /results/2024-06-15T21-40-30_train_02x08x08/diff_tb
Missing logger folder: /results/2024-06-15T21-40-31_train_02x08x08/diff_tb
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is None and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is 1024 and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is None and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is 1024 and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is None and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is 1024 and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is None and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is 1024 and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is None and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is 1024 and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is None and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is 1024 and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is None and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is 1024 and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is None and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is 1024 and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is None and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is 1024 and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is None and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is 1024 and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is None and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is 1024 and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is None and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is 1024 and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is None and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is 1024 and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is None and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is 1024 and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is None and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is 1024 and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is None and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is 1024 and using 5 heads.
:::MLLOG {"namespace": "", "time_ms": 1718487687848, "event_type": "POINT_IN_TIME", "key": "train_samples", "value": 1, "metadata": {"file": "main.py", "lineno": 613}}
Missing logger folder: /results/2024-06-15T21-40-31_train_02x08x08/diff_tb
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is None and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is 1024 and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is None and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is 1024 and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is None and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is 1024 and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is None and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is 1024 and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is None and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is 1024 and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is None and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is 1024 and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is None and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is 1024 and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is None and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is 1024 and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is None and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is 1024 and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is None and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is 1024 and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is None and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is 1024 and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is None and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is 1024 and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is None and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is 1024 and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is None and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is 1024 and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is None and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is 1024 and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is None and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is 1024 and using 5 heads.
:::MLLOG {"namespace": "", "time_ms": 1718487687850, "event_type": "POINT_IN_TIME", "key": "train_samples", "value": 1, "metadata": {"file": "main.py", "lineno": 613}}
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is None and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is 1024 and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is None and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is 1024 and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is None and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is 1024 and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is None and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is 1024 and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is None and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is 1024 and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is None and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is 1024 and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is None and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is 1024 and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is None and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is 1024 and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is None and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is 1024 and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is None and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is 1024 and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is None and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is 1024 and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is None and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is 1024 and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is None and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is 1024 and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is None and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is 1024 and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is None and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is 1024 and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is None and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is 1024 and using 5 heads.
:::MLLOG {"namespace": "", "time_ms": 1718487687849, "event_type": "POINT_IN_TIME", "key": "train_samples", "value": 1, "metadata": {"file": "main.py", "lineno": 613}}
:::MLLOG {"namespace": "", "time_ms": 1718487687850, "event_type": "POINT_IN_TIME", "key": "eval_samples", "value": 30000, "metadata": {"file": "main.py", "lineno": 614}}
:::MLLOG {"namespace": "", "time_ms": 1718487687851, "event_type": "POINT_IN_TIME", "key": "eval_samples", "value": 30000, "metadata": {"file": "main.py", "lineno": 614}}
:::MLLOG {"namespace": "", "time_ms": 1718487687852, "event_type": "POINT_IN_TIME", "key": "eval_samples", "value": 30000, "metadata": {"file": "main.py", "lineno": 614}}
:::MLLOG {"namespace": "", "time_ms": 1718487687854, "event_type": "POINT_IN_TIME", "key": "gradient_accumulation_steps", "value": 1, "metadata": {"file": "main.py", "lineno": 622}}
:::MLLOG {"namespace": "", "time_ms": 1718487687855, "event_type": "POINT_IN_TIME", "key": "gradient_accumulation_steps", "value": 1, "metadata": {"file": "main.py", "lineno": 622}}
:::MLLOG {"namespace": "", "time_ms": 1718487687856, "event_type": "POINT_IN_TIME", "key": "gradient_accumulation_steps", "value": 1, "metadata": {"file": "main.py", "lineno": 622}}
:::MLLOG {"namespace": "", "time_ms": 1718487687857, "event_type": "POINT_IN_TIME", "key": "global_batch_size", "value": 128, "metadata": {"file": "main.py", "lineno": 633}}
:::MLLOG {"namespace": "", "time_ms": 1718487687858, "event_type": "POINT_IN_TIME", "key": "global_batch_size", "value": 128, "metadata": {"file": "main.py", "lineno": 633}}
:::MLLOG {"namespace": "", "time_ms": 1718487687859, "event_type": "POINT_IN_TIME", "key": "global_batch_size", "value": 128, "metadata": {"file": "main.py", "lineno": 633}}
:::MLLOG {"namespace": "", "time_ms": 1718487687859, "event_type": "INTERVAL_END", "key": "init_stop", "value": null, "metadata": {"file": "main.py", "lineno": 666}}
:::MLLOG {"namespace": "", "time_ms": 1718487687860, "event_type": "INTERVAL_END", "key": "init_stop", "value": null, "metadata": {"file": "main.py", "lineno": 666}}
:::MLLOG {"namespace": "", "time_ms": 1718487687862, "event_type": "INTERVAL_END", "key": "init_stop", "value": null, "metadata": {"file": "main.py", "lineno": 666}}
Missing logger folder: /results/2024-06-15T21-40-29_train_02x08x08/diff_tb
[rank: 12] Global seed set to 2666444545
Initializing distributed: GLOBAL_RANK: 12, MEMBER: 13/16
[rank: 10] Global seed set to 912576944
[rank: 8] Global seed set to 2529196808
Initializing distributed: GLOBAL_RANK: 10, MEMBER: 11/16
Initializing distributed: GLOBAL_RANK: 8, MEMBER: 9/16
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is None and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is 1024 and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is None and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is 1024 and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is None and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is 1024 and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is None and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is 1024 and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is None and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is 1024 and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is None and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is 1024 and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is None and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is 1024 and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is None and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is 1024 and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is None and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is 1024 and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is None and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is 1024 and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is None and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is 1024 and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is None and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is 1024 and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is None and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is 1024 and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is None and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is 1024 and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is None and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is 1024 and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is None and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is 1024 and using 5 heads.
:::MLLOG {"namespace": "", "time_ms": 1718487688190, "event_type": "POINT_IN_TIME", "key": "train_samples", "value": 1, "metadata": {"file": "main.py", "lineno": 613}}
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is None and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is 1024 and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is None and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is 1024 and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is None and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is 1024 and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is None and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is 1024 and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is None and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is 1024 and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is None and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is 1024 and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is None and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is 1024 and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is None and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is 1024 and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is None and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is 1024 and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is None and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is 1024 and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is None and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is 1024 and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is None and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is 1024 and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is None and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is 1024 and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is None and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is 1024 and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is None and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is 1024 and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is None and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is 1024 and using 5 heads.
:::MLLOG {"namespace": "", "time_ms": 1718487688190, "event_type": "POINT_IN_TIME", "key": "train_samples", "value": 1, "metadata": {"file": "main.py", "lineno": 613}}
:::MLLOG {"namespace": "", "time_ms": 1718487688193, "event_type": "POINT_IN_TIME", "key": "eval_samples", "value": 30000, "metadata": {"file": "main.py", "lineno": 614}}
:::MLLOG {"namespace": "", "time_ms": 1718487688194, "event_type": "POINT_IN_TIME", "key": "eval_samples", "value": 30000, "metadata": {"file": "main.py", "lineno": 614}}
:::MLLOG {"namespace": "", "time_ms": 1718487688195, "event_type": "POINT_IN_TIME", "key": "gradient_accumulation_steps", "value": 1, "metadata": {"file": "main.py", "lineno": 622}}
:::MLLOG {"namespace": "", "time_ms": 1718487688196, "event_type": "POINT_IN_TIME", "key": "gradient_accumulation_steps", "value": 1, "metadata": {"file": "main.py", "lineno": 622}}
:::MLLOG {"namespace": "", "time_ms": 1718487688197, "event_type": "POINT_IN_TIME", "key": "global_batch_size", "value": 128, "metadata": {"file": "main.py", "lineno": 633}}
:::MLLOG {"namespace": "", "time_ms": 1718487688198, "event_type": "POINT_IN_TIME", "key": "global_batch_size", "value": 128, "metadata": {"file": "main.py", "lineno": 633}}
:::MLLOG {"namespace": "", "time_ms": 1718487688199, "event_type": "INTERVAL_END", "key": "init_stop", "value": null, "metadata": {"file": "main.py", "lineno": 666}}
:::MLLOG {"namespace": "", "time_ms": 1718487688201, "event_type": "INTERVAL_END", "key": "init_stop", "value": null, "metadata": {"file": "main.py", "lineno": 666}}
[rank: 15] Global seed set to 1439472685
Initializing distributed: GLOBAL_RANK: 15, MEMBER: 16/16
Missing logger folder: /results/2024-06-15T21-40-27_train_02x08x08/diff_tb
[rank: 14] Global seed set to 1664490200
Initializing distributed: GLOBAL_RANK: 14, MEMBER: 15/16
Missing logger folder: /results/2024-06-15T21-40-27_train_02x08x08/diff_tb
Missing logger folder: /results/2024-06-15T21-40-27_train_02x08x08/diff_tb
Missing logger folder: /results/2024-06-15T21-40-27_train_02x08x08/diff_tb
Missing logger folder: /results/2024-06-15T21-40-27_train_02x08x08/diff_tb
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is None and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is 1024 and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is None and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is 1024 and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is None and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is 1024 and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is None and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is 1024 and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is None and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is 1024 and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is None and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is 1024 and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is None and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is 1024 and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is None and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is 1024 and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is None and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is 1024 and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is None and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is 1024 and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is None and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is 1024 and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is None and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is 1024 and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is None and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is 1024 and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is None and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is 1024 and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is None and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is 1024 and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is None and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is 1024 and using 5 heads.
:::MLLOG {"namespace": "", "time_ms": 1718487692611, "event_type": "POINT_IN_TIME", "key": "train_samples", "value": 1, "metadata": {"file": "main.py", "lineno": 613}}
:::MLLOG {"namespace": "", "time_ms": 1718487692613, "event_type": "POINT_IN_TIME", "key": "eval_samples", "value": 30000, "metadata": {"file": "main.py", "lineno": 614}}
:::MLLOG {"namespace": "", "time_ms": 1718487692614, "event_type": "POINT_IN_TIME", "key": "gradient_accumulation_steps", "value": 1, "metadata": {"file": "main.py", "lineno": 622}}
:::MLLOG {"namespace": "", "time_ms": 1718487692616, "event_type": "POINT_IN_TIME", "key": "global_batch_size", "value": 128, "metadata": {"file": "main.py", "lineno": 633}}
:::MLLOG {"namespace": "", "time_ms": 1718487692617, "event_type": "INTERVAL_END", "key": "init_stop", "value": null, "metadata": {"file": "main.py", "lineno": 666}}
[rank: 13] Global seed set to 3547194125
Initializing distributed: GLOBAL_RANK: 13, MEMBER: 14/16
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is None and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is 1024 and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is None and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is 1024 and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is None and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is 1024 and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is None and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is 1024 and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is None and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is 1024 and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is None and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is 1024 and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is None and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is 1024 and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is None and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is 1024 and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is None and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is 1024 and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is None and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is 1024 and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is None and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is 1024 and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is None and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is 1024 and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is None and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is 1024 and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is None and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is 1024 and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is None and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is 1024 and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is None and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is 1024 and using 5 heads.
:::MLLOG {"namespace": "", "time_ms": 1718487692621, "event_type": "POINT_IN_TIME", "key": "train_samples", "value": 1, "metadata": {"file": "main.py", "lineno": 613}}
:::MLLOG {"namespace": "", "time_ms": 1718487692622, "event_type": "POINT_IN_TIME", "key": "eval_samples", "value": 30000, "metadata": {"file": "main.py", "lineno": 614}}
:::MLLOG {"namespace": "", "time_ms": 1718487692624, "event_type": "POINT_IN_TIME", "key": "gradient_accumulation_steps", "value": 1, "metadata": {"file": "main.py", "lineno": 622}}
:::MLLOG {"namespace": "", "time_ms": 1718487692625, "event_type": "POINT_IN_TIME", "key": "global_batch_size", "value": 128, "metadata": {"file": "main.py", "lineno": 633}}
:::MLLOG {"namespace": "", "time_ms": 1718487692625, "event_type": "INTERVAL_END", "key": "init_stop", "value": null, "metadata": {"file": "main.py", "lineno": 666}}
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is None and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is 1024 and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is None and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is 1024 and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is None and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is 1024 and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is None and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is 1024 and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is None and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is 1024 and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is None and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is 1024 and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is None and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is 1024 and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is None and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is 1024 and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is None and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is 1024 and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is None and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is 1024 and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is None and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is 1024 and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is None and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is 1024 and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is None and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is 1024 and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is None and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is 1024 and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is None and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is 1024 and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is None and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is 1024 and using 5 heads.
:::MLLOG {"namespace": "", "time_ms": 1718487692628, "event_type": "POINT_IN_TIME", "key": "train_samples", "value": 1, "metadata": {"file": "main.py", "lineno": 613}}
[rank: 9] Global seed set to 2078658137
:::MLLOG {"namespace": "", "time_ms": 1718487692630, "event_type": "POINT_IN_TIME", "key": "eval_samples", "value": 30000, "metadata": {"file": "main.py", "lineno": 614}}
Initializing distributed: GLOBAL_RANK: 9, MEMBER: 10/16
:::MLLOG {"namespace": "", "time_ms": 1718487692631, "event_type": "POINT_IN_TIME", "key": "gradient_accumulation_steps", "value": 1, "metadata": {"file": "main.py", "lineno": 622}}
:::MLLOG {"namespace": "", "time_ms": 1718487692632, "event_type": "POINT_IN_TIME", "key": "global_batch_size", "value": 128, "metadata": {"file": "main.py", "lineno": 633}}
:::MLLOG {"namespace": "", "time_ms": 1718487692636, "event_type": "INTERVAL_END", "key": "init_stop", "value": null, "metadata": {"file": "main.py", "lineno": 666}}
[rank: 11] Global seed set to 1290533972
Initializing distributed: GLOBAL_RANK: 11, MEMBER: 12/16
Missing logger folder: /results/2024-06-15T21-40-39_train_02x08x08/diff_tb
Missing logger folder: /results/2024-06-15T21-40-38_train_02x08x08/diff_tb
Missing logger folder: /results/2024-06-15T21-40-38_train_02x08x08/diff_tb
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is None and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is 1024 and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is None and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is 1024 and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is None and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is 1024 and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is None and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is 1024 and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is None and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is 1024 and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is None and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is 1024 and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is None and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is 1024 and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is None and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is 1024 and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is None and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is 1024 and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is None and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is 1024 and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is None and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is 1024 and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is None and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is 1024 and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is None and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is 1024 and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is None and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is 1024 and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is None and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is 1024 and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is None and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is 1024 and using 5 heads.
:::MLLOG {"namespace": "", "time_ms": 1718487698431, "event_type": "POINT_IN_TIME", "key": "train_samples", "value": 1, "metadata": {"file": "main.py", "lineno": 613}}
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is None and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is 1024 and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is None and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is 1024 and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is None and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is 1024 and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is None and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is 1024 and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is None and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is 1024 and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is None and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is 1024 and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is None and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is 1024 and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is None and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is 1024 and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is None and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is 1024 and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is None and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is 1024 and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is None and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is 1024 and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is None and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is 1024 and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is None and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is 1024 and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is None and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is 1024 and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is None and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is 1024 and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is None and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is 1024 and using 5 heads.
:::MLLOG {"namespace": "", "time_ms": 1718487698431, "event_type": "POINT_IN_TIME", "key": "train_samples", "value": 1, "metadata": {"file": "main.py", "lineno": 613}}
:::MLLOG {"namespace": "", "time_ms": 1718487698432, "event_type": "POINT_IN_TIME", "key": "eval_samples", "value": 30000, "metadata": {"file": "main.py", "lineno": 614}}
:::MLLOG {"namespace": "", "time_ms": 1718487698433, "event_type": "POINT_IN_TIME", "key": "eval_samples", "value": 30000, "metadata": {"file": "main.py", "lineno": 614}}
:::MLLOG {"namespace": "", "time_ms": 1718487698434, "event_type": "POINT_IN_TIME", "key": "gradient_accumulation_steps", "value": 1, "metadata": {"file": "main.py", "lineno": 622}}
:::MLLOG {"namespace": "", "time_ms": 1718487698435, "event_type": "POINT_IN_TIME", "key": "gradient_accumulation_steps", "value": 1, "metadata": {"file": "main.py", "lineno": 622}}
:::MLLOG {"namespace": "", "time_ms": 1718487698436, "event_type": "POINT_IN_TIME", "key": "global_batch_size", "value": 128, "metadata": {"file": "main.py", "lineno": 633}}
:::MLLOG {"namespace": "", "time_ms": 1718487698441, "event_type": "POINT_IN_TIME", "key": "global_batch_size", "value": 128, "metadata": {"file": "main.py", "lineno": 633}}
:::MLLOG {"namespace": "", "time_ms": 1718487698442, "event_type": "INTERVAL_END", "key": "init_stop", "value": null, "metadata": {"file": "main.py", "lineno": 666}}
:::MLLOG {"namespace": "", "time_ms": 1718487698443, "event_type": "INTERVAL_END", "key": "init_stop", "value": null, "metadata": {"file": "main.py", "lineno": 666}}
[rank: 6] Global seed set to 1497686907
Initializing distributed: GLOBAL_RANK: 6, MEMBER: 7/16
[rank: 1] Global seed set to 3948419655
Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/16
----------------------------------------------------------------------------------------------------
distributed_backend=nccl
All distributed processes registered. Starting with 16 processes
----------------------------------------------------------------------------------------------------

Missing logger folder: /results/2024-06-15T21-40-30_train_02x08x08/diff_tb
worker-1:5776:5776 [0] NCCL INFO Bootstrap : Using eth0:10.113.5.242<0>
worker-1:5776:5776 [0] NCCL INFO NET/Plugin: Failed to find ncclNetPlugin_v7 symbol.
worker-1:5776:5776 [0] NCCL INFO NET/Plugin: Loaded net plugin NCCL RDMA Plugin v6 (v6)
worker-1:5776:5776 [0] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v7 symbol.
worker-1:5776:5776 [0] NCCL INFO NET/Plugin: Loaded coll plugin SHARP (v6)
worker-1:5776:5776 [0] NCCL INFO cudaDriverVersion 12030
NCCL version 2.19.3+cuda12.3
Missing logger folder: /results/2024-06-15T21-40-41_train_02x08x08/diff_tb
Missing logger folder: /results/2024-06-15T21-40-41_train_02x08x08/diff_tb
worker-1:5776:5864 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
worker-1:5776:5864 [0] NCCL INFO P2P plugin IBext
worker-1:5776:5864 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_1:1/IB/SHARP [2]mlx5_2:1/IB/SHARP [3]mlx5_3:1/IB/SHARP [4]mlx5_4:1/IB/SHARP [5]mlx5_5:1/IB/SHARP [6]mlx5_6:1/IB/SHARP [7]mlx5_7:1/IB/SHARP [RO]; OOB eth0:10.113.5.242<0>
worker-1:5776:5864 [0] NCCL INFO Using non-device net plugin version 0
worker-1:5776:5864 [0] NCCL INFO Using network IBext
worker-1:5776:5864 [0] NCCL INFO comm 0x55bd13e90250 rank 0 nranks 16 cudaDev 0 nvmlDev 0 busId 8d000 commId 0xfd5d9e8febee040d - Init START
worker-1:5776:5864 [0] NCCL INFO NCCL_TOPO_FILE set by environment to /var/run/nvidia-topologyd/virtualTopology.xml
worker-1:5776:5864 [0] NCCL INFO Setting affinity for GPU 0 to 01
worker-1:5776:5864 [0] NCCL INFO NVLS multicast support is available on dev 0
worker-1:5776:5864 [0] NCCL INFO NVLS Head  0:  0  8
worker-1:5776:5864 [0] NCCL INFO NVLS Head  1:  1  9
worker-1:5776:5864 [0] NCCL INFO NVLS Head  2:  2 10
worker-1:5776:5864 [0] NCCL INFO NVLS Head  3:  3 11
worker-1:5776:5864 [0] NCCL INFO NVLS Head  4:  4 12
worker-1:5776:5864 [0] NCCL INFO NVLS Head  5:  5 13
worker-1:5776:5864 [0] NCCL INFO NVLS Head  6:  6 14
worker-1:5776:5864 [0] NCCL INFO NVLS Head  7:  7 15
worker-1:5776:5864 [0] NCCL INFO Channel 00/16 :    0   7   6   5   4   3   2   1   8  15  14  13  12  11  10   9
worker-1:5776:5864 [0] NCCL INFO Channel 01/16 :    0   7   6   5   4   3   2   9   8  15  14  13  12  11  10   1
worker-1:5776:5864 [0] NCCL INFO Channel 02/16 :    0   7   6   5   4   3  10   9   8  15  14  13  12  11   2   1
worker-1:5776:5864 [0] NCCL INFO Channel 03/16 :    0   7   6   5   4  11  10   9   8  15  14  13  12   3   2   1
worker-1:5776:5864 [0] NCCL INFO Channel 04/16 :    0   7   6   5  12  11  10   9   8  15  14  13   4   3   2   1
worker-1:5776:5864 [0] NCCL INFO Channel 05/16 :    0   7   6  13  12  11  10   9   8  15  14   5   4   3   2   1
worker-1:5776:5864 [0] NCCL INFO Channel 06/16 :    0   7  14  13  12  11  10   9   8  15   6   5   4   3   2   1
worker-1:5776:5864 [0] NCCL INFO Channel 07/16 :    0  15  14  13  12  11  10   9   8   7   6   5   4   3   2   1
worker-1:5776:5864 [0] NCCL INFO Channel 08/16 :    0   7   6   5   4   3   2   1   8  15  14  13  12  11  10   9
worker-1:5776:5864 [0] NCCL INFO Channel 09/16 :    0   7   6   5   4   3   2   9   8  15  14  13  12  11  10   1
worker-1:5776:5864 [0] NCCL INFO Channel 10/16 :    0   7   6   5   4   3  10   9   8  15  14  13  12  11   2   1
worker-1:5776:5864 [0] NCCL INFO Channel 11/16 :    0   7   6   5   4  11  10   9   8  15  14  13  12   3   2   1
worker-1:5776:5864 [0] NCCL INFO Channel 12/16 :    0   7   6   5  12  11  10   9   8  15  14  13   4   3   2   1
worker-1:5776:5864 [0] NCCL INFO Channel 13/16 :    0   7   6  13  12  11  10   9   8  15  14   5   4   3   2   1
worker-1:5776:5864 [0] NCCL INFO Channel 14/16 :    0   7  14  13  12  11  10   9   8  15   6   5   4   3   2   1
worker-1:5776:5864 [0] NCCL INFO Channel 15/16 :    0  15  14  13  12  11  10   9   8   7   6   5   4   3   2   1
worker-1:5776:5864 [0] NCCL INFO Trees [0] 1/8/-1->0->-1 [1] -1/-1/-1->0->7 [2] 1/-1/-1->0->7 [3] 1/-1/-1->0->7 [4] 1/-1/-1->0->7 [5] 1/-1/-1->0->7 [6] 1/-1/-1->0->7 [7] 1/-1/-1->0->7 [8] 1/-1/-1->0->8 [9] -1/-1/-1->0->7 [10] 1/-1/-1->0->7 [11] 1/-1/-1->0->7 [12] 1/-1/-1->0->7 [13] 1/-1/-1->0->7 [14] 1/-1/-1->0->7 [15] 1/-1/-1->0->7
worker-1:5776:5864 [0] NCCL INFO P2P Chunksize set to 131072
worker-1:5776:5864 [0] NCCL INFO Channel 00/0 : 9[1] -> 0[0] [receive] via NET/IBext/4/GDRDMA
worker-1:5776:5864 [0] NCCL INFO Channel 08/0 : 9[1] -> 0[0] [receive] via NET/IBext/4/GDRDMA
worker-1:5776:5864 [0] NCCL INFO Channel 00/0 : 0[0] -> 7[7] via P2P/CUMEM
worker-1:5776:5864 [0] NCCL INFO Channel 01/0 : 0[0] -> 7[7] via P2P/CUMEM
worker-1:5776:5864 [0] NCCL INFO Channel 02/0 : 0[0] -> 7[7] via P2P/CUMEM
worker-1:5776:5864 [0] NCCL INFO Channel 03/0 : 0[0] -> 7[7] via P2P/CUMEM
worker-1:5788:5788 [1] NCCL INFO cudaDriverVersion 12030
worker-1:5788:5788 [1] NCCL INFO Bootstrap : Using eth0:10.113.5.242<0>
worker-1:5788:5788 [1] NCCL INFO NET/Plugin: Failed to find ncclNetPlugin_v7 symbol.
worker-1:5788:5788 [1] NCCL INFO NET/Plugin: Loaded net plugin NCCL RDMA Plugin v6 (v6)
worker-1:5788:5788 [1] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v7 symbol.
worker-1:5788:5788 [1] NCCL INFO NET/Plugin: Loaded coll plugin SHARP (v6)
worker-1:5788:5870 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
worker-1:5788:5870 [1] NCCL INFO P2P plugin IBext
worker-1:5788:5870 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_1:1/IB/SHARP [2]mlx5_2:1/IB/SHARP [3]mlx5_3:1/IB/SHARP [4]mlx5_4:1/IB/SHARP [5]mlx5_5:1/IB/SHARP [6]mlx5_6:1/IB/SHARP [7]mlx5_7:1/IB/SHARP [RO]; OOB eth0:10.113.5.242<0>
worker-1:5788:5870 [1] NCCL INFO Using non-device net plugin version 0
worker-1:5788:5870 [1] NCCL INFO Using network IBext
worker-1:5788:5870 [1] NCCL INFO comm 0x56195ea363f0 rank 1 nranks 16 cudaDev 1 nvmlDev 1 busId 91000 commId 0xfd5d9e8febee040d - Init START
worker-1:5788:5870 [1] NCCL INFO NCCL_TOPO_FILE set by environment to /var/run/nvidia-topologyd/virtualTopology.xml
worker-1:5788:5870 [1] NCCL INFO Setting affinity for GPU 1 to 02
worker-1:5788:5870 [1] NCCL INFO NVLS multicast support is available on dev 1
worker-1:5788:5870 [1] NCCL INFO NVLS Head  0:  0  8
worker-1:5788:5870 [1] NCCL INFO NVLS Head  1:  1  9
worker-1:5788:5870 [1] NCCL INFO NVLS Head  2:  2 10
worker-1:5788:5870 [1] NCCL INFO NVLS Head  3:  3 11
worker-1:5788:5870 [1] NCCL INFO NVLS Head  4:  4 12
worker-1:5788:5870 [1] NCCL INFO NVLS Head  5:  5 13
worker-1:5788:5870 [1] NCCL INFO NVLS Head  6:  6 14
worker-1:5788:5870 [1] NCCL INFO NVLS Head  7:  7 15
worker-1:5788:5870 [1] NCCL INFO Trees [0] 2/-1/-1->1->0 [1] 2/9/-1->1->-1 [2] -1/-1/-1->1->0 [3] 2/-1/-1->1->0 [4] 2/-1/-1->1->0 [5] 2/-1/-1->1->0 [6] 2/-1/-1->1->0 [7] 2/-1/-1->1->0 [8] 2/-1/-1->1->0 [9] 2/-1/-1->1->9 [10] -1/-1/-1->1->0 [11] 2/-1/-1->1->0 [12] 2/-1/-1->1->0 [13] 2/-1/-1->1->0 [14] 2/-1/-1->1->0 [15] 2/-1/-1->1->0
worker-1:5788:5870 [1] NCCL INFO P2P Chunksize set to 131072
worker-1:5788:5870 [1] NCCL INFO Channel 01/0 : 10[2] -> 1[1] [receive] via NET/IBext/5/GDRDMA
worker-1:5788:5870 [1] NCCL INFO Channel 09/0 : 10[2] -> 1[1] [receive] via NET/IBext/5/GDRDMA
worker-1:5788:5870 [1] NCCL INFO Channel 00/0 : 1[1] -> 8[0] [send] via NET/IBext/4(0)/GDRDMA
worker-1:5788:5870 [1] NCCL INFO Channel 08/0 : 1[1] -> 8[0] [send] via NET/IBext/4(0)/GDRDMA
worker-1:5788:5870 [1] NCCL INFO Channel 01/0 : 1[1] -> 0[0] via P2P/CUMEM
worker-1:5788:5870 [1] NCCL INFO Channel 02/0 : 1[1] -> 0[0] via P2P/CUMEM
worker-1:5788:5870 [1] NCCL INFO Channel 03/0 : 1[1] -> 0[0] via P2P/CUMEM
worker-0:5751:5751 [1] NCCL INFO cudaDriverVersion 12030
worker-0:5751:5751 [1] NCCL INFO Bootstrap : Using eth0:10.113.4.37<0>
worker-0:5751:5751 [1] NCCL INFO NET/Plugin: Failed to find ncclNetPlugin_v7 symbol.
worker-0:5751:5751 [1] NCCL INFO NET/Plugin: Loaded net plugin NCCL RDMA Plugin v6 (v6)
worker-0:5751:5751 [1] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v7 symbol.
worker-0:5751:5751 [1] NCCL INFO NET/Plugin: Loaded coll plugin SHARP (v6)
worker-0:5751:5834 [1] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
worker-0:5751:5834 [1] NCCL INFO P2P plugin IBext
worker-0:5751:5834 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_1:1/IB/SHARP [2]mlx5_2:1/IB/SHARP [3]mlx5_3:1/IB/SHARP [4]mlx5_4:1/IB/SHARP [5]mlx5_5:1/IB/SHARP [6]mlx5_6:1/IB/SHARP [7]mlx5_7:1/IB/SHARP [RO]; OOB eth0:10.113.4.37<0>
worker-0:5751:5834 [1] NCCL INFO Using non-device net plugin version 0
worker-0:5751:5834 [1] NCCL INFO Using network IBext
worker-1:5788:5870 [1] NCCL INFO Channel 04/0 : 1[1] -> 0[0] via P2P/CUMEM
worker-1:5788:5870 [1] NCCL INFO Channel 05/0 : 1[1] -> 0[0] via P2P/CUMEM
worker-1:5788:5870 [1] NCCL INFO Channel 06/0 : 1[1] -> 0[0] via P2P/CUMEM
worker-1:5788:5870 [1] NCCL INFO Channel 07/0 : 1[1] -> 0[0] via P2P/CUMEM
worker-1:5788:5870 [1] NCCL INFO Channel 09/0 : 1[1] -> 0[0] via P2P/CUMEM
worker-1:5788:5870 [1] NCCL INFO Channel 10/0 : 1[1] -> 0[0] via P2P/CUMEM
worker-1:5788:5870 [1] NCCL INFO Channel 11/0 : 1[1] -> 0[0] via P2P/CUMEM
worker-1:5788:5870 [1] NCCL INFO Channel 12/0 : 1[1] -> 0[0] via P2P/CUMEM
worker-1:5788:5870 [1] NCCL INFO Channel 13/0 : 1[1] -> 0[0] via P2P/CUMEM
worker-1:5788:5870 [1] NCCL INFO Channel 14/0 : 1[1] -> 0[0] via P2P/CUMEM
worker-1:5788:5870 [1] NCCL INFO Channel 15/0 : 1[1] -> 0[0] via P2P/CUMEM
worker-1:5788:5870 [1] NCCL INFO Connected all rings
worker-1:5788:5870 [1] NCCL INFO Channel 00/0 : 1[1] -> 2[2] via P2P/CUMEM
worker-0:5751:5834 [1] NCCL INFO comm 0x559a6e72c030 rank 9 nranks 16 cudaDev 1 nvmlDev 1 busId 91000 commId 0xfd5d9e8febee040d - Init START
worker-0:5751:5834 [1] NCCL INFO NCCL_TOPO_FILE set by environment to /var/run/nvidia-topologyd/virtualTopology.xml
worker-0:5751:5834 [1] NCCL INFO Setting affinity for GPU 1 to 02
worker-0:5751:5834 [1] NCCL INFO NVLS multicast support is available on dev 1
worker-0:5751:5834 [1] NCCL INFO Trees [0] 10/-1/-1->9->8 [1] 10/-1/-1->9->1 [2] -1/-1/-1->9->8 [3] 10/-1/-1->9->8 [4] 10/-1/-1->9->8 [5] 10/-1/-1->9->8 [6] 10/-1/-1->9->8 [7] 10/-1/-1->9->8 [8] 10/-1/-1->9->8 [9] 10/1/-1->9->-1 [10] -1/-1/-1->9->8 [11] 10/-1/-1->9->8 [12] 10/-1/-1->9->8 [13] 10/-1/-1->9->8 [14] 10/-1/-1->9->8 [15] 10/-1/-1->9->8
worker-0:5751:5834 [1] NCCL INFO P2P Chunksize set to 131072
worker-0:5751:5834 [1] NCCL INFO Channel 01/0 : 2[2] -> 9[1] [receive] via NET/IBext/5/GDRDMA
worker-0:5751:5834 [1] NCCL INFO Channel 09/0 : 2[2] -> 9[1] [receive] via NET/IBext/5/GDRDMA
worker-1:5788:5870 [1] NCCL INFO Channel 01/0 : 1[1] -> 2[2] via P2P/CUMEM
worker-1:5788:5870 [1] NCCL INFO Channel 03/0 : 1[1] -> 2[2] via P2P/CUMEM
worker-1:5788:5870 [1] NCCL INFO Channel 04/0 : 1[1] -> 2[2] via P2P/CUMEM
worker-1:5788:5870 [1] NCCL INFO Channel 05/0 : 1[1] -> 2[2] via P2P/CUMEM
worker-0:5751:5834 [1] NCCL INFO Channel 00/0 : 9[1] -> 0[0] [send] via NET/IBext/4(8)/GDRDMA
worker-0:5751:5834 [1] NCCL INFO Channel 08/0 : 9[1] -> 0[0] [send] via NET/IBext/4(8)/GDRDMA
worker-0:5751:5834 [1] NCCL INFO Channel 01/0 : 9[1] -> 8[0] via P2P/CUMEM
worker-0:5751:5834 [1] NCCL INFO Channel 02/0 : 9[1] -> 8[0] via P2P/CUMEM
worker-0:5751:5834 [1] NCCL INFO Channel 03/0 : 9[1] -> 8[0] via P2P/CUMEM
worker-0:5751:5834 [1] NCCL INFO Channel 04/0 : 9[1] -> 8[0] via P2P/CUMEM
worker-0:5751:5834 [1] NCCL INFO Channel 05/0 : 9[1] -> 8[0] via P2P/CUMEM
worker-0:5751:5834 [1] NCCL INFO Channel 06/0 : 9[1] -> 8[0] via P2P/CUMEM
worker-0:5751:5834 [1] NCCL INFO Channel 07/0 : 9[1] -> 8[0] via P2P/CUMEM
worker-0:5751:5834 [1] NCCL INFO Channel 09/0 : 9[1] -> 8[0] via P2P/CUMEM
worker-0:5751:5834 [1] NCCL INFO Channel 10/0 : 9[1] -> 8[0] via P2P/CUMEM
worker-0:5751:5834 [1] NCCL INFO Channel 11/0 : 9[1] -> 8[0] via P2P/CUMEM
worker-0:5751:5834 [1] NCCL INFO Channel 12/0 : 9[1] -> 8[0] via P2P/CUMEM
worker-1:5780:5780 [2] NCCL INFO cudaDriverVersion 12030
worker-1:5780:5780 [2] NCCL INFO Bootstrap : Using eth0:10.113.5.242<0>
worker-1:5780:5780 [2] NCCL INFO NET/Plugin: Failed to find ncclNetPlugin_v7 symbol.
worker-1:5780:5780 [2] NCCL INFO NET/Plugin: Loaded net plugin NCCL RDMA Plugin v6 (v6)
worker-1:5780:5780 [2] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v7 symbol.
worker-1:5780:5780 [2] NCCL INFO NET/Plugin: Loaded coll plugin SHARP (v6)
worker-1:5780:5867 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
worker-1:5780:5867 [2] NCCL INFO P2P plugin IBext
worker-1:5780:5867 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_1:1/IB/SHARP [2]mlx5_2:1/IB/SHARP [3]mlx5_3:1/IB/SHARP [4]mlx5_4:1/IB/SHARP [5]mlx5_5:1/IB/SHARP [6]mlx5_6:1/IB/SHARP [7]mlx5_7:1/IB/SHARP [RO]; OOB eth0:10.113.5.242<0>
worker-1:5780:5867 [2] NCCL INFO Using non-device net plugin version 0
worker-1:5780:5867 [2] NCCL INFO Using network IBext
worker-0:5751:5834 [1] NCCL INFO Channel 13/0 : 9[1] -> 8[0] via P2P/CUMEM
worker-0:5751:5834 [1] NCCL INFO Channel 14/0 : 9[1] -> 8[0] via P2P/CUMEM
worker-0:5751:5834 [1] NCCL INFO Channel 15/0 : 9[1] -> 8[0] via P2P/CUMEM
worker-0:5751:5834 [1] NCCL INFO Connected all rings
worker-0:5751:5834 [1] NCCL INFO Channel 00/0 : 9[1] -> 10[2] via P2P/CUMEM
worker-0:5751:5834 [1] NCCL INFO Channel 01/0 : 9[1] -> 10[2] via P2P/CUMEM
worker-0:5751:5834 [1] NCCL INFO Channel 03/0 : 9[1] -> 10[2] via P2P/CUMEM
worker-0:5751:5834 [1] NCCL INFO Channel 04/0 : 9[1] -> 10[2] via P2P/CUMEM
worker-0:5751:5834 [1] NCCL INFO Channel 05/0 : 9[1] -> 10[2] via P2P/CUMEM
worker-0:5751:5834 [1] NCCL INFO Channel 06/0 : 9[1] -> 10[2] via P2P/CUMEM
worker-0:5751:5834 [1] NCCL INFO Channel 07/0 : 9[1] -> 10[2] via P2P/CUMEM
worker-0:5751:5834 [1] NCCL INFO Channel 08/0 : 9[1] -> 10[2] via P2P/CUMEM
worker-0:5751:5834 [1] NCCL INFO Channel 09/0 : 9[1] -> 10[2] via P2P/CUMEM
worker-1:5780:5867 [2] NCCL INFO comm 0x558b9d3cada0 rank 2 nranks 16 cudaDev 2 nvmlDev 2 busId 95000 commId 0xfd5d9e8febee040d - Init START
worker-1:5780:5867 [2] NCCL INFO NCCL_TOPO_FILE set by environment to /var/run/nvidia-topologyd/virtualTopology.xml
worker-1:5780:5867 [2] NCCL INFO Setting affinity for GPU 2 to 04
worker-1:5780:5867 [2] NCCL INFO NVLS multicast support is available on dev 2
worker-1:5780:5867 [2] NCCL INFO NVLS Head  0:  0  8
worker-1:5780:5867 [2] NCCL INFO NVLS Head  1:  1  9
worker-1:5780:5867 [2] NCCL INFO NVLS Head  2:  2 10
worker-1:5780:5867 [2] NCCL INFO NVLS Head  3:  3 11
worker-1:5780:5867 [2] NCCL INFO NVLS Head  4:  4 12
worker-1:5780:5867 [2] NCCL INFO NVLS Head  5:  5 13
worker-1:5780:5867 [2] NCCL INFO NVLS Head  6:  6 14
worker-1:5780:5867 [2] NCCL INFO NVLS Head  7:  7 15
worker-0:5751:5834 [1] NCCL INFO Channel 11/0 : 9[1] -> 10[2] via P2P/CUMEM
worker-1:5780:5867 [2] NCCL INFO Trees [0] 3/-1/-1->2->1 [1] 3/-1/-1->2->1 [2] 3/10/-1->2->-1 [3] -1/-1/-1->2->1 [4] 3/-1/-1->2->1 [5] 3/-1/-1->2->1 [6] 3/-1/-1->2->1 [7] 3/-1/-1->2->1 [8] 3/-1/-1->2->1 [9] 3/-1/-1->2->1 [10] 3/-1/-1->2->10 [11] -1/-1/-1->2->1 [12] 3/-1/-1->2->1 [13] 3/-1/-1->2->1 [14] 3/-1/-1->2->1 [15] 3/-1/-1->2->1
worker-1:5780:5867 [2] NCCL INFO P2P Chunksize set to 131072
worker-1:5780:5867 [2] NCCL INFO Channel 02/0 : 11[3] -> 2[2] [receive] via NET/IBext/6/GDRDMA
worker-1:5780:5867 [2] NCCL INFO Channel 10/0 : 11[3] -> 2[2] [receive] via NET/IBext/6/GDRDMA
worker-1:5780:5867 [2] NCCL INFO Channel 01/0 : 2[2] -> 9[1] [send] via NET/IBext/5(1)/GDRDMA
worker-1:5780:5867 [2] NCCL INFO Channel 09/0 : 2[2] -> 9[1] [send] via NET/IBext/5(1)/GDRDMA
worker-1:5780:5867 [2] NCCL INFO Channel 00/0 : 2[2] -> 1[1] via P2P/CUMEM
worker-1:5780:5867 [2] NCCL INFO Channel 02/0 : 2[2] -> 1[1] via P2P/CUMEM
worker-1:5780:5867 [2] NCCL INFO Channel 03/0 : 2[2] -> 1[1] via P2P/CUMEM
worker-0:5752:5752 [3] NCCL INFO cudaDriverVersion 12030
worker-0:5752:5752 [3] NCCL INFO Bootstrap : Using eth0:10.113.4.37<0>
worker-0:5752:5752 [3] NCCL INFO NET/Plugin: Failed to find ncclNetPlugin_v7 symbol.
worker-0:5752:5752 [3] NCCL INFO NET/Plugin: Loaded net plugin NCCL RDMA Plugin v6 (v6)
worker-0:5752:5752 [3] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v7 symbol.
worker-0:5752:5752 [3] NCCL INFO NET/Plugin: Loaded coll plugin SHARP (v6)
worker-0:5752:5835 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
worker-0:5752:5835 [3] NCCL INFO P2P plugin IBext
worker-0:5752:5835 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_1:1/IB/SHARP [2]mlx5_2:1/IB/SHARP [3]mlx5_3:1/IB/SHARP [4]mlx5_4:1/IB/SHARP [5]mlx5_5:1/IB/SHARP [6]mlx5_6:1/IB/SHARP [7]mlx5_7:1/IB/SHARP [RO]; OOB eth0:10.113.4.37<0>
worker-0:5752:5835 [3] NCCL INFO Using non-device net plugin version 0
worker-0:5752:5835 [3] NCCL INFO Using network IBext
worker-1:5780:5867 [2] NCCL INFO Channel 04/0 : 2[2] -> 1[1] via P2P/CUMEM
worker-1:5780:5867 [2] NCCL INFO Channel 05/0 : 2[2] -> 1[1] via P2P/CUMEM
worker-1:5780:5867 [2] NCCL INFO Channel 06/0 : 2[2] -> 1[1] via P2P/CUMEM
worker-1:5780:5867 [2] NCCL INFO Channel 07/0 : 2[2] -> 1[1] via P2P/CUMEM
worker-1:5780:5867 [2] NCCL INFO Channel 08/0 : 2[2] -> 1[1] via P2P/CUMEM
worker-1:5780:5867 [2] NCCL INFO Channel 10/0 : 2[2] -> 1[1] via P2P/CUMEM
worker-1:5780:5867 [2] NCCL INFO Channel 11/0 : 2[2] -> 1[1] via P2P/CUMEM
worker-1:5780:5867 [2] NCCL INFO Channel 12/0 : 2[2] -> 1[1] via P2P/CUMEM
worker-1:5780:5867 [2] NCCL INFO Channel 13/0 : 2[2] -> 1[1] via P2P/CUMEM
worker-1:5780:5867 [2] NCCL INFO Channel 14/0 : 2[2] -> 1[1] via P2P/CUMEM
worker-1:5780:5867 [2] NCCL INFO Channel 15/0 : 2[2] -> 1[1] via P2P/CUMEM
worker-1:5780:5867 [2] NCCL INFO Connected all rings
worker-1:5780:5867 [2] NCCL INFO Channel 00/0 : 2[2] -> 3[3] via P2P/CUMEM
worker-0:5752:5835 [3] NCCL INFO comm 0x55af9c131630 rank 11 nranks 16 cudaDev 3 nvmlDev 3 busId 99000 commId 0xfd5d9e8febee040d - Init START
worker-0:5752:5835 [3] NCCL INFO NCCL_TOPO_FILE set by environment to /var/run/nvidia-topologyd/virtualTopology.xml
worker-0:5752:5835 [3] NCCL INFO Setting affinity for GPU 3 to 08
worker-0:5752:5835 [3] NCCL INFO NVLS multicast support is available on dev 3
worker-0:5752:5835 [3] NCCL INFO Trees [0] 12/-1/-1->11->10 [1] 12/-1/-1->11->10 [2] 12/-1/-1->11->10 [3] 12/-1/-1->11->3 [4] -1/-1/-1->11->10 [5] 12/-1/-1->11->10 [6] 12/-1/-1->11->10 [7] 12/-1/-1->11->10 [8] 12/-1/-1->11->10 [9] 12/-1/-1->11->10 [10] 12/-1/-1->11->10 [11] 12/3/-1->11->-1 [12] -1/-1/-1->11->10 [13] 12/-1/-1->11->10 [14] 12/-1/-1->11->10 [15] 12/-1/-1->11->10
worker-0:5752:5835 [3] NCCL INFO P2P Chunksize set to 131072
worker-0:5752:5835 [3] NCCL INFO Channel 03/0 : 4[4] -> 11[3] [receive] via NET/IBext/7/GDRDMA
worker-1:5780:5867 [2] NCCL INFO Channel 01/0 : 2[2] -> 3[3] via P2P/CUMEM
worker-1:5780:5867 [2] NCCL INFO Channel 02/0 : 2[2] -> 3[3] via P2P/CUMEM
worker-1:5780:5867 [2] NCCL INFO Channel 04/0 : 2[2] -> 3[3] via P2P/CUMEM
worker-1:5780:5867 [2] NCCL INFO Channel 05/0 : 2[2] -> 3[3] via P2P/CUMEM
worker-0:5752:5835 [3] NCCL INFO Channel 11/0 : 4[4] -> 11[3] [receive] via NET/IBext/7/GDRDMA
worker-0:5752:5835 [3] NCCL INFO Channel 02/0 : 11[3] -> 2[2] [send] via NET/IBext/6(10)/GDRDMA
worker-0:5752:5835 [3] NCCL INFO Channel 10/0 : 11[3] -> 2[2] [send] via NET/IBext/6(10)/GDRDMA
worker-0:5752:5835 [3] NCCL INFO Channel 00/0 : 11[3] -> 10[2] via P2P/CUMEM
worker-0:5752:5835 [3] NCCL INFO Channel 01/0 : 11[3] -> 10[2] via P2P/CUMEM
worker-0:5752:5835 [3] NCCL INFO Channel 03/0 : 11[3] -> 10[2] via P2P/CUMEM
worker-0:5752:5835 [3] NCCL INFO Channel 04/0 : 11[3] -> 10[2] via P2P/CUMEM
worker-0:5752:5835 [3] NCCL INFO Channel 05/0 : 11[3] -> 10[2] via P2P/CUMEM
worker-0:5752:5835 [3] NCCL INFO Channel 06/0 : 11[3] -> 10[2] via P2P/CUMEM
worker-0:5752:5835 [3] NCCL INFO Channel 07/0 : 11[3] -> 10[2] via P2P/CUMEM
worker-0:5752:5835 [3] NCCL INFO Channel 08/0 : 11[3] -> 10[2] via P2P/CUMEM
worker-0:5752:5835 [3] NCCL INFO Channel 09/0 : 11[3] -> 10[2] via P2P/CUMEM
worker-1:5778:5778 [3] NCCL INFO cudaDriverVersion 12030
worker-1:5778:5778 [3] NCCL INFO Bootstrap : Using eth0:10.113.5.242<0>
worker-1:5778:5778 [3] NCCL INFO NET/Plugin: Failed to find ncclNetPlugin_v7 symbol.
worker-1:5778:5778 [3] NCCL INFO NET/Plugin: Loaded net plugin NCCL RDMA Plugin v6 (v6)
worker-1:5778:5778 [3] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v7 symbol.
worker-1:5778:5778 [3] NCCL INFO NET/Plugin: Loaded coll plugin SHARP (v6)
worker-1:5778:5868 [3] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
worker-1:5778:5868 [3] NCCL INFO P2P plugin IBext
worker-1:5778:5868 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_1:1/IB/SHARP [2]mlx5_2:1/IB/SHARP [3]mlx5_3:1/IB/SHARP [4]mlx5_4:1/IB/SHARP [5]mlx5_5:1/IB/SHARP [6]mlx5_6:1/IB/SHARP [7]mlx5_7:1/IB/SHARP [RO]; OOB eth0:10.113.5.242<0>
worker-1:5778:5868 [3] NCCL INFO Using non-device net plugin version 0
worker-1:5778:5868 [3] NCCL INFO Using network IBext
worker-0:5752:5835 [3] NCCL INFO Channel 11/0 : 11[3] -> 10[2] via P2P/CUMEM
worker-0:5752:5835 [3] NCCL INFO Channel 12/0 : 11[3] -> 10[2] via P2P/CUMEM
worker-0:5752:5835 [3] NCCL INFO Channel 13/0 : 11[3] -> 10[2] via P2P/CUMEM
worker-0:5752:5835 [3] NCCL INFO Channel 14/0 : 11[3] -> 10[2] via P2P/CUMEM
worker-0:5752:5835 [3] NCCL INFO Channel 15/0 : 11[3] -> 10[2] via P2P/CUMEM
worker-0:5752:5835 [3] NCCL INFO Connected all rings
worker-0:5752:5835 [3] NCCL INFO Channel 00/0 : 11[3] -> 12[4] via P2P/CUMEM
worker-0:5752:5835 [3] NCCL INFO Channel 01/0 : 11[3] -> 12[4] via P2P/CUMEM
worker-0:5752:5835 [3] NCCL INFO Channel 02/0 : 11[3] -> 12[4] via P2P/CUMEM
worker-0:5752:5835 [3] NCCL INFO Channel 03/0 : 11[3] -> 12[4] via P2P/CUMEM
worker-0:5752:5835 [3] NCCL INFO Channel 05/0 : 11[3] -> 12[4] via P2P/CUMEM
worker-0:5752:5835 [3] NCCL INFO Channel 06/0 : 11[3] -> 12[4] via P2P/CUMEM
worker-0:5752:5835 [3] NCCL INFO Channel 07/0 : 11[3] -> 12[4] via P2P/CUMEM
worker-1:5778:5868 [3] NCCL INFO comm 0x557bfad72dd0 rank 3 nranks 16 cudaDev 3 nvmlDev 3 busId 99000 commId 0xfd5d9e8febee040d - Init START
worker-1:5778:5868 [3] NCCL INFO NCCL_TOPO_FILE set by environment to /var/run/nvidia-topologyd/virtualTopology.xml
worker-1:5778:5868 [3] NCCL INFO Setting affinity for GPU 3 to 08
worker-1:5778:5868 [3] NCCL INFO NVLS multicast support is available on dev 3
worker-1:5778:5868 [3] NCCL INFO NVLS Head  0:  0  8
worker-1:5778:5868 [3] NCCL INFO NVLS Head  1:  1  9
worker-1:5778:5868 [3] NCCL INFO NVLS Head  2:  2 10
worker-1:5778:5868 [3] NCCL INFO NVLS Head  3:  3 11
worker-1:5778:5868 [3] NCCL INFO NVLS Head  4:  4 12
worker-1:5778:5868 [3] NCCL INFO NVLS Head  5:  5 13
worker-1:5778:5868 [3] NCCL INFO NVLS Head  6:  6 14
worker-1:5778:5868 [3] NCCL INFO NVLS Head  7:  7 15
worker-0:5752:5835 [3] NCCL INFO Channel 08/0 : 11[3] -> 12[4] via P2P/CUMEM
worker-0:5752:5835 [3] NCCL INFO Channel 09/0 : 11[3] -> 12[4] via P2P/CUMEM
worker-1:5778:5868 [3] NCCL INFO Trees [0] 4/-1/-1->3->2 [1] 4/-1/-1->3->2 [2] 4/-1/-1->3->2 [3] 4/11/-1->3->-1 [4] -1/-1/-1->3->2 [5] 4/-1/-1->3->2 [6] 4/-1/-1->3->2 [7] 4/-1/-1->3->2 [8] 4/-1/-1->3->2 [9] 4/-1/-1->3->2 [10] 4/-1/-1->3->2 [11] 4/-1/-1->3->11 [12] -1/-1/-1->3->2 [13] 4/-1/-1->3->2 [14] 4/-1/-1->3->2 [15] 4/-1/-1->3->2
worker-1:5778:5868 [3] NCCL INFO P2P Chunksize set to 131072
worker-1:5778:5868 [3] NCCL INFO Channel 03/0 : 12[4] -> 3[3] [receive] via NET/IBext/7/GDRDMA
worker-1:5778:5868 [3] NCCL INFO Channel 11/0 : 12[4] -> 3[3] [receive] via NET/IBext/7/GDRDMA
worker-1:5778:5868 [3] NCCL INFO Channel 02/0 : 3[3] -> 10[2] [send] via NET/IBext/6(2)/GDRDMA
worker-1:5778:5868 [3] NCCL INFO Channel 10/0 : 3[3] -> 10[2] [send] via NET/IBext/6(2)/GDRDMA
worker-1:5778:5868 [3] NCCL INFO Channel 00/0 : 3[3] -> 2[2] via P2P/CUMEM
worker-1:5778:5868 [3] NCCL INFO Channel 01/0 : 3[3] -> 2[2] via P2P/CUMEM
worker-1:5778:5868 [3] NCCL INFO Channel 03/0 : 3[3] -> 2[2] via P2P/CUMEM
worker-0:5745:5745 [0] NCCL INFO cudaDriverVersion 12030
worker-0:5745:5745 [0] NCCL INFO Bootstrap : Using eth0:10.113.4.37<0>
worker-0:5745:5745 [0] NCCL INFO NET/Plugin: Failed to find ncclNetPlugin_v7 symbol.
worker-0:5745:5745 [0] NCCL INFO NET/Plugin: Loaded net plugin NCCL RDMA Plugin v6 (v6)
worker-0:5745:5745 [0] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v7 symbol.
worker-0:5745:5745 [0] NCCL INFO NET/Plugin: Loaded coll plugin SHARP (v6)
worker-0:5745:5832 [0] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
worker-0:5745:5832 [0] NCCL INFO P2P plugin IBext
worker-0:5745:5832 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_1:1/IB/SHARP [2]mlx5_2:1/IB/SHARP [3]mlx5_3:1/IB/SHARP [4]mlx5_4:1/IB/SHARP [5]mlx5_5:1/IB/SHARP [6]mlx5_6:1/IB/SHARP [7]mlx5_7:1/IB/SHARP [RO]; OOB eth0:10.113.4.37<0>
worker-0:5745:5832 [0] NCCL INFO Using non-device net plugin version 0
worker-0:5745:5832 [0] NCCL INFO Using network IBext
worker-1:5778:5868 [3] NCCL INFO Channel 04/0 : 3[3] -> 2[2] via P2P/CUMEM
worker-1:5778:5868 [3] NCCL INFO Channel 05/0 : 3[3] -> 2[2] via P2P/CUMEM
worker-1:5778:5868 [3] NCCL INFO Channel 06/0 : 3[3] -> 2[2] via P2P/CUMEM
worker-1:5778:5868 [3] NCCL INFO Channel 07/0 : 3[3] -> 2[2] via P2P/CUMEM
worker-1:5778:5868 [3] NCCL INFO Channel 08/0 : 3[3] -> 2[2] via P2P/CUMEM
worker-1:5778:5868 [3] NCCL INFO Channel 09/0 : 3[3] -> 2[2] via P2P/CUMEM
worker-1:5778:5868 [3] NCCL INFO Channel 11/0 : 3[3] -> 2[2] via P2P/CUMEM
worker-1:5778:5868 [3] NCCL INFO Channel 12/0 : 3[3] -> 2[2] via P2P/CUMEM
worker-1:5778:5868 [3] NCCL INFO Channel 13/0 : 3[3] -> 2[2] via P2P/CUMEM
worker-1:5778:5868 [3] NCCL INFO Channel 14/0 : 3[3] -> 2[2] via P2P/CUMEM
worker-1:5778:5868 [3] NCCL INFO Channel 15/0 : 3[3] -> 2[2] via P2P/CUMEM
worker-1:5778:5868 [3] NCCL INFO Connected all rings
worker-1:5778:5868 [3] NCCL INFO Channel 00/0 : 3[3] -> 4[4] via P2P/CUMEM
worker-0:5745:5832 [0] NCCL INFO comm 0x55624bbca340 rank 8 nranks 16 cudaDev 0 nvmlDev 0 busId 8d000 commId 0xfd5d9e8febee040d - Init START
worker-0:5745:5832 [0] NCCL INFO NCCL_TOPO_FILE set by environment to /var/run/nvidia-topologyd/virtualTopology.xml
worker-0:5745:5832 [0] NCCL INFO Setting affinity for GPU 0 to 01
worker-0:5745:5832 [0] NCCL INFO NVLS multicast support is available on dev 0
worker-0:5745:5832 [0] NCCL INFO Trees [0] 9/-1/-1->8->0 [1] -1/-1/-1->8->15 [2] 9/-1/-1->8->15 [3] 9/-1/-1->8->15 [4] 9/-1/-1->8->15 [5] 9/-1/-1->8->15 [6] 9/-1/-1->8->15 [7] 9/-1/-1->8->15 [8] 9/0/-1->8->-1 [9] -1/-1/-1->8->15 [10] 9/-1/-1->8->15 [11] 9/-1/-1->8->15 [12] 9/-1/-1->8->15 [13] 9/-1/-1->8->15 [14] 9/-1/-1->8->15 [15] 9/-1/-1->8->15
worker-0:5745:5832 [0] NCCL INFO P2P Chunksize set to 131072
worker-0:5745:5832 [0] NCCL INFO Channel 00/0 : 1[1] -> 8[0] [receive] via NET/IBext/4/GDRDMA
worker-0:5745:5832 [0] NCCL INFO Channel 08/0 : 1[1] -> 8[0] [receive] via NET/IBext/4/GDRDMA
worker-1:5778:5868 [3] NCCL INFO Channel 01/0 : 3[3] -> 4[4] via P2P/CUMEM
worker-1:5778:5868 [3] NCCL INFO Channel 02/0 : 3[3] -> 4[4] via P2P/CUMEM
worker-1:5778:5868 [3] NCCL INFO Channel 03/0 : 3[3] -> 4[4] via P2P/CUMEM
worker-1:5778:5868 [3] NCCL INFO Channel 05/0 : 3[3] -> 4[4] via P2P/CUMEM
worker-0:5745:5832 [0] NCCL INFO Channel 00/0 : 8[0] -> 15[7] via P2P/CUMEM
worker-0:5745:5832 [0] NCCL INFO Channel 01/0 : 8[0] -> 15[7] via P2P/CUMEM
worker-0:5745:5832 [0] NCCL INFO Channel 02/0 : 8[0] -> 15[7] via P2P/CUMEM
worker-0:5745:5832 [0] NCCL INFO Channel 03/0 : 8[0] -> 15[7] via P2P/CUMEM
worker-0:5745:5832 [0] NCCL INFO Channel 04/0 : 8[0] -> 15[7] via P2P/CUMEM
worker-0:5745:5832 [0] NCCL INFO Channel 05/0 : 8[0] -> 15[7] via P2P/CUMEM
worker-0:5745:5832 [0] NCCL INFO Channel 06/0 : 8[0] -> 15[7] via P2P/CUMEM
worker-0:5745:5832 [0] NCCL INFO Channel 08/0 : 8[0] -> 15[7] via P2P/CUMEM
worker-0:5745:5832 [0] NCCL INFO Channel 09/0 : 8[0] -> 15[7] via P2P/CUMEM
worker-0:5745:5832 [0] NCCL INFO Channel 10/0 : 8[0] -> 15[7] via P2P/CUMEM
worker-0:5745:5832 [0] NCCL INFO Channel 11/0 : 8[0] -> 15[7] via P2P/CUMEM
worker-0:5745:5832 [0] NCCL INFO Channel 12/0 : 8[0] -> 15[7] via P2P/CUMEM
worker-0:5745:5832 [0] NCCL INFO Channel 13/0 : 8[0] -> 15[7] via P2P/CUMEM
worker-1:5789:5789 [6] NCCL INFO cudaDriverVersion 12030
worker-1:5789:5789 [6] NCCL INFO Bootstrap : Using eth0:10.113.5.242<0>
worker-1:5789:5789 [6] NCCL INFO NET/Plugin: Failed to find ncclNetPlugin_v7 symbol.
worker-1:5789:5789 [6] NCCL INFO NET/Plugin: Loaded net plugin NCCL RDMA Plugin v6 (v6)
worker-1:5789:5789 [6] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v7 symbol.
worker-1:5789:5789 [6] NCCL INFO NET/Plugin: Loaded coll plugin SHARP (v6)
worker-1:5789:5869 [6] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
worker-1:5789:5869 [6] NCCL INFO P2P plugin IBext
worker-1:5789:5869 [6] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_1:1/IB/SHARP [2]mlx5_2:1/IB/SHARP [3]mlx5_3:1/IB/SHARP [4]mlx5_4:1/IB/SHARP [5]mlx5_5:1/IB/SHARP [6]mlx5_6:1/IB/SHARP [7]mlx5_7:1/IB/SHARP [RO]; OOB eth0:10.113.5.242<0>
worker-1:5789:5869 [6] NCCL INFO Using non-device net plugin version 0
worker-1:5789:5869 [6] NCCL INFO Using network IBext
worker-0:5745:5832 [0] NCCL INFO Channel 14/0 : 8[0] -> 15[7] via P2P/CUMEM
worker-0:5745:5832 [0] NCCL INFO Channel 07/0 : 8[0] -> 7[7] [send] via NET/IBext/3(15)/GDRDMA
worker-0:5745:5832 [0] NCCL INFO Channel 15/0 : 8[0] -> 7[7] [send] via NET/IBext/3(15)/GDRDMA
worker-0:5745:5832 [0] NCCL INFO Connected all rings
worker-0:5745:5832 [0] NCCL INFO Channel 00/0 : 8[0] -> 9[1] via P2P/CUMEM
worker-0:5745:5832 [0] NCCL INFO Channel 02/0 : 8[0] -> 9[1] via P2P/CUMEM
worker-0:5745:5832 [0] NCCL INFO Channel 03/0 : 8[0] -> 9[1] via P2P/CUMEM
worker-0:5745:5832 [0] NCCL INFO Channel 04/0 : 8[0] -> 9[1] via P2P/CUMEM
worker-0:5745:5832 [0] NCCL INFO Channel 05/0 : 8[0] -> 9[1] via P2P/CUMEM
worker-0:5745:5832 [0] NCCL INFO Channel 06/0 : 8[0] -> 9[1] via P2P/CUMEM
worker-0:5745:5832 [0] NCCL INFO Channel 07/0 : 8[0] -> 9[1] via P2P/CUMEM
worker-0:5745:5832 [0] NCCL INFO Channel 08/0 : 8[0] -> 9[1] via P2P/CUMEM
worker-0:5745:5832 [0] NCCL INFO Channel 10/0 : 8[0] -> 9[1] via P2P/CUMEM
worker-1:5789:5869 [6] NCCL INFO comm 0x564f0897bdf0 rank 6 nranks 16 cudaDev 6 nvmlDev 6 busId b3000 commId 0xfd5d9e8febee040d - Init START
worker-1:5789:5869 [6] NCCL INFO NCCL_TOPO_FILE set by environment to /var/run/nvidia-topologyd/virtualTopology.xml
worker-1:5789:5869 [6] NCCL INFO NVLS multicast support is available on dev 6
worker-1:5789:5869 [6] NCCL INFO NVLS Head  0:  0  8
worker-1:5789:5869 [6] NCCL INFO NVLS Head  1:  1  9
worker-1:5789:5869 [6] NCCL INFO NVLS Head  2:  2 10
worker-1:5789:5869 [6] NCCL INFO NVLS Head  3:  3 11
worker-1:5789:5869 [6] NCCL INFO NVLS Head  4:  4 12
worker-1:5789:5869 [6] NCCL INFO NVLS Head  5:  5 13
worker-1:5789:5869 [6] NCCL INFO NVLS Head  6:  6 14
worker-1:5789:5869 [6] NCCL INFO NVLS Head  7:  7 15
worker-0:5745:5832 [0] NCCL INFO Channel 11/0 : 8[0] -> 9[1] via P2P/CUMEM
worker-1:5789:5869 [6] NCCL INFO Trees [0] 7/-1/-1->6->5 [1] 7/-1/-1->6->5 [2] 7/-1/-1->6->5 [3] 7/-1/-1->6->5 [4] 7/-1/-1->6->5 [5] 7/-1/-1->6->5 [6] 7/14/-1->6->-1 [7] -1/-1/-1->6->5 [8] 7/-1/-1->6->5 [9] 7/-1/-1->6->5 [10] 7/-1/-1->6->5 [11] 7/-1/-1->6->5 [12] 7/-1/-1->6->5 [13] 7/-1/-1->6->5 [14] 7/-1/-1->6->14 [15] -1/-1/-1->6->5
worker-1:5789:5869 [6] NCCL INFO P2P Chunksize set to 131072
worker-1:5789:5869 [6] NCCL INFO Channel 06/0 : 15[7] -> 6[6] [receive] via NET/IBext/2/GDRDMA
worker-1:5789:5869 [6] NCCL INFO Channel 14/0 : 15[7] -> 6[6] [receive] via NET/IBext/2/GDRDMA
worker-1:5789:5869 [6] NCCL INFO Channel 05/0 : 6[6] -> 13[5] [send] via NET/IBext/1(5)/GDRDMA
worker-1:5789:5869 [6] NCCL INFO Channel 13/0 : 6[6] -> 13[5] [send] via NET/IBext/1(5)/GDRDMA
worker-1:5789:5869 [6] NCCL INFO Channel 00/0 : 6[6] -> 5[5] via P2P/CUMEM
worker-1:5789:5869 [6] NCCL INFO Channel 01/0 : 6[6] -> 5[5] via P2P/CUMEM
worker-1:5789:5869 [6] NCCL INFO Channel 02/0 : 6[6] -> 5[5] via P2P/CUMEM
worker-0:5741:5741 [2] NCCL INFO cudaDriverVersion 12030
worker-0:5741:5741 [2] NCCL INFO Bootstrap : Using eth0:10.113.4.37<0>
worker-0:5741:5741 [2] NCCL INFO NET/Plugin: Failed to find ncclNetPlugin_v7 symbol.
worker-0:5741:5741 [2] NCCL INFO NET/Plugin: Loaded net plugin NCCL RDMA Plugin v6 (v6)
worker-0:5741:5741 [2] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v7 symbol.
worker-0:5741:5741 [2] NCCL INFO NET/Plugin: Loaded coll plugin SHARP (v6)
worker-0:5741:5830 [2] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
worker-0:5741:5830 [2] NCCL INFO P2P plugin IBext
worker-0:5741:5830 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_1:1/IB/SHARP [2]mlx5_2:1/IB/SHARP [3]mlx5_3:1/IB/SHARP [4]mlx5_4:1/IB/SHARP [5]mlx5_5:1/IB/SHARP [6]mlx5_6:1/IB/SHARP [7]mlx5_7:1/IB/SHARP [RO]; OOB eth0:10.113.4.37<0>
worker-0:5741:5830 [2] NCCL INFO Using non-device net plugin version 0
worker-0:5741:5830 [2] NCCL INFO Using network IBext
worker-1:5789:5869 [6] NCCL INFO Channel 03/0 : 6[6] -> 5[5] via P2P/CUMEM
worker-1:5789:5869 [6] NCCL INFO Channel 04/0 : 6[6] -> 5[5] via P2P/CUMEM
worker-1:5789:5869 [6] NCCL INFO Channel 06/0 : 6[6] -> 5[5] via P2P/CUMEM
worker-1:5789:5869 [6] NCCL INFO Channel 07/0 : 6[6] -> 5[5] via P2P/CUMEM
worker-1:5789:5869 [6] NCCL INFO Channel 08/0 : 6[6] -> 5[5] via P2P/CUMEM
worker-1:5789:5869 [6] NCCL INFO Channel 09/0 : 6[6] -> 5[5] via P2P/CUMEM
worker-1:5789:5869 [6] NCCL INFO Channel 10/0 : 6[6] -> 5[5] via P2P/CUMEM
worker-1:5789:5869 [6] NCCL INFO Channel 11/0 : 6[6] -> 5[5] via P2P/CUMEM
worker-1:5789:5869 [6] NCCL INFO Channel 12/0 : 6[6] -> 5[5] via P2P/CUMEM
worker-1:5789:5869 [6] NCCL INFO Channel 14/0 : 6[6] -> 5[5] via P2P/CUMEM
worker-1:5789:5869 [6] NCCL INFO Channel 15/0 : 6[6] -> 5[5] via P2P/CUMEM
worker-1:5789:5869 [6] NCCL INFO Connected all rings
worker-1:5789:5869 [6] NCCL INFO Channel 00/0 : 6[6] -> 7[7] via P2P/CUMEM
worker-0:5741:5830 [2] NCCL INFO comm 0x55cc16ec5ad0 rank 10 nranks 16 cudaDev 2 nvmlDev 2 busId 95000 commId 0xfd5d9e8febee040d - Init START
worker-0:5741:5830 [2] NCCL INFO NCCL_TOPO_FILE set by environment to /var/run/nvidia-topologyd/virtualTopology.xml
worker-0:5741:5830 [2] NCCL INFO Setting affinity for GPU 2 to 04
worker-0:5741:5830 [2] NCCL INFO NVLS multicast support is available on dev 2
worker-0:5741:5830 [2] NCCL INFO Trees [0] 11/-1/-1->10->9 [1] 11/-1/-1->10->9 [2] 11/-1/-1->10->2 [3] -1/-1/-1->10->9 [4] 11/-1/-1->10->9 [5] 11/-1/-1->10->9 [6] 11/-1/-1->10->9 [7] 11/-1/-1->10->9 [8] 11/-1/-1->10->9 [9] 11/-1/-1->10->9 [10] 11/2/-1->10->-1 [11] -1/-1/-1->10->9 [12] 11/-1/-1->10->9 [13] 11/-1/-1->10->9 [14] 11/-1/-1->10->9 [15] 11/-1/-1->10->9
worker-0:5741:5830 [2] NCCL INFO P2P Chunksize set to 131072
worker-0:5741:5830 [2] NCCL INFO Channel 02/0 : 3[3] -> 10[2] [receive] via NET/IBext/6/GDRDMA
worker-0:5741:5830 [2] NCCL INFO Channel 10/0 : 3[3] -> 10[2] [receive] via NET/IBext/6/GDRDMA
worker-1:5789:5869 [6] NCCL INFO Channel 01/0 : 6[6] -> 7[7] via P2P/CUMEM
worker-1:5789:5869 [6] NCCL INFO Channel 02/0 : 6[6] -> 7[7] via P2P/CUMEM
worker-1:5789:5869 [6] NCCL INFO Channel 03/0 : 6[6] -> 7[7] via P2P/CUMEM
worker-1:5789:5869 [6] NCCL INFO Channel 04/0 : 6[6] -> 7[7] via P2P/CUMEM
worker-1:5789:5869 [6] NCCL INFO Channel 05/0 : 6[6] -> 7[7] via P2P/CUMEM
worker-0:5741:5830 [2] NCCL INFO Channel 01/0 : 10[2] -> 1[1] [send] via NET/IBext/5(9)/GDRDMA
worker-0:5741:5830 [2] NCCL INFO Channel 09/0 : 10[2] -> 1[1] [send] via NET/IBext/5(9)/GDRDMA
worker-0:5741:5830 [2] NCCL INFO Channel 00/0 : 10[2] -> 9[1] via P2P/CUMEM
worker-0:5741:5830 [2] NCCL INFO Channel 02/0 : 10[2] -> 9[1] via P2P/CUMEM
worker-0:5741:5830 [2] NCCL INFO Channel 03/0 : 10[2] -> 9[1] via P2P/CUMEM
worker-0:5741:5830 [2] NCCL INFO Channel 04/0 : 10[2] -> 9[1] via P2P/CUMEM
worker-0:5741:5830 [2] NCCL INFO Channel 05/0 : 10[2] -> 9[1] via P2P/CUMEM
worker-0:5741:5830 [2] NCCL INFO Channel 06/0 : 10[2] -> 9[1] via P2P/CUMEM
worker-0:5741:5830 [2] NCCL INFO Channel 07/0 : 10[2] -> 9[1] via P2P/CUMEM
worker-0:5741:5830 [2] NCCL INFO Channel 08/0 : 10[2] -> 9[1] via P2P/CUMEM
worker-0:5741:5830 [2] NCCL INFO Channel 10/0 : 10[2] -> 9[1] via P2P/CUMEM
worker-0:5741:5830 [2] NCCL INFO Channel 11/0 : 10[2] -> 9[1] via P2P/CUMEM
worker-1:5782:5782 [4] NCCL INFO cudaDriverVersion 12030
worker-1:5782:5782 [4] NCCL INFO Bootstrap : Using eth0:10.113.5.242<0>
worker-1:5782:5782 [4] NCCL INFO NET/Plugin: Failed to find ncclNetPlugin_v7 symbol.
worker-1:5782:5782 [4] NCCL INFO NET/Plugin: Loaded net plugin NCCL RDMA Plugin v6 (v6)
worker-1:5782:5782 [4] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v7 symbol.
worker-1:5782:5782 [4] NCCL INFO NET/Plugin: Loaded coll plugin SHARP (v6)
worker-1:5782:5866 [4] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
worker-1:5782:5866 [4] NCCL INFO P2P plugin IBext
worker-1:5782:5866 [4] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_1:1/IB/SHARP [2]mlx5_2:1/IB/SHARP [3]mlx5_3:1/IB/SHARP [4]mlx5_4:1/IB/SHARP [5]mlx5_5:1/IB/SHARP [6]mlx5_6:1/IB/SHARP [7]mlx5_7:1/IB/SHARP [RO]; OOB eth0:10.113.5.242<0>
worker-1:5782:5866 [4] NCCL INFO Using non-device net plugin version 0
worker-1:5782:5866 [4] NCCL INFO Using network IBext
worker-0:5741:5830 [2] NCCL INFO Channel 12/0 : 10[2] -> 9[1] via P2P/CUMEM
worker-0:5741:5830 [2] NCCL INFO Channel 13/0 : 10[2] -> 9[1] via P2P/CUMEM
worker-0:5741:5830 [2] NCCL INFO Channel 14/0 : 10[2] -> 9[1] via P2P/CUMEM
worker-0:5741:5830 [2] NCCL INFO Channel 15/0 : 10[2] -> 9[1] via P2P/CUMEM
worker-0:5741:5830 [2] NCCL INFO Connected all rings
worker-0:5741:5830 [2] NCCL INFO Channel 00/0 : 10[2] -> 11[3] via P2P/CUMEM
worker-0:5741:5830 [2] NCCL INFO Channel 01/0 : 10[2] -> 11[3] via P2P/CUMEM
worker-0:5741:5830 [2] NCCL INFO Channel 02/0 : 10[2] -> 11[3] via P2P/CUMEM
worker-0:5741:5830 [2] NCCL INFO Channel 04/0 : 10[2] -> 11[3] via P2P/CUMEM
worker-0:5741:5830 [2] NCCL INFO Channel 05/0 : 10[2] -> 11[3] via P2P/CUMEM
worker-0:5741:5830 [2] NCCL INFO Channel 06/0 : 10[2] -> 11[3] via P2P/CUMEM
worker-0:5741:5830 [2] NCCL INFO Channel 07/0 : 10[2] -> 11[3] via P2P/CUMEM
worker-0:5741:5830 [2] NCCL INFO Channel 08/0 : 10[2] -> 11[3] via P2P/CUMEM
worker-1:5782:5866 [4] NCCL INFO comm 0x560f2e6b1fa0 rank 4 nranks 16 cudaDev 4 nvmlDev 4 busId ab000 commId 0xfd5d9e8febee040d - Init START
worker-1:5782:5866 [4] NCCL INFO NCCL_TOPO_FILE set by environment to /var/run/nvidia-topologyd/virtualTopology.xml
worker-1:5782:5866 [4] NCCL INFO NVLS multicast support is available on dev 4
worker-1:5782:5866 [4] NCCL INFO NVLS Head  0:  0  8
worker-1:5782:5866 [4] NCCL INFO NVLS Head  1:  1  9
worker-1:5782:5866 [4] NCCL INFO NVLS Head  2:  2 10
worker-1:5782:5866 [4] NCCL INFO NVLS Head  3:  3 11
worker-1:5782:5866 [4] NCCL INFO NVLS Head  4:  4 12
worker-1:5782:5866 [4] NCCL INFO NVLS Head  5:  5 13
worker-1:5782:5866 [4] NCCL INFO NVLS Head  6:  6 14
worker-1:5782:5866 [4] NCCL INFO NVLS Head  7:  7 15
worker-0:5741:5830 [2] NCCL INFO Channel 09/0 : 10[2] -> 11[3] via P2P/CUMEM
worker-0:5741:5830 [2] NCCL INFO Channel 10/0 : 10[2] -> 11[3] via P2P/CUMEM
worker-1:5782:5866 [4] NCCL INFO Trees [0] 5/-1/-1->4->3 [1] 5/-1/-1->4->3 [2] 5/-1/-1->4->3 [3] 5/-1/-1->4->3 [4] 5/12/-1->4->-1 [5] -1/-1/-1->4->3 [6] 5/-1/-1->4->3 [7] 5/-1/-1->4->3 [8] 5/-1/-1->4->3 [9] 5/-1/-1->4->3 [10] 5/-1/-1->4->3 [11] 5/-1/-1->4->3 [12] 5/-1/-1->4->12 [13] -1/-1/-1->4->3 [14] 5/-1/-1->4->3 [15] 5/-1/-1->4->3
worker-1:5782:5866 [4] NCCL INFO P2P Chunksize set to 131072
worker-1:5782:5866 [4] NCCL INFO Channel 04/0 : 13[5] -> 4[4] [receive] via NET/IBext/0/GDRDMA
worker-1:5782:5866 [4] NCCL INFO Channel 12/0 : 13[5] -> 4[4] [receive] via NET/IBext/0/GDRDMA
worker-1:5782:5866 [4] NCCL INFO Channel 03/0 : 4[4] -> 11[3] [send] via NET/IBext/7(3)/GDRDMA
worker-1:5782:5866 [4] NCCL INFO Channel 11/0 : 4[4] -> 11[3] [send] via NET/IBext/7(3)/GDRDMA
worker-1:5782:5866 [4] NCCL INFO Channel 00/0 : 4[4] -> 3[3] via P2P/CUMEM
worker-1:5782:5866 [4] NCCL INFO Channel 01/0 : 4[4] -> 3[3] via P2P/CUMEM
worker-1:5782:5866 [4] NCCL INFO Channel 02/0 : 4[4] -> 3[3] via P2P/CUMEM
worker-0:5760:5760 [5] NCCL INFO cudaDriverVersion 12030
worker-0:5760:5760 [5] NCCL INFO Bootstrap : Using eth0:10.113.4.37<0>
worker-0:5760:5760 [5] NCCL INFO NET/Plugin: Failed to find ncclNetPlugin_v7 symbol.
worker-0:5760:5760 [5] NCCL INFO NET/Plugin: Loaded net plugin NCCL RDMA Plugin v6 (v6)
worker-0:5760:5760 [5] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v7 symbol.
worker-0:5760:5760 [5] NCCL INFO NET/Plugin: Loaded coll plugin SHARP (v6)
worker-0:5760:5824 [5] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
worker-0:5760:5824 [5] NCCL INFO P2P plugin IBext
worker-0:5760:5824 [5] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_1:1/IB/SHARP [2]mlx5_2:1/IB/SHARP [3]mlx5_3:1/IB/SHARP [4]mlx5_4:1/IB/SHARP [5]mlx5_5:1/IB/SHARP [6]mlx5_6:1/IB/SHARP [7]mlx5_7:1/IB/SHARP [RO]; OOB eth0:10.113.4.37<0>
worker-0:5760:5824 [5] NCCL INFO Using non-device net plugin version 0
worker-0:5760:5824 [5] NCCL INFO Using network IBext
worker-1:5782:5866 [4] NCCL INFO Channel 04/0 : 4[4] -> 3[3] via P2P/CUMEM
worker-1:5782:5866 [4] NCCL INFO Channel 05/0 : 4[4] -> 3[3] via P2P/CUMEM
worker-1:5782:5866 [4] NCCL INFO Channel 06/0 : 4[4] -> 3[3] via P2P/CUMEM
worker-1:5782:5866 [4] NCCL INFO Channel 07/0 : 4[4] -> 3[3] via P2P/CUMEM
worker-1:5782:5866 [4] NCCL INFO Channel 08/0 : 4[4] -> 3[3] via P2P/CUMEM
worker-1:5782:5866 [4] NCCL INFO Channel 09/0 : 4[4] -> 3[3] via P2P/CUMEM
worker-1:5782:5866 [4] NCCL INFO Channel 10/0 : 4[4] -> 3[3] via P2P/CUMEM
worker-1:5782:5866 [4] NCCL INFO Channel 12/0 : 4[4] -> 3[3] via P2P/CUMEM
worker-1:5782:5866 [4] NCCL INFO Channel 13/0 : 4[4] -> 3[3] via P2P/CUMEM
worker-1:5782:5866 [4] NCCL INFO Channel 14/0 : 4[4] -> 3[3] via P2P/CUMEM
worker-1:5782:5866 [4] NCCL INFO Channel 15/0 : 4[4] -> 3[3] via P2P/CUMEM
worker-1:5782:5866 [4] NCCL INFO Connected all rings
worker-1:5782:5866 [4] NCCL INFO Channel 00/0 : 4[4] -> 5[5] via P2P/CUMEM
worker-0:5760:5824 [5] NCCL INFO comm 0x5606545756f0 rank 13 nranks 16 cudaDev 5 nvmlDev 5 busId af000 commId 0xfd5d9e8febee040d - Init START
worker-0:5760:5824 [5] NCCL INFO NCCL_TOPO_FILE set by environment to /var/run/nvidia-topologyd/virtualTopology.xml
worker-0:5760:5824 [5] NCCL INFO NVLS multicast support is available on dev 5
worker-0:5760:5824 [5] NCCL INFO Trees [0] 14/-1/-1->13->12 [1] 14/-1/-1->13->12 [2] 14/-1/-1->13->12 [3] 14/-1/-1->13->12 [4] 14/-1/-1->13->12 [5] 14/-1/-1->13->5 [6] -1/-1/-1->13->12 [7] 14/-1/-1->13->12 [8] 14/-1/-1->13->12 [9] 14/-1/-1->13->12 [10] 14/-1/-1->13->12 [11] 14/-1/-1->13->12 [12] 14/-1/-1->13->12 [13] 14/5/-1->13->-1 [14] -1/-1/-1->13->12 [15] 14/-1/-1->13->12
worker-0:5760:5824 [5] NCCL INFO P2P Chunksize set to 131072
worker-0:5760:5824 [5] NCCL INFO Channel 05/0 : 6[6] -> 13[5] [receive] via NET/IBext/1/GDRDMA
worker-0:5760:5824 [5] NCCL INFO Channel 13/0 : 6[6] -> 13[5] [receive] via NET/IBext/1/GDRDMA
worker-1:5782:5866 [4] NCCL INFO Channel 01/0 : 4[4] -> 5[5] via P2P/CUMEM
worker-1:5782:5866 [4] NCCL INFO Channel 02/0 : 4[4] -> 5[5] via P2P/CUMEM
worker-1:5782:5866 [4] NCCL INFO Channel 03/0 : 4[4] -> 5[5] via P2P/CUMEM
worker-1:5782:5866 [4] NCCL INFO Channel 04/0 : 4[4] -> 5[5] via P2P/CUMEM
worker-1:5782:5866 [4] NCCL INFO Channel 06/0 : 4[4] -> 5[5] via P2P/CUMEM
worker-0:5760:5824 [5] NCCL INFO Channel 04/0 : 13[5] -> 4[4] [send] via NET/IBext/0(12)/GDRDMA
worker-0:5760:5824 [5] NCCL INFO Channel 12/0 : 13[5] -> 4[4] [send] via NET/IBext/0(12)/GDRDMA
worker-0:5760:5824 [5] NCCL INFO Channel 00/0 : 13[5] -> 12[4] via P2P/CUMEM
worker-0:5760:5824 [5] NCCL INFO Channel 01/0 : 13[5] -> 12[4] via P2P/CUMEM
worker-0:5760:5824 [5] NCCL INFO Channel 02/0 : 13[5] -> 12[4] via P2P/CUMEM
worker-0:5760:5824 [5] NCCL INFO Channel 03/0 : 13[5] -> 12[4] via P2P/CUMEM
worker-0:5760:5824 [5] NCCL INFO Channel 05/0 : 13[5] -> 12[4] via P2P/CUMEM
worker-0:5760:5824 [5] NCCL INFO Channel 06/0 : 13[5] -> 12[4] via P2P/CUMEM
worker-0:5760:5824 [5] NCCL INFO Channel 07/0 : 13[5] -> 12[4] via P2P/CUMEM
worker-0:5760:5824 [5] NCCL INFO Channel 08/0 : 13[5] -> 12[4] via P2P/CUMEM
worker-0:5760:5824 [5] NCCL INFO Channel 09/0 : 13[5] -> 12[4] via P2P/CUMEM
worker-0:5760:5824 [5] NCCL INFO Channel 10/0 : 13[5] -> 12[4] via P2P/CUMEM
worker-1:5783:5783 [5] NCCL INFO cudaDriverVersion 12030
worker-1:5783:5783 [5] NCCL INFO Bootstrap : Using eth0:10.113.5.242<0>
worker-1:5783:5783 [5] NCCL INFO NET/Plugin: Failed to find ncclNetPlugin_v7 symbol.
worker-1:5783:5783 [5] NCCL INFO NET/Plugin: Loaded net plugin NCCL RDMA Plugin v6 (v6)
worker-1:5783:5783 [5] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v7 symbol.
worker-1:5783:5783 [5] NCCL INFO NET/Plugin: Loaded coll plugin SHARP (v6)
worker-1:5783:5865 [5] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
worker-1:5783:5865 [5] NCCL INFO P2P plugin IBext
worker-1:5783:5865 [5] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_1:1/IB/SHARP [2]mlx5_2:1/IB/SHARP [3]mlx5_3:1/IB/SHARP [4]mlx5_4:1/IB/SHARP [5]mlx5_5:1/IB/SHARP [6]mlx5_6:1/IB/SHARP [7]mlx5_7:1/IB/SHARP [RO]; OOB eth0:10.113.5.242<0>
worker-1:5783:5865 [5] NCCL INFO Using non-device net plugin version 0
worker-1:5783:5865 [5] NCCL INFO Using network IBext
worker-0:5760:5824 [5] NCCL INFO Channel 11/0 : 13[5] -> 12[4] via P2P/CUMEM
worker-0:5760:5824 [5] NCCL INFO Channel 13/0 : 13[5] -> 12[4] via P2P/CUMEM
worker-0:5760:5824 [5] NCCL INFO Channel 14/0 : 13[5] -> 12[4] via P2P/CUMEM
worker-0:5760:5824 [5] NCCL INFO Channel 15/0 : 13[5] -> 12[4] via P2P/CUMEM
worker-0:5760:5824 [5] NCCL INFO Connected all rings
worker-0:5760:5824 [5] NCCL INFO Channel 00/0 : 13[5] -> 14[6] via P2P/CUMEM
worker-0:5760:5824 [5] NCCL INFO Channel 01/0 : 13[5] -> 14[6] via P2P/CUMEM
worker-0:5760:5824 [5] NCCL INFO Channel 02/0 : 13[5] -> 14[6] via P2P/CUMEM
worker-0:5760:5824 [5] NCCL INFO Channel 03/0 : 13[5] -> 14[6] via P2P/CUMEM
worker-0:5760:5824 [5] NCCL INFO Channel 04/0 : 13[5] -> 14[6] via P2P/CUMEM
worker-0:5760:5824 [5] NCCL INFO Channel 05/0 : 13[5] -> 14[6] via P2P/CUMEM
worker-0:5760:5824 [5] NCCL INFO Channel 07/0 : 13[5] -> 14[6] via P2P/CUMEM
worker-0:5760:5824 [5] NCCL INFO Channel 08/0 : 13[5] -> 14[6] via P2P/CUMEM
worker-1:5783:5865 [5] NCCL INFO comm 0x557b6d2784a0 rank 5 nranks 16 cudaDev 5 nvmlDev 5 busId af000 commId 0xfd5d9e8febee040d - Init START
worker-1:5783:5865 [5] NCCL INFO NCCL_TOPO_FILE set by environment to /var/run/nvidia-topologyd/virtualTopology.xml
worker-1:5783:5865 [5] NCCL INFO NVLS multicast support is available on dev 5
worker-1:5783:5865 [5] NCCL INFO NVLS Head  0:  0  8
worker-1:5783:5865 [5] NCCL INFO NVLS Head  1:  1  9
worker-1:5783:5865 [5] NCCL INFO NVLS Head  2:  2 10
worker-1:5783:5865 [5] NCCL INFO NVLS Head  3:  3 11
worker-1:5783:5865 [5] NCCL INFO NVLS Head  4:  4 12
worker-1:5783:5865 [5] NCCL INFO NVLS Head  5:  5 13
worker-1:5783:5865 [5] NCCL INFO NVLS Head  6:  6 14
worker-1:5783:5865 [5] NCCL INFO NVLS Head  7:  7 15
worker-0:5760:5824 [5] NCCL INFO Channel 09/0 : 13[5] -> 14[6] via P2P/CUMEM
worker-0:5760:5824 [5] NCCL INFO Channel 10/0 : 13[5] -> 14[6] via P2P/CUMEM
worker-1:5783:5865 [5] NCCL INFO Trees [0] 6/-1/-1->5->4 [1] 6/-1/-1->5->4 [2] 6/-1/-1->5->4 [3] 6/-1/-1->5->4 [4] 6/-1/-1->5->4 [5] 6/13/-1->5->-1 [6] -1/-1/-1->5->4 [7] 6/-1/-1->5->4 [8] 6/-1/-1->5->4 [9] 6/-1/-1->5->4 [10] 6/-1/-1->5->4 [11] 6/-1/-1->5->4 [12] 6/-1/-1->5->4 [13] 6/-1/-1->5->13 [14] -1/-1/-1->5->4 [15] 6/-1/-1->5->4
worker-1:5783:5865 [5] NCCL INFO P2P Chunksize set to 131072
worker-1:5783:5865 [5] NCCL INFO Channel 05/0 : 14[6] -> 5[5] [receive] via NET/IBext/1/GDRDMA
worker-1:5783:5865 [5] NCCL INFO Channel 13/0 : 14[6] -> 5[5] [receive] via NET/IBext/1/GDRDMA
worker-1:5783:5865 [5] NCCL INFO Channel 04/0 : 5[5] -> 12[4] [send] via NET/IBext/0(4)/GDRDMA
worker-1:5783:5865 [5] NCCL INFO Channel 12/0 : 5[5] -> 12[4] [send] via NET/IBext/0(4)/GDRDMA
worker-1:5783:5865 [5] NCCL INFO Channel 00/0 : 5[5] -> 4[4] via P2P/CUMEM
worker-1:5783:5865 [5] NCCL INFO Channel 01/0 : 5[5] -> 4[4] via P2P/CUMEM
worker-1:5783:5865 [5] NCCL INFO Channel 02/0 : 5[5] -> 4[4] via P2P/CUMEM
worker-0:5742:5742 [4] NCCL INFO cudaDriverVersion 12030
worker-0:5742:5742 [4] NCCL INFO Bootstrap : Using eth0:10.113.4.37<0>
worker-0:5742:5742 [4] NCCL INFO NET/Plugin: Failed to find ncclNetPlugin_v7 symbol.
worker-0:5742:5742 [4] NCCL INFO NET/Plugin: Loaded net plugin NCCL RDMA Plugin v6 (v6)
worker-0:5742:5742 [4] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v7 symbol.
worker-0:5742:5742 [4] NCCL INFO NET/Plugin: Loaded coll plugin SHARP (v6)
worker-0:5742:5831 [4] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
worker-0:5742:5831 [4] NCCL INFO P2P plugin IBext
worker-0:5742:5831 [4] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_1:1/IB/SHARP [2]mlx5_2:1/IB/SHARP [3]mlx5_3:1/IB/SHARP [4]mlx5_4:1/IB/SHARP [5]mlx5_5:1/IB/SHARP [6]mlx5_6:1/IB/SHARP [7]mlx5_7:1/IB/SHARP [RO]; OOB eth0:10.113.4.37<0>
worker-0:5742:5831 [4] NCCL INFO Using non-device net plugin version 0
worker-0:5742:5831 [4] NCCL INFO Using network IBext
worker-1:5783:5865 [5] NCCL INFO Channel 03/0 : 5[5] -> 4[4] via P2P/CUMEM
worker-1:5783:5865 [5] NCCL INFO Channel 05/0 : 5[5] -> 4[4] via P2P/CUMEM
worker-1:5783:5865 [5] NCCL INFO Channel 06/0 : 5[5] -> 4[4] via P2P/CUMEM
worker-1:5783:5865 [5] NCCL INFO Channel 07/0 : 5[5] -> 4[4] via P2P/CUMEM
worker-1:5783:5865 [5] NCCL INFO Channel 08/0 : 5[5] -> 4[4] via P2P/CUMEM
worker-1:5783:5865 [5] NCCL INFO Channel 09/0 : 5[5] -> 4[4] via P2P/CUMEM
worker-1:5783:5865 [5] NCCL INFO Channel 10/0 : 5[5] -> 4[4] via P2P/CUMEM
worker-1:5783:5865 [5] NCCL INFO Channel 11/0 : 5[5] -> 4[4] via P2P/CUMEM
worker-1:5783:5865 [5] NCCL INFO Channel 13/0 : 5[5] -> 4[4] via P2P/CUMEM
worker-1:5783:5865 [5] NCCL INFO Channel 14/0 : 5[5] -> 4[4] via P2P/CUMEM
worker-1:5783:5865 [5] NCCL INFO Channel 15/0 : 5[5] -> 4[4] via P2P/CUMEM
worker-1:5783:5865 [5] NCCL INFO Connected all rings
worker-1:5783:5865 [5] NCCL INFO Channel 00/0 : 5[5] -> 6[6] via P2P/CUMEM
worker-0:5742:5831 [4] NCCL INFO comm 0x55ea104763d0 rank 12 nranks 16 cudaDev 4 nvmlDev 4 busId ab000 commId 0xfd5d9e8febee040d - Init START
worker-0:5742:5831 [4] NCCL INFO NCCL_TOPO_FILE set by environment to /var/run/nvidia-topologyd/virtualTopology.xml
worker-0:5742:5831 [4] NCCL INFO NVLS multicast support is available on dev 4
worker-0:5742:5831 [4] NCCL INFO Trees [0] 13/-1/-1->12->11 [1] 13/-1/-1->12->11 [2] 13/-1/-1->12->11 [3] 13/-1/-1->12->11 [4] 13/-1/-1->12->4 [5] -1/-1/-1->12->11 [6] 13/-1/-1->12->11 [7] 13/-1/-1->12->11 [8] 13/-1/-1->12->11 [9] 13/-1/-1->12->11 [10] 13/-1/-1->12->11 [11] 13/-1/-1->12->11 [12] 13/4/-1->12->-1 [13] -1/-1/-1->12->11 [14] 13/-1/-1->12->11 [15] 13/-1/-1->12->11
worker-0:5742:5831 [4] NCCL INFO P2P Chunksize set to 131072
worker-0:5742:5831 [4] NCCL INFO Channel 04/0 : 5[5] -> 12[4] [receive] via NET/IBext/0/GDRDMA
worker-0:5742:5831 [4] NCCL INFO Channel 12/0 : 5[5] -> 12[4] [receive] via NET/IBext/0/GDRDMA
worker-1:5783:5865 [5] NCCL INFO Channel 01/0 : 5[5] -> 6[6] via P2P/CUMEM
worker-1:5783:5865 [5] NCCL INFO Channel 02/0 : 5[5] -> 6[6] via P2P/CUMEM
worker-1:5783:5865 [5] NCCL INFO Channel 03/0 : 5[5] -> 6[6] via P2P/CUMEM
worker-1:5783:5865 [5] NCCL INFO Channel 04/0 : 5[5] -> 6[6] via P2P/CUMEM
worker-1:5783:5865 [5] NCCL INFO Channel 05/0 : 5[5] -> 6[6] via P2P/CUMEM
worker-0:5742:5831 [4] NCCL INFO Channel 03/0 : 12[4] -> 3[3] [send] via NET/IBext/7(11)/GDRDMA
worker-0:5742:5831 [4] NCCL INFO Channel 11/0 : 12[4] -> 3[3] [send] via NET/IBext/7(11)/GDRDMA
worker-0:5742:5831 [4] NCCL INFO Channel 00/0 : 12[4] -> 11[3] via P2P/CUMEM
worker-0:5742:5831 [4] NCCL INFO Channel 01/0 : 12[4] -> 11[3] via P2P/CUMEM
worker-0:5742:5831 [4] NCCL INFO Channel 02/0 : 12[4] -> 11[3] via P2P/CUMEM
worker-0:5742:5831 [4] NCCL INFO Channel 04/0 : 12[4] -> 11[3] via P2P/CUMEM
worker-0:5742:5831 [4] NCCL INFO Channel 05/0 : 12[4] -> 11[3] via P2P/CUMEM
worker-0:5742:5831 [4] NCCL INFO Channel 06/0 : 12[4] -> 11[3] via P2P/CUMEM
worker-0:5742:5831 [4] NCCL INFO Channel 07/0 : 12[4] -> 11[3] via P2P/CUMEM
worker-0:5742:5831 [4] NCCL INFO Channel 08/0 : 12[4] -> 11[3] via P2P/CUMEM
worker-0:5742:5831 [4] NCCL INFO Channel 09/0 : 12[4] -> 11[3] via P2P/CUMEM
worker-0:5742:5831 [4] NCCL INFO Channel 10/0 : 12[4] -> 11[3] via P2P/CUMEM
worker-1:5774:5774 [7] NCCL INFO cudaDriverVersion 12030
worker-1:5774:5774 [7] NCCL INFO Bootstrap : Using eth0:10.113.5.242<0>
worker-1:5774:5774 [7] NCCL INFO NET/Plugin: Failed to find ncclNetPlugin_v7 symbol.
worker-1:5774:5774 [7] NCCL INFO NET/Plugin: Loaded net plugin NCCL RDMA Plugin v6 (v6)
worker-1:5774:5774 [7] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v7 symbol.
worker-1:5774:5774 [7] NCCL INFO NET/Plugin: Loaded coll plugin SHARP (v6)
worker-1:5774:5863 [7] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
worker-1:5774:5863 [7] NCCL INFO P2P plugin IBext
worker-1:5774:5863 [7] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_1:1/IB/SHARP [2]mlx5_2:1/IB/SHARP [3]mlx5_3:1/IB/SHARP [4]mlx5_4:1/IB/SHARP [5]mlx5_5:1/IB/SHARP [6]mlx5_6:1/IB/SHARP [7]mlx5_7:1/IB/SHARP [RO]; OOB eth0:10.113.5.242<0>
worker-1:5774:5863 [7] NCCL INFO Using non-device net plugin version 0
worker-1:5774:5863 [7] NCCL INFO Using network IBext
worker-0:5742:5831 [4] NCCL INFO Channel 12/0 : 12[4] -> 11[3] via P2P/CUMEM
worker-0:5742:5831 [4] NCCL INFO Channel 13/0 : 12[4] -> 11[3] via P2P/CUMEM
worker-0:5742:5831 [4] NCCL INFO Channel 14/0 : 12[4] -> 11[3] via P2P/CUMEM
worker-0:5742:5831 [4] NCCL INFO Channel 15/0 : 12[4] -> 11[3] via P2P/CUMEM
worker-0:5742:5831 [4] NCCL INFO Connected all rings
worker-0:5742:5831 [4] NCCL INFO Channel 00/0 : 12[4] -> 13[5] via P2P/CUMEM
worker-0:5742:5831 [4] NCCL INFO Channel 01/0 : 12[4] -> 13[5] via P2P/CUMEM
worker-0:5742:5831 [4] NCCL INFO Channel 02/0 : 12[4] -> 13[5] via P2P/CUMEM
worker-0:5742:5831 [4] NCCL INFO Channel 03/0 : 12[4] -> 13[5] via P2P/CUMEM
worker-0:5742:5831 [4] NCCL INFO Channel 04/0 : 12[4] -> 13[5] via P2P/CUMEM
worker-0:5742:5831 [4] NCCL INFO Channel 06/0 : 12[4] -> 13[5] via P2P/CUMEM
worker-0:5742:5831 [4] NCCL INFO Channel 07/0 : 12[4] -> 13[5] via P2P/CUMEM
worker-0:5742:5831 [4] NCCL INFO Channel 08/0 : 12[4] -> 13[5] via P2P/CUMEM
worker-1:5774:5863 [7] NCCL INFO comm 0x5592d3c98590 rank 7 nranks 16 cudaDev 7 nvmlDev 7 busId b7000 commId 0xfd5d9e8febee040d - Init START
worker-1:5774:5863 [7] NCCL INFO NCCL_TOPO_FILE set by environment to /var/run/nvidia-topologyd/virtualTopology.xml
worker-1:5774:5863 [7] NCCL INFO NVLS multicast support is available on dev 7
worker-1:5774:5863 [7] NCCL INFO NVLS Head  0:  0  8
worker-1:5774:5863 [7] NCCL INFO NVLS Head  1:  1  9
worker-1:5774:5863 [7] NCCL INFO NVLS Head  2:  2 10
worker-1:5774:5863 [7] NCCL INFO NVLS Head  3:  3 11
worker-1:5774:5863 [7] NCCL INFO NVLS Head  4:  4 12
worker-1:5774:5863 [7] NCCL INFO NVLS Head  5:  5 13
worker-1:5774:5863 [7] NCCL INFO NVLS Head  6:  6 14
worker-1:5774:5863 [7] NCCL INFO NVLS Head  7:  7 15
worker-0:5742:5831 [4] NCCL INFO Channel 09/0 : 12[4] -> 13[5] via P2P/CUMEM
worker-0:5742:5831 [4] NCCL INFO Channel 10/0 : 12[4] -> 13[5] via P2P/CUMEM
worker-1:5774:5863 [7] NCCL INFO Trees [0] -1/-1/-1->7->6 [1] 0/-1/-1->7->6 [2] 0/-1/-1->7->6 [3] 0/-1/-1->7->6 [4] 0/-1/-1->7->6 [5] 0/-1/-1->7->6 [6] 0/-1/-1->7->6 [7] 0/15/-1->7->-1 [8] -1/-1/-1->7->6 [9] 0/-1/-1->7->6 [10] 0/-1/-1->7->6 [11] 0/-1/-1->7->6 [12] 0/-1/-1->7->6 [13] 0/-1/-1->7->6 [14] 0/-1/-1->7->6 [15] 0/-1/-1->7->15
worker-1:5774:5863 [7] NCCL INFO P2P Chunksize set to 131072
worker-1:5774:5863 [7] NCCL INFO Channel 06/0 : 7[7] -> 14[6] [send] via NET/IBext/2(6)/GDRDMA
worker-1:5774:5863 [7] NCCL INFO Channel 14/0 : 7[7] -> 14[6] [send] via NET/IBext/2(6)/GDRDMA
worker-1:5774:5863 [7] NCCL INFO Channel 07/0 : 8[0] -> 7[7] [receive] via NET/IBext/3/GDRDMA
worker-1:5774:5863 [7] NCCL INFO Channel 15/0 : 8[0] -> 7[7] [receive] via NET/IBext/3/GDRDMA
worker-1:5774:5863 [7] NCCL INFO Channel 00/0 : 7[7] -> 6[6] via P2P/CUMEM
worker-1:5774:5863 [7] NCCL INFO Channel 01/0 : 7[7] -> 6[6] via P2P/CUMEM
worker-1:5774:5863 [7] NCCL INFO Channel 02/0 : 7[7] -> 6[6] via P2P/CUMEM
worker-0:5746:5746 [6] NCCL INFO cudaDriverVersion 12030
worker-0:5746:5746 [6] NCCL INFO Bootstrap : Using eth0:10.113.4.37<0>
worker-0:5746:5746 [6] NCCL INFO NET/Plugin: Failed to find ncclNetPlugin_v7 symbol.
worker-0:5746:5746 [6] NCCL INFO NET/Plugin: Loaded net plugin NCCL RDMA Plugin v6 (v6)
worker-0:5746:5746 [6] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v7 symbol.
worker-0:5746:5746 [6] NCCL INFO NET/Plugin: Loaded coll plugin SHARP (v6)
worker-0:5746:5833 [6] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
worker-0:5746:5833 [6] NCCL INFO P2P plugin IBext
worker-0:5746:5833 [6] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_1:1/IB/SHARP [2]mlx5_2:1/IB/SHARP [3]mlx5_3:1/IB/SHARP [4]mlx5_4:1/IB/SHARP [5]mlx5_5:1/IB/SHARP [6]mlx5_6:1/IB/SHARP [7]mlx5_7:1/IB/SHARP [RO]; OOB eth0:10.113.4.37<0>
worker-0:5746:5833 [6] NCCL INFO Using non-device net plugin version 0
worker-0:5746:5833 [6] NCCL INFO Using network IBext
worker-1:5774:5863 [7] NCCL INFO Channel 03/0 : 7[7] -> 6[6] via P2P/CUMEM
worker-1:5774:5863 [7] NCCL INFO Channel 04/0 : 7[7] -> 6[6] via P2P/CUMEM
worker-1:5774:5863 [7] NCCL INFO Channel 05/0 : 7[7] -> 6[6] via P2P/CUMEM
worker-1:5774:5863 [7] NCCL INFO Channel 07/0 : 7[7] -> 6[6] via P2P/CUMEM
worker-1:5774:5863 [7] NCCL INFO Channel 08/0 : 7[7] -> 6[6] via P2P/CUMEM
worker-1:5774:5863 [7] NCCL INFO Channel 09/0 : 7[7] -> 6[6] via P2P/CUMEM
worker-1:5774:5863 [7] NCCL INFO Channel 10/0 : 7[7] -> 6[6] via P2P/CUMEM
worker-1:5774:5863 [7] NCCL INFO Channel 11/0 : 7[7] -> 6[6] via P2P/CUMEM
worker-1:5774:5863 [7] NCCL INFO Channel 12/0 : 7[7] -> 6[6] via P2P/CUMEM
worker-1:5774:5863 [7] NCCL INFO Channel 13/0 : 7[7] -> 6[6] via P2P/CUMEM
worker-1:5774:5863 [7] NCCL INFO Channel 15/0 : 7[7] -> 6[6] via P2P/CUMEM
worker-1:5774:5863 [7] NCCL INFO Connected all rings
worker-1:5774:5863 [7] NCCL INFO Channel 07/0 : 15[7] -> 7[7] [receive] via NET/IBext/3/GDRDMA
worker-0:5746:5833 [6] NCCL INFO comm 0x5560558af130 rank 14 nranks 16 cudaDev 6 nvmlDev 6 busId b3000 commId 0xfd5d9e8febee040d - Init START
worker-0:5746:5833 [6] NCCL INFO NCCL_TOPO_FILE set by environment to /var/run/nvidia-topologyd/virtualTopology.xml
worker-0:5746:5833 [6] NCCL INFO NVLS multicast support is available on dev 6
worker-0:5746:5833 [6] NCCL INFO Trees [0] 15/-1/-1->14->13 [1] 15/-1/-1->14->13 [2] 15/-1/-1->14->13 [3] 15/-1/-1->14->13 [4] 15/-1/-1->14->13 [5] 15/-1/-1->14->13 [6] 15/-1/-1->14->6 [7] -1/-1/-1->14->13 [8] 15/-1/-1->14->13 [9] 15/-1/-1->14->13 [10] 15/-1/-1->14->13 [11] 15/-1/-1->14->13 [12] 15/-1/-1->14->13 [13] 15/-1/-1->14->13 [14] 15/6/-1->14->-1 [15] -1/-1/-1->14->13
worker-0:5746:5833 [6] NCCL INFO P2P Chunksize set to 131072
worker-0:5746:5833 [6] NCCL INFO Channel 06/0 : 7[7] -> 14[6] [receive] via NET/IBext/2/GDRDMA
worker-0:5746:5833 [6] NCCL INFO Channel 14/0 : 7[7] -> 14[6] [receive] via NET/IBext/2/GDRDMA
worker-1:5774:5863 [7] NCCL INFO Channel 15/0 : 15[7] -> 7[7] [receive] via NET/IBext/3/GDRDMA
worker-1:5774:5863 [7] NCCL INFO Channel 07/0 : 7[7] -> 15[7] [send] via NET/IBext/3/GDRDMA
worker-1:5774:5863 [7] NCCL INFO Channel 15/0 : 7[7] -> 15[7] [send] via NET/IBext/3/GDRDMA
worker-1:5774:5863 [7] NCCL INFO Channel 01/0 : 7[7] -> 0[0] via P2P/CUMEM
worker-0:5746:5833 [6] NCCL INFO Channel 05/0 : 14[6] -> 5[5] [send] via NET/IBext/1(13)/GDRDMA
worker-0:5746:5833 [6] NCCL INFO Channel 13/0 : 14[6] -> 5[5] [send] via NET/IBext/1(13)/GDRDMA
worker-0:5746:5833 [6] NCCL INFO Channel 00/0 : 14[6] -> 13[5] via P2P/CUMEM
worker-0:5746:5833 [6] NCCL INFO Channel 01/0 : 14[6] -> 13[5] via P2P/CUMEM
worker-0:5746:5833 [6] NCCL INFO Channel 02/0 : 14[6] -> 13[5] via P2P/CUMEM
worker-0:5746:5833 [6] NCCL INFO Channel 03/0 : 14[6] -> 13[5] via P2P/CUMEM
worker-0:5746:5833 [6] NCCL INFO Channel 04/0 : 14[6] -> 13[5] via P2P/CUMEM
worker-0:5746:5833 [6] NCCL INFO Channel 06/0 : 14[6] -> 13[5] via P2P/CUMEM
worker-0:5746:5833 [6] NCCL INFO Channel 07/0 : 14[6] -> 13[5] via P2P/CUMEM
worker-0:5746:5833 [6] NCCL INFO Channel 08/0 : 14[6] -> 13[5] via P2P/CUMEM
worker-0:5746:5833 [6] NCCL INFO Channel 09/0 : 14[6] -> 13[5] via P2P/CUMEM
worker-0:5746:5833 [6] NCCL INFO Channel 10/0 : 14[6] -> 13[5] via P2P/CUMEM
worker-0:5746:5833 [6] NCCL INFO Channel 11/0 : 14[6] -> 13[5] via P2P/CUMEM
worker-0:5746:5833 [6] NCCL INFO Channel 12/0 : 14[6] -> 13[5] via P2P/CUMEM
worker-0:5746:5833 [6] NCCL INFO Channel 14/0 : 14[6] -> 13[5] via P2P/CUMEM
worker-0:5746:5833 [6] NCCL INFO Channel 15/0 : 14[6] -> 13[5] via P2P/CUMEM
worker-0:5746:5833 [6] NCCL INFO Connected all rings
worker-0:5746:5833 [6] NCCL INFO Channel 00/0 : 14[6] -> 15[7] via P2P/CUMEM
worker-0:5746:5833 [6] NCCL INFO Channel 01/0 : 14[6] -> 15[7] via P2P/CUMEM
worker-0:5746:5833 [6] NCCL INFO Channel 02/0 : 14[6] -> 15[7] via P2P/CUMEM
worker-0:5746:5833 [6] NCCL INFO Channel 03/0 : 14[6] -> 15[7] via P2P/CUMEM
worker-0:5746:5833 [6] NCCL INFO Channel 04/0 : 14[6] -> 15[7] via P2P/CUMEM
worker-0:5746:5833 [6] NCCL INFO Channel 05/0 : 14[6] -> 15[7] via P2P/CUMEM
worker-0:5746:5833 [6] NCCL INFO Channel 06/0 : 14[6] -> 15[7] via P2P/CUMEM
worker-0:5746:5833 [6] NCCL INFO Channel 08/0 : 14[6] -> 15[7] via P2P/CUMEM
worker-0:5746:5833 [6] NCCL INFO Channel 09/0 : 14[6] -> 15[7] via P2P/CUMEM
worker-0:5746:5833 [6] NCCL INFO Channel 10/0 : 14[6] -> 15[7] via P2P/CUMEM
worker-0:5747:5747 [7] NCCL INFO cudaDriverVersion 12030
worker-0:5747:5747 [7] NCCL INFO Bootstrap : Using eth0:10.113.4.37<0>
worker-0:5747:5747 [7] NCCL INFO NET/Plugin: Failed to find ncclNetPlugin_v7 symbol.
worker-0:5747:5747 [7] NCCL INFO NET/Plugin: Loaded net plugin NCCL RDMA Plugin v6 (v6)
worker-0:5747:5747 [7] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v7 symbol.
worker-0:5747:5747 [7] NCCL INFO NET/Plugin: Loaded coll plugin SHARP (v6)
worker-0:5747:5829 [7] NCCL INFO Plugin Path : /opt/hpcx/nccl_rdma_sharp_plugin/lib/libnccl-net.so
worker-0:5747:5829 [7] NCCL INFO P2P plugin IBext
worker-0:5747:5829 [7] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB/SHARP [1]mlx5_1:1/IB/SHARP [2]mlx5_2:1/IB/SHARP [3]mlx5_3:1/IB/SHARP [4]mlx5_4:1/IB/SHARP [5]mlx5_5:1/IB/SHARP [6]mlx5_6:1/IB/SHARP [7]mlx5_7:1/IB/SHARP [RO]; OOB eth0:10.113.4.37<0>
worker-0:5747:5829 [7] NCCL INFO Using non-device net plugin version 0
worker-0:5747:5829 [7] NCCL INFO Using network IBext
worker-0:5747:5829 [7] NCCL INFO comm 0x563e6e6cbbe0 rank 15 nranks 16 cudaDev 7 nvmlDev 7 busId b7000 commId 0xfd5d9e8febee040d - Init START
worker-0:5747:5829 [7] NCCL INFO NCCL_TOPO_FILE set by environment to /var/run/nvidia-topologyd/virtualTopology.xml
worker-0:5747:5829 [7] NCCL INFO NVLS multicast support is available on dev 7
worker-0:5747:5829 [7] NCCL INFO Trees [0] -1/-1/-1->15->14 [1] 8/-1/-1->15->14 [2] 8/-1/-1->15->14 [3] 8/-1/-1->15->14 [4] 8/-1/-1->15->14 [5] 8/-1/-1->15->14 [6] 8/-1/-1->15->14 [7] 8/-1/-1->15->7 [8] -1/-1/-1->15->14 [9] 8/-1/-1->15->14 [10] 8/-1/-1->15->14 [11] 8/-1/-1->15->14 [12] 8/-1/-1->15->14 [13] 8/-1/-1->15->14 [14] 8/-1/-1->15->14 [15] 8/7/-1->15->-1
worker-0:5747:5829 [7] NCCL INFO P2P Chunksize set to 131072
worker-0:5747:5829 [7] NCCL INFO Channel 06/0 : 15[7] -> 6[6] [send] via NET/IBext/2(14)/GDRDMA
worker-0:5747:5829 [7] NCCL INFO Channel 14/0 : 15[7] -> 6[6] [send] via NET/IBext/2(14)/GDRDMA
worker-0:5747:5829 [7] NCCL INFO Channel 07/0 : 0[0] -> 15[7] [receive] via NET/IBext/3/GDRDMA
worker-0:5747:5829 [7] NCCL INFO Channel 15/0 : 0[0] -> 15[7] [receive] via NET/IBext/3/GDRDMA
worker-0:5747:5829 [7] NCCL INFO Channel 00/0 : 15[7] -> 14[6] via P2P/CUMEM
worker-0:5747:5829 [7] NCCL INFO Channel 01/0 : 15[7] -> 14[6] via P2P/CUMEM
worker-0:5747:5829 [7] NCCL INFO Channel 02/0 : 15[7] -> 14[6] via P2P/CUMEM
worker-0:5747:5829 [7] NCCL INFO Channel 03/0 : 15[7] -> 14[6] via P2P/CUMEM
worker-0:5747:5829 [7] NCCL INFO Channel 04/0 : 15[7] -> 14[6] via P2P/CUMEM
worker-0:5747:5829 [7] NCCL INFO Channel 05/0 : 15[7] -> 14[6] via P2P/CUMEM
worker-0:5747:5829 [7] NCCL INFO Channel 07/0 : 15[7] -> 14[6] via P2P/CUMEM
worker-0:5747:5829 [7] NCCL INFO Channel 08/0 : 15[7] -> 14[6] via P2P/CUMEM
worker-0:5747:5829 [7] NCCL INFO Channel 09/0 : 15[7] -> 14[6] via P2P/CUMEM
worker-0:5747:5829 [7] NCCL INFO Channel 10/0 : 15[7] -> 14[6] via P2P/CUMEM
worker-0:5747:5829 [7] NCCL INFO Channel 11/0 : 15[7] -> 14[6] via P2P/CUMEM
worker-0:5747:5829 [7] NCCL INFO Channel 12/0 : 15[7] -> 14[6] via P2P/CUMEM
worker-0:5747:5829 [7] NCCL INFO Channel 13/0 : 15[7] -> 14[6] via P2P/CUMEM
worker-0:5747:5829 [7] NCCL INFO Channel 15/0 : 15[7] -> 14[6] via P2P/CUMEM
worker-0:5747:5829 [7] NCCL INFO Connected all rings
worker-0:5747:5829 [7] NCCL INFO Channel 07/0 : 7[7] -> 15[7] [receive] via NET/IBext/3/GDRDMA
worker-0:5747:5829 [7] NCCL INFO Channel 15/0 : 7[7] -> 15[7] [receive] via NET/IBext/3/GDRDMA
worker-0:5747:5829 [7] NCCL INFO Channel 07/0 : 15[7] -> 7[7] [send] via NET/IBext/3/GDRDMA
worker-0:5747:5829 [7] NCCL INFO Channel 15/0 : 15[7] -> 7[7] [send] via NET/IBext/3/GDRDMA
worker-0:5747:5829 [7] NCCL INFO Channel 01/0 : 15[7] -> 8[0] via P2P/CUMEM
worker-0:5747:5829 [7] NCCL INFO Channel 02/0 : 15[7] -> 8[0] via P2P/CUMEM
worker-0:5747:5829 [7] NCCL INFO Channel 03/0 : 15[7] -> 8[0] via P2P/CUMEM
worker-0:5747:5829 [7] NCCL INFO Channel 04/0 : 15[7] -> 8[0] via P2P/CUMEM
worker-0:5747:5829 [7] NCCL INFO Channel 05/0 : 15[7] -> 8[0] via P2P/CUMEM
worker-0:5747:5829 [7] NCCL INFO Channel 06/0 : 15[7] -> 8[0] via P2P/CUMEM
worker-1:5776:5864 [0] NCCL INFO Channel 04/0 : 0[0] -> 7[7] via P2P/CUMEM
worker-1:5776:5864 [0] NCCL INFO Channel 05/0 : 0[0] -> 7[7] via P2P/CUMEM
worker-1:5776:5864 [0] NCCL INFO Channel 06/0 : 0[0] -> 7[7] via P2P/CUMEM
worker-1:5776:5864 [0] NCCL INFO Channel 08/0 : 0[0] -> 7[7] via P2P/CUMEM
worker-1:5776:5864 [0] NCCL INFO Channel 09/0 : 0[0] -> 7[7] via P2P/CUMEM
worker-1:5776:5864 [0] NCCL INFO Channel 10/0 : 0[0] -> 7[7] via P2P/CUMEM
worker-1:5776:5864 [0] NCCL INFO Channel 11/0 : 0[0] -> 7[7] via P2P/CUMEM
worker-1:5776:5864 [0] NCCL INFO Channel 12/0 : 0[0] -> 7[7] via P2P/CUMEM
worker-1:5776:5864 [0] NCCL INFO Channel 13/0 : 0[0] -> 7[7] via P2P/CUMEM
worker-1:5776:5864 [0] NCCL INFO Channel 14/0 : 0[0] -> 7[7] via P2P/CUMEM
worker-1:5776:5864 [0] NCCL INFO Channel 07/0 : 0[0] -> 15[7] [send] via NET/IBext/3(7)/GDRDMA
worker-1:5776:5864 [0] NCCL INFO Channel 15/0 : 0[0] -> 15[7] [send] via NET/IBext/3(7)/GDRDMA
worker-1:5776:5864 [0] NCCL INFO Connected all rings
worker-1:5776:5864 [0] NCCL INFO Channel 00/0 : 0[0] -> 1[1] via P2P/CUMEM
worker-1:5776:5864 [0] NCCL INFO Channel 02/0 : 0[0] -> 1[1] via P2P/CUMEM
worker-1:5776:5864 [0] NCCL INFO Channel 03/0 : 0[0] -> 1[1] via P2P/CUMEM
worker-1:5776:5864 [0] NCCL INFO Channel 04/0 : 0[0] -> 1[1] via P2P/CUMEM
worker-1:5776:5864 [0] NCCL INFO Channel 05/0 : 0[0] -> 1[1] via P2P/CUMEM
worker-1:5776:5864 [0] NCCL INFO Channel 06/0 : 0[0] -> 1[1] via P2P/CUMEM
worker-1:5776:5864 [0] NCCL INFO Channel 07/0 : 0[0] -> 1[1] via P2P/CUMEM
worker-1:5776:5864 [0] NCCL INFO Channel 08/0 : 0[0] -> 1[1] via P2P/CUMEM
worker-1:5776:5864 [0] NCCL INFO Channel 10/0 : 0[0] -> 1[1] via P2P/CUMEM
worker-1:5776:5864 [0] NCCL INFO Channel 11/0 : 0[0] -> 1[1] via P2P/CUMEM
worker-1:5776:5864 [0] NCCL INFO Channel 12/0 : 0[0] -> 1[1] via P2P/CUMEM
worker-1:5776:5864 [0] NCCL INFO Channel 13/0 : 0[0] -> 1[1] via P2P/CUMEM
worker-1:5776:5864 [0] NCCL INFO Channel 14/0 : 0[0] -> 1[1] via P2P/CUMEM
worker-1:5776:5864 [0] NCCL INFO Channel 15/0 : 0[0] -> 1[1] via P2P/CUMEM
worker-1:5776:5864 [0] NCCL INFO Channel 07/0 : 0[0] -> 7[7] via P2P/CUMEM
worker-1:5776:5864 [0] NCCL INFO Channel 15/0 : 0[0] -> 7[7] via P2P/CUMEM
worker-1:5776:5864 [0] NCCL INFO Channel 00/0 : 8[0] -> 0[0] [receive] via NET/IBext/4/GDRDMA
worker-1:5776:5864 [0] NCCL INFO Channel 08/0 : 8[0] -> 0[0] [receive] via NET/IBext/4/GDRDMA
worker-1:5776:5864 [0] NCCL INFO Channel 00/0 : 0[0] -> 8[0] [send] via NET/IBext/4/GDRDMA
worker-1:5776:5864 [0] NCCL INFO Channel 08/0 : 0[0] -> 8[0] [send] via NET/IBext/4/GDRDMA
worker-1:5776:5864 [0] NCCL INFO Connected all trees
worker-1:5776:5864 [0] NCCL INFO NVLS comm 0x55bd13e90250 headRank 0 nHeads 8 buffSize 4194304 memSize 2097152 nvlsPerRankSize 201326592 nvlsTotalSize 1610612736
worker-1:5776:5864 [0] NCCL INFO Channel 01/0 : 8[0] -> 0[0] [receive] via NET/IBext/4/GDRDMA
worker-1:5776:5864 [0] NCCL INFO Channel 02/0 : 8[0] -> 0[0] [receive] via NET/IBext/4/GDRDMA
worker-1:5776:5864 [0] NCCL INFO Channel 03/0 : 8[0] -> 0[0] [receive] via NET/IBext/4/GDRDMA
worker-1:5776:5864 [0] NCCL INFO Channel 04/0 : 8[0] -> 0[0] [receive] via NET/IBext/4/GDRDMA
worker-1:5776:5864 [0] NCCL INFO Channel 05/0 : 8[0] -> 0[0] [receive] via NET/IBext/4/GDRDMA
worker-1:5776:5864 [0] NCCL INFO Channel 06/0 : 8[0] -> 0[0] [receive] via NET/IBext/4/GDRDMA
worker-1:5776:5864 [0] NCCL INFO Channel 07/0 : 8[0] -> 0[0] [receive] via NET/IBext/4/GDRDMA
worker-1:5776:5864 [0] NCCL INFO Channel 09/0 : 8[0] -> 0[0] [receive] via NET/IBext/4/GDRDMA
worker-1:5776:5864 [0] NCCL INFO Channel 10/0 : 8[0] -> 0[0] [receive] via NET/IBext/4/GDRDMA
worker-1:5776:5864 [0] NCCL INFO Channel 11/0 : 8[0] -> 0[0] [receive] via NET/IBext/4/GDRDMA
worker-1:5776:5864 [0] NCCL INFO Channel 12/0 : 8[0] -> 0[0] [receive] via NET/IBext/4/GDRDMA
worker-1:5776:5864 [0] NCCL INFO Channel 13/0 : 8[0] -> 0[0] [receive] via NET/IBext/4/GDRDMA
worker-1:5776:5864 [0] NCCL INFO Channel 14/0 : 8[0] -> 0[0] [receive] via NET/IBext/4/GDRDMA
worker-1:5776:5864 [0] NCCL INFO Channel 15/0 : 8[0] -> 0[0] [receive] via NET/IBext/4/GDRDMA
worker-1:5780:5867 [2] NCCL INFO Channel 06/0 : 2[2] -> 3[3] via P2P/CUMEM
worker-1:5780:5867 [2] NCCL INFO Channel 07/0 : 2[2] -> 3[3] via P2P/CUMEM
worker-1:5780:5867 [2] NCCL INFO Channel 08/0 : 2[2] -> 3[3] via P2P/CUMEM
worker-1:5780:5867 [2] NCCL INFO Channel 09/0 : 2[2] -> 3[3] via P2P/CUMEM
worker-1:5780:5867 [2] NCCL INFO Channel 10/0 : 2[2] -> 3[3] via P2P/CUMEM
worker-1:5780:5867 [2] NCCL INFO Channel 12/0 : 2[2] -> 3[3] via P2P/CUMEM
worker-1:5780:5867 [2] NCCL INFO Channel 13/0 : 2[2] -> 3[3] via P2P/CUMEM
worker-1:5780:5867 [2] NCCL INFO Channel 14/0 : 2[2] -> 3[3] via P2P/CUMEM
worker-1:5780:5867 [2] NCCL INFO Channel 15/0 : 2[2] -> 3[3] via P2P/CUMEM
worker-1:5780:5867 [2] NCCL INFO Channel 02/0 : 10[2] -> 2[2] [receive] via NET/IBext/6/GDRDMA
worker-1:5780:5867 [2] NCCL INFO Channel 10/0 : 10[2] -> 2[2] [receive] via NET/IBext/6/GDRDMA
worker-1:5780:5867 [2] NCCL INFO Channel 02/0 : 2[2] -> 10[2] [send] via NET/IBext/6/GDRDMA
worker-1:5780:5867 [2] NCCL INFO Channel 10/0 : 2[2] -> 10[2] [send] via NET/IBext/6/GDRDMA
worker-1:5780:5867 [2] NCCL INFO Channel 01/0 : 2[2] -> 1[1] via P2P/CUMEM
worker-1:5780:5867 [2] NCCL INFO Channel 09/0 : 2[2] -> 1[1] via P2P/CUMEM
worker-1:5780:5867 [2] NCCL INFO Connected all trees
worker-1:5780:5867 [2] NCCL INFO NVLS comm 0x558b9d3cada0 headRank 2 nHeads 8 buffSize 4194304 memSize 2097152 nvlsPerRankSize 201326592 nvlsTotalSize 1610612736
worker-1:5780:5867 [2] NCCL INFO Channel 00/0 : 10[2] -> 2[2] [receive] via NET/IBext/6/GDRDMA
worker-1:5780:5867 [2] NCCL INFO Channel 01/0 : 10[2] -> 2[2] [receive] via NET/IBext/6/GDRDMA
worker-1:5780:5867 [2] NCCL INFO Channel 03/0 : 10[2] -> 2[2] [receive] via NET/IBext/6/GDRDMA
worker-1:5780:5867 [2] NCCL INFO Channel 04/0 : 10[2] -> 2[2] [receive] via NET/IBext/6/GDRDMA
worker-1:5780:5867 [2] NCCL INFO Channel 05/0 : 10[2] -> 2[2] [receive] via NET/IBext/6/GDRDMA
worker-1:5780:5867 [2] NCCL INFO Channel 06/0 : 10[2] -> 2[2] [receive] via NET/IBext/6/GDRDMA
worker-1:5780:5867 [2] NCCL INFO Channel 07/0 : 10[2] -> 2[2] [receive] via NET/IBext/6/GDRDMA
worker-1:5780:5867 [2] NCCL INFO Channel 08/0 : 10[2] -> 2[2] [receive] via NET/IBext/6/GDRDMA
worker-1:5780:5867 [2] NCCL INFO Channel 09/0 : 10[2] -> 2[2] [receive] via NET/IBext/6/GDRDMA
worker-1:5780:5867 [2] NCCL INFO Channel 11/0 : 10[2] -> 2[2] [receive] via NET/IBext/6/GDRDMA
worker-1:5780:5867 [2] NCCL INFO Channel 12/0 : 10[2] -> 2[2] [receive] via NET/IBext/6/GDRDMA
worker-1:5780:5867 [2] NCCL INFO Channel 13/0 : 10[2] -> 2[2] [receive] via NET/IBext/6/GDRDMA
worker-1:5780:5867 [2] NCCL INFO Channel 14/0 : 10[2] -> 2[2] [receive] via NET/IBext/6/GDRDMA
worker-1:5780:5867 [2] NCCL INFO Channel 15/0 : 10[2] -> 2[2] [receive] via NET/IBext/6/GDRDMA
worker-1:5780:5867 [2] NCCL INFO Channel 00/0 : 2[2] -> 10[2] [send] via NET/IBext/6/GDRDMA
worker-1:5780:5867 [2] NCCL INFO Channel 01/0 : 2[2] -> 10[2] [send] via NET/IBext/6/GDRDMA
worker-1:5780:5867 [2] NCCL INFO Channel 03/0 : 2[2] -> 10[2] [send] via NET/IBext/6/GDRDMA
worker-1:5780:5867 [2] NCCL INFO Channel 04/0 : 2[2] -> 10[2] [send] via NET/IBext/6/GDRDMA
worker-1:5780:5867 [2] NCCL INFO Channel 05/0 : 2[2] -> 10[2] [send] via NET/IBext/6/GDRDMA
worker-1:5780:5867 [2] NCCL INFO Channel 06/0 : 2[2] -> 10[2] [send] via NET/IBext/6/GDRDMA
worker-1:5780:5867 [2] NCCL INFO Channel 07/0 : 2[2] -> 10[2] [send] via NET/IBext/6/GDRDMA
worker-1:5780:5867 [2] NCCL INFO Channel 08/0 : 2[2] -> 10[2] [send] via NET/IBext/6/GDRDMA
worker-1:5780:5867 [2] NCCL INFO Channel 09/0 : 2[2] -> 10[2] [send] via NET/IBext/6/GDRDMA
worker-1:5780:5867 [2] NCCL INFO Channel 11/0 : 2[2] -> 10[2] [send] via NET/IBext/6/GDRDMA
worker-1:5780:5867 [2] NCCL INFO Channel 12/0 : 2[2] -> 10[2] [send] via NET/IBext/6/GDRDMA
worker-1:5780:5867 [2] NCCL INFO Channel 13/0 : 2[2] -> 10[2] [send] via NET/IBext/6/GDRDMA
worker-1:5780:5867 [2] NCCL INFO Channel 14/0 : 2[2] -> 10[2] [send] via NET/IBext/6/GDRDMA
worker-1:5780:5867 [2] NCCL INFO Channel 15/0 : 2[2] -> 10[2] [send] via NET/IBext/6/GDRDMA
worker-1:5780:5867 [2] NCCL INFO Connected NVLS tree
worker-1:5782:5866 [4] NCCL INFO Channel 07/0 : 4[4] -> 5[5] via P2P/CUMEM
worker-1:5782:5866 [4] NCCL INFO Channel 08/0 : 4[4] -> 5[5] via P2P/CUMEM
worker-1:5782:5866 [4] NCCL INFO Channel 09/0 : 4[4] -> 5[5] via P2P/CUMEM
worker-1:5782:5866 [4] NCCL INFO Channel 10/0 : 4[4] -> 5[5] via P2P/CUMEM
worker-1:5782:5866 [4] NCCL INFO Channel 11/0 : 4[4] -> 5[5] via P2P/CUMEM
worker-1:5782:5866 [4] NCCL INFO Channel 12/0 : 4[4] -> 5[5] via P2P/CUMEM
worker-1:5782:5866 [4] NCCL INFO Channel 14/0 : 4[4] -> 5[5] via P2P/CUMEM
worker-1:5782:5866 [4] NCCL INFO Channel 15/0 : 4[4] -> 5[5] via P2P/CUMEM
worker-1:5782:5866 [4] NCCL INFO Channel 04/0 : 12[4] -> 4[4] [receive] via NET/IBext/0/GDRDMA
worker-1:5782:5866 [4] NCCL INFO Channel 12/0 : 12[4] -> 4[4] [receive] via NET/IBext/0/GDRDMA
worker-1:5782:5866 [4] NCCL INFO Channel 04/0 : 4[4] -> 12[4] [send] via NET/IBext/0/GDRDMA
worker-1:5782:5866 [4] NCCL INFO Channel 12/0 : 4[4] -> 12[4] [send] via NET/IBext/0/GDRDMA
worker-1:5782:5866 [4] NCCL INFO Channel 03/0 : 4[4] -> 3[3] via P2P/CUMEM
worker-1:5782:5866 [4] NCCL INFO Channel 11/0 : 4[4] -> 3[3] via P2P/CUMEM
worker-1:5782:5866 [4] NCCL INFO Connected all trees
worker-1:5782:5866 [4] NCCL INFO NVLS comm 0x560f2e6b1fa0 headRank 4 nHeads 8 buffSize 4194304 memSize 2097152 nvlsPerRankSize 201326592 nvlsTotalSize 1610612736
worker-1:5782:5866 [4] NCCL INFO Channel 00/0 : 12[4] -> 4[4] [receive] via NET/IBext/0/GDRDMA
worker-1:5782:5866 [4] NCCL INFO Channel 01/0 : 12[4] -> 4[4] [receive] via NET/IBext/0/GDRDMA
worker-1:5782:5866 [4] NCCL INFO Channel 02/0 : 12[4] -> 4[4] [receive] via NET/IBext/0/GDRDMA
worker-1:5782:5866 [4] NCCL INFO Channel 03/0 : 12[4] -> 4[4] [receive] via NET/IBext/0/GDRDMA
worker-1:5782:5866 [4] NCCL INFO Channel 05/0 : 12[4] -> 4[4] [receive] via NET/IBext/0/GDRDMA
worker-1:5782:5866 [4] NCCL INFO Channel 06/0 : 12[4] -> 4[4] [receive] via NET/IBext/0/GDRDMA
worker-1:5782:5866 [4] NCCL INFO Channel 07/0 : 12[4] -> 4[4] [receive] via NET/IBext/0/GDRDMA
worker-1:5782:5866 [4] NCCL INFO Channel 08/0 : 12[4] -> 4[4] [receive] via NET/IBext/0/GDRDMA
worker-1:5782:5866 [4] NCCL INFO Channel 09/0 : 12[4] -> 4[4] [receive] via NET/IBext/0/GDRDMA
worker-1:5782:5866 [4] NCCL INFO Channel 10/0 : 12[4] -> 4[4] [receive] via NET/IBext/0/GDRDMA
worker-1:5782:5866 [4] NCCL INFO Channel 11/0 : 12[4] -> 4[4] [receive] via NET/IBext/0/GDRDMA
worker-1:5782:5866 [4] NCCL INFO Channel 13/0 : 12[4] -> 4[4] [receive] via NET/IBext/0/GDRDMA
worker-1:5782:5866 [4] NCCL INFO Channel 14/0 : 12[4] -> 4[4] [receive] via NET/IBext/0/GDRDMA
worker-1:5782:5866 [4] NCCL INFO Channel 15/0 : 12[4] -> 4[4] [receive] via NET/IBext/0/GDRDMA
worker-1:5782:5866 [4] NCCL INFO Channel 00/0 : 4[4] -> 12[4] [send] via NET/IBext/0/GDRDMA
worker-1:5782:5866 [4] NCCL INFO Channel 01/0 : 4[4] -> 12[4] [send] via NET/IBext/0/GDRDMA
worker-1:5782:5866 [4] NCCL INFO Channel 02/0 : 4[4] -> 12[4] [send] via NET/IBext/0/GDRDMA
worker-1:5782:5866 [4] NCCL INFO Channel 03/0 : 4[4] -> 12[4] [send] via NET/IBext/0/GDRDMA
worker-1:5782:5866 [4] NCCL INFO Channel 05/0 : 4[4] -> 12[4] [send] via NET/IBext/0/GDRDMA
worker-1:5782:5866 [4] NCCL INFO Channel 06/0 : 4[4] -> 12[4] [send] via NET/IBext/0/GDRDMA
worker-1:5782:5866 [4] NCCL INFO Channel 07/0 : 4[4] -> 12[4] [send] via NET/IBext/0/GDRDMA
worker-1:5782:5866 [4] NCCL INFO Channel 08/0 : 4[4] -> 12[4] [send] via NET/IBext/0/GDRDMA
worker-1:5782:5866 [4] NCCL INFO Channel 09/0 : 4[4] -> 12[4] [send] via NET/IBext/0/GDRDMA
worker-1:5782:5866 [4] NCCL INFO Channel 10/0 : 4[4] -> 12[4] [send] via NET/IBext/0/GDRDMA
worker-1:5782:5866 [4] NCCL INFO Channel 11/0 : 4[4] -> 12[4] [send] via NET/IBext/0/GDRDMA
worker-1:5782:5866 [4] NCCL INFO Channel 13/0 : 4[4] -> 12[4] [send] via NET/IBext/0/GDRDMA
worker-1:5782:5866 [4] NCCL INFO Channel 14/0 : 4[4] -> 12[4] [send] via NET/IBext/0/GDRDMA
worker-1:5782:5866 [4] NCCL INFO Channel 15/0 : 4[4] -> 12[4] [send] via NET/IBext/0/GDRDMA
worker-1:5782:5866 [4] NCCL INFO Connected NVLS tree
worker-1:5782:5866 [4] NCCL INFO threadThresholds 8/8/64 | 128/8/64 | 512 | 512
worker-1:5774:5863 [7] NCCL INFO Channel 02/0 : 7[7] -> 0[0] via P2P/CUMEM
worker-1:5774:5863 [7] NCCL INFO Channel 03/0 : 7[7] -> 0[0] via P2P/CUMEM
worker-1:5774:5863 [7] NCCL INFO Channel 04/0 : 7[7] -> 0[0] via P2P/CUMEM
worker-1:5774:5863 [7] NCCL INFO Channel 05/0 : 7[7] -> 0[0] via P2P/CUMEM
worker-1:5774:5863 [7] NCCL INFO Channel 06/0 : 7[7] -> 0[0] via P2P/CUMEM
worker-1:5774:5863 [7] NCCL INFO Channel 07/0 : 7[7] -> 0[0] via P2P/CUMEM
worker-1:5774:5863 [7] NCCL INFO Channel 09/0 : 7[7] -> 0[0] via P2P/CUMEM
worker-1:5774:5863 [7] NCCL INFO Channel 10/0 : 7[7] -> 0[0] via P2P/CUMEM
worker-1:5774:5863 [7] NCCL INFO Channel 11/0 : 7[7] -> 0[0] via P2P/CUMEM
worker-1:5774:5863 [7] NCCL INFO Channel 12/0 : 7[7] -> 0[0] via P2P/CUMEM
worker-1:5774:5863 [7] NCCL INFO Channel 13/0 : 7[7] -> 0[0] via P2P/CUMEM
worker-1:5774:5863 [7] NCCL INFO Channel 14/0 : 7[7] -> 0[0] via P2P/CUMEM
worker-1:5774:5863 [7] NCCL INFO Channel 15/0 : 7[7] -> 0[0] via P2P/CUMEM
worker-1:5774:5863 [7] NCCL INFO Channel 06/0 : 7[7] -> 6[6] via P2P/CUMEM
worker-1:5774:5863 [7] NCCL INFO Channel 14/0 : 7[7] -> 6[6] via P2P/CUMEM
worker-1:5774:5863 [7] NCCL INFO Connected all trees
worker-1:5774:5863 [7] NCCL INFO NVLS comm 0x5592d3c98590 headRank 7 nHeads 8 buffSize 4194304 memSize 2097152 nvlsPerRankSize 201326592 nvlsTotalSize 1610612736
worker-1:5774:5863 [7] NCCL INFO Channel 00/0 : 15[7] -> 7[7] [receive] via NET/IBext/3/GDRDMA
worker-1:5774:5863 [7] NCCL INFO Channel 01/0 : 15[7] -> 7[7] [receive] via NET/IBext/3/GDRDMA
worker-1:5774:5863 [7] NCCL INFO Channel 02/0 : 15[7] -> 7[7] [receive] via NET/IBext/3/GDRDMA
worker-1:5774:5863 [7] NCCL INFO Channel 03/0 : 15[7] -> 7[7] [receive] via NET/IBext/3/GDRDMA
worker-1:5774:5863 [7] NCCL INFO Channel 04/0 : 15[7] -> 7[7] [receive] via NET/IBext/3/GDRDMA
worker-1:5774:5863 [7] NCCL INFO Channel 05/0 : 15[7] -> 7[7] [receive] via NET/IBext/3/GDRDMA
worker-1:5774:5863 [7] NCCL INFO Channel 06/0 : 15[7] -> 7[7] [receive] via NET/IBext/3/GDRDMA
worker-1:5774:5863 [7] NCCL INFO Channel 08/0 : 15[7] -> 7[7] [receive] via NET/IBext/3/GDRDMA
worker-1:5774:5863 [7] NCCL INFO Channel 09/0 : 15[7] -> 7[7] [receive] via NET/IBext/3/GDRDMA
worker-1:5774:5863 [7] NCCL INFO Channel 10/0 : 15[7] -> 7[7] [receive] via NET/IBext/3/GDRDMA
worker-1:5774:5863 [7] NCCL INFO Channel 11/0 : 15[7] -> 7[7] [receive] via NET/IBext/3/GDRDMA
worker-1:5774:5863 [7] NCCL INFO Channel 12/0 : 15[7] -> 7[7] [receive] via NET/IBext/3/GDRDMA
worker-1:5774:5863 [7] NCCL INFO Channel 13/0 : 15[7] -> 7[7] [receive] via NET/IBext/3/GDRDMA
worker-1:5774:5863 [7] NCCL INFO Channel 14/0 : 15[7] -> 7[7] [receive] via NET/IBext/3/GDRDMA
worker-1:5774:5863 [7] NCCL INFO Channel 00/0 : 7[7] -> 15[7] [send] via NET/IBext/3/GDRDMA
worker-1:5774:5863 [7] NCCL INFO Channel 01/0 : 7[7] -> 15[7] [send] via NET/IBext/3/GDRDMA
worker-1:5774:5863 [7] NCCL INFO Channel 02/0 : 7[7] -> 15[7] [send] via NET/IBext/3/GDRDMA
worker-1:5774:5863 [7] NCCL INFO Channel 03/0 : 7[7] -> 15[7] [send] via NET/IBext/3/GDRDMA
worker-1:5774:5863 [7] NCCL INFO Channel 04/0 : 7[7] -> 15[7] [send] via NET/IBext/3/GDRDMA
worker-1:5774:5863 [7] NCCL INFO Channel 05/0 : 7[7] -> 15[7] [send] via NET/IBext/3/GDRDMA
worker-1:5774:5863 [7] NCCL INFO Channel 06/0 : 7[7] -> 15[7] [send] via NET/IBext/3/GDRDMA
worker-1:5774:5863 [7] NCCL INFO Channel 08/0 : 7[7] -> 15[7] [send] via NET/IBext/3/GDRDMA
worker-1:5774:5863 [7] NCCL INFO Channel 09/0 : 7[7] -> 15[7] [send] via NET/IBext/3/GDRDMA
worker-1:5774:5863 [7] NCCL INFO Channel 10/0 : 7[7] -> 15[7] [send] via NET/IBext/3/GDRDMA
worker-1:5774:5863 [7] NCCL INFO Channel 11/0 : 7[7] -> 15[7] [send] via NET/IBext/3/GDRDMA
worker-1:5774:5863 [7] NCCL INFO Channel 12/0 : 7[7] -> 15[7] [send] via NET/IBext/3/GDRDMA
worker-1:5774:5863 [7] NCCL INFO Channel 13/0 : 7[7] -> 15[7] [send] via NET/IBext/3/GDRDMA
worker-1:5774:5863 [7] NCCL INFO Channel 14/0 : 7[7] -> 15[7] [send] via NET/IBext/3/GDRDMA
worker-1:5774:5863 [7] NCCL INFO Connected NVLS tree
worker-1:5774:5863 [7] NCCL INFO threadThresholds 8/8/64 | 128/8/64 | 512 | 512
worker-1:5778:5868 [3] NCCL INFO Channel 06/0 : 3[3] -> 4[4] via P2P/CUMEM
worker-1:5778:5868 [3] NCCL INFO Channel 07/0 : 3[3] -> 4[4] via P2P/CUMEM
worker-1:5778:5868 [3] NCCL INFO Channel 08/0 : 3[3] -> 4[4] via P2P/CUMEM
worker-1:5778:5868 [3] NCCL INFO Channel 09/0 : 3[3] -> 4[4] via P2P/CUMEM
worker-1:5778:5868 [3] NCCL INFO Channel 10/0 : 3[3] -> 4[4] via P2P/CUMEM
worker-1:5778:5868 [3] NCCL INFO Channel 11/0 : 3[3] -> 4[4] via P2P/CUMEM
worker-1:5778:5868 [3] NCCL INFO Channel 13/0 : 3[3] -> 4[4] via P2P/CUMEM
worker-1:5778:5868 [3] NCCL INFO Channel 14/0 : 3[3] -> 4[4] via P2P/CUMEM
worker-1:5778:5868 [3] NCCL INFO Channel 15/0 : 3[3] -> 4[4] via P2P/CUMEM
worker-1:5778:5868 [3] NCCL INFO Channel 03/0 : 11[3] -> 3[3] [receive] via NET/IBext/7/GDRDMA
worker-1:5778:5868 [3] NCCL INFO Channel 11/0 : 11[3] -> 3[3] [receive] via NET/IBext/7/GDRDMA
worker-1:5778:5868 [3] NCCL INFO Channel 03/0 : 3[3] -> 11[3] [send] via NET/IBext/7/GDRDMA
worker-1:5778:5868 [3] NCCL INFO Channel 11/0 : 3[3] -> 11[3] [send] via NET/IBext/7/GDRDMA
worker-1:5778:5868 [3] NCCL INFO Channel 02/0 : 3[3] -> 2[2] via P2P/CUMEM
worker-1:5778:5868 [3] NCCL INFO Channel 10/0 : 3[3] -> 2[2] via P2P/CUMEM
worker-1:5778:5868 [3] NCCL INFO Connected all trees
worker-1:5778:5868 [3] NCCL INFO NVLS comm 0x557bfad72dd0 headRank 3 nHeads 8 buffSize 4194304 memSize 2097152 nvlsPerRankSize 201326592 nvlsTotalSize 1610612736
worker-1:5778:5868 [3] NCCL INFO Channel 00/0 : 11[3] -> 3[3] [receive] via NET/IBext/7/GDRDMA
worker-1:5778:5868 [3] NCCL INFO Channel 01/0 : 11[3] -> 3[3] [receive] via NET/IBext/7/GDRDMA
worker-1:5778:5868 [3] NCCL INFO Channel 02/0 : 11[3] -> 3[3] [receive] via NET/IBext/7/GDRDMA
worker-1:5778:5868 [3] NCCL INFO Channel 04/0 : 11[3] -> 3[3] [receive] via NET/IBext/7/GDRDMA
worker-1:5778:5868 [3] NCCL INFO Channel 05/0 : 11[3] -> 3[3] [receive] via NET/IBext/7/GDRDMA
worker-1:5778:5868 [3] NCCL INFO Channel 06/0 : 11[3] -> 3[3] [receive] via NET/IBext/7/GDRDMA
worker-1:5778:5868 [3] NCCL INFO Channel 07/0 : 11[3] -> 3[3] [receive] via NET/IBext/7/GDRDMA
worker-1:5778:5868 [3] NCCL INFO Channel 08/0 : 11[3] -> 3[3] [receive] via NET/IBext/7/GDRDMA
worker-1:5778:5868 [3] NCCL INFO Channel 09/0 : 11[3] -> 3[3] [receive] via NET/IBext/7/GDRDMA
worker-1:5778:5868 [3] NCCL INFO Channel 10/0 : 11[3] -> 3[3] [receive] via NET/IBext/7/GDRDMA
worker-1:5778:5868 [3] NCCL INFO Channel 12/0 : 11[3] -> 3[3] [receive] via NET/IBext/7/GDRDMA
worker-1:5778:5868 [3] NCCL INFO Channel 13/0 : 11[3] -> 3[3] [receive] via NET/IBext/7/GDRDMA
worker-1:5778:5868 [3] NCCL INFO Channel 14/0 : 11[3] -> 3[3] [receive] via NET/IBext/7/GDRDMA
worker-1:5778:5868 [3] NCCL INFO Channel 15/0 : 11[3] -> 3[3] [receive] via NET/IBext/7/GDRDMA
worker-1:5778:5868 [3] NCCL INFO Channel 00/0 : 3[3] -> 11[3] [send] via NET/IBext/7/GDRDMA
/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
worker-1:5778:5868 [3] NCCL INFO Channel 01/0 : 3[3] -> 11[3] [send] via NET/IBext/7/GDRDMA
worker-1:5778:5868 [3] NCCL INFO Channel 02/0 : 3[3] -> 11[3] [send] via NET/IBext/7/GDRDMA
worker-1:5778:5868 [3] NCCL INFO Channel 04/0 : 3[3] -> 11[3] [send] via NET/IBext/7/GDRDMA
worker-1:5778:5868 [3] NCCL INFO Channel 05/0 : 3[3] -> 11[3] [send] via NET/IBext/7/GDRDMA
worker-1:5778:5868 [3] NCCL INFO Channel 06/0 : 3[3] -> 11[3] [send] via NET/IBext/7/GDRDMA
worker-1:5778:5868 [3] NCCL INFO Channel 07/0 : 3[3] -> 11[3] [send] via NET/IBext/7/GDRDMA
worker-1:5778:5868 [3] NCCL INFO Channel 08/0 : 3[3] -> 11[3] [send] via NET/IBext/7/GDRDMA
worker-1:5778:5868 [3] NCCL INFO Channel 09/0 : 3[3] -> 11[3] [send] via NET/IBext/7/GDRDMA
worker-1:5778:5868 [3] NCCL INFO Channel 10/0 : 3[3] -> 11[3] [send] via NET/IBext/7/GDRDMA
worker-1:5778:5868 [3] NCCL INFO Channel 12/0 : 3[3] -> 11[3] [send] via NET/IBext/7/GDRDMA
worker-1:5778:5868 [3] NCCL INFO Channel 13/0 : 3[3] -> 11[3] [send] via NET/IBext/7/GDRDMA
/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
worker-1:5778:5868 [3] NCCL INFO Channel 14/0 : 3[3] -> 11[3] [send] via NET/IBext/7/GDRDMA
worker-1:5778:5868 [3] NCCL INFO Channel 15/0 : 3[3] -> 11[3] [send] via NET/IBext/7/GDRDMA
worker-1:5778:5868 [3] NCCL INFO Connected NVLS tree
/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
worker-1:5783:5865 [5] NCCL INFO Channel 07/0 : 5[5] -> 6[6] via P2P/CUMEM
worker-1:5783:5865 [5] NCCL INFO Channel 08/0 : 5[5] -> 6[6] via P2P/CUMEM
worker-1:5783:5865 [5] NCCL INFO Channel 09/0 : 5[5] -> 6[6] via P2P/CUMEM
worker-1:5783:5865 [5] NCCL INFO Channel 10/0 : 5[5] -> 6[6] via P2P/CUMEM
worker-1:5783:5865 [5] NCCL INFO Channel 11/0 : 5[5] -> 6[6] via P2P/CUMEM
worker-1:5783:5865 [5] NCCL INFO Channel 12/0 : 5[5] -> 6[6] via P2P/CUMEM
worker-1:5783:5865 [5] NCCL INFO Channel 13/0 : 5[5] -> 6[6] via P2P/CUMEM
worker-1:5783:5865 [5] NCCL INFO Channel 15/0 : 5[5] -> 6[6] via P2P/CUMEM
worker-1:5783:5865 [5] NCCL INFO Channel 05/0 : 13[5] -> 5[5] [receive] via NET/IBext/1/GDRDMA
worker-1:5783:5865 [5] NCCL INFO Channel 13/0 : 13[5] -> 5[5] [receive] via NET/IBext/1/GDRDMA
worker-1:5783:5865 [5] NCCL INFO Channel 05/0 : 5[5] -> 13[5] [send] via NET/IBext/1/GDRDMA
worker-1:5783:5865 [5] NCCL INFO Channel 13/0 : 5[5] -> 13[5] [send] via NET/IBext/1/GDRDMA
/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
worker-1:5783:5865 [5] NCCL INFO Channel 04/0 : 5[5] -> 4[4] via P2P/CUMEM
worker-1:5783:5865 [5] NCCL INFO Channel 12/0 : 5[5] -> 4[4] via P2P/CUMEM
worker-1:5783:5865 [5] NCCL INFO Connected all trees
worker-1:5783:5865 [5] NCCL INFO NVLS comm 0x557b6d2784a0 headRank 5 nHeads 8 buffSize 4194304 memSize 2097152 nvlsPerRankSize 201326592 nvlsTotalSize 1610612736
worker-1:5783:5865 [5] NCCL INFO Channel 00/0 : 13[5] -> 5[5] [receive] via NET/IBext/1/GDRDMA
worker-1:5783:5865 [5] NCCL INFO Channel 01/0 : 13[5] -> 5[5] [receive] via NET/IBext/1/GDRDMA
worker-1:5783:5865 [5] NCCL INFO Channel 02/0 : 13[5] -> 5[5] [receive] via NET/IBext/1/GDRDMA
worker-1:5783:5865 [5] NCCL INFO Channel 03/0 : 13[5] -> 5[5] [receive] via NET/IBext/1/GDRDMA
worker-1:5783:5865 [5] NCCL INFO Channel 04/0 : 13[5] -> 5[5] [receive] via NET/IBext/1/GDRDMA
worker-1:5783:5865 [5] NCCL INFO Channel 06/0 : 13[5] -> 5[5] [receive] via NET/IBext/1/GDRDMA
/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
worker-1:5783:5865 [5] NCCL INFO Channel 07/0 : 13[5] -> 5[5] [receive] via NET/IBext/1/GDRDMA
worker-1:5783:5865 [5] NCCL INFO Channel 08/0 : 13[5] -> 5[5] [receive] via NET/IBext/1/GDRDMA
worker-1:5783:5865 [5] NCCL INFO Channel 09/0 : 13[5] -> 5[5] [receive] via NET/IBext/1/GDRDMA
worker-1:5783:5865 [5] NCCL INFO Channel 10/0 : 13[5] -> 5[5] [receive] via NET/IBext/1/GDRDMA
worker-1:5783:5865 [5] NCCL INFO Channel 11/0 : 13[5] -> 5[5] [receive] via NET/IBext/1/GDRDMA
worker-1:5783:5865 [5] NCCL INFO Channel 12/0 : 13[5] -> 5[5] [receive] via NET/IBext/1/GDRDMA
worker-1:5783:5865 [5] NCCL INFO Channel 14/0 : 13[5] -> 5[5] [receive] via NET/IBext/1/GDRDMA
worker-1:5783:5865 [5] NCCL INFO Channel 15/0 : 13[5] -> 5[5] [receive] via NET/IBext/1/GDRDMA
worker-1:5783:5865 [5] NCCL INFO Channel 00/0 : 5[5] -> 13[5] [send] via NET/IBext/1/GDRDMA
worker-1:5783:5865 [5] NCCL INFO Channel 01/0 : 5[5] -> 13[5] [send] via NET/IBext/1/GDRDMA
/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
worker-1:5783:5865 [5] NCCL INFO Channel 02/0 : 5[5] -> 13[5] [send] via NET/IBext/1/GDRDMA
worker-1:5783:5865 [5] NCCL INFO Channel 03/0 : 5[5] -> 13[5] [send] via NET/IBext/1/GDRDMA
worker-1:5783:5865 [5] NCCL INFO Channel 04/0 : 5[5] -> 13[5] [send] via NET/IBext/1/GDRDMA
worker-1:5783:5865 [5] NCCL INFO Channel 06/0 : 5[5] -> 13[5] [send] via NET/IBext/1/GDRDMA
worker-1:5783:5865 [5] NCCL INFO Channel 07/0 : 5[5] -> 13[5] [send] via NET/IBext/1/GDRDMA
worker-1:5783:5865 [5] NCCL INFO Channel 08/0 : 5[5] -> 13[5] [send] via NET/IBext/1/GDRDMA
worker-1:5783:5865 [5] NCCL INFO Channel 09/0 : 5[5] -> 13[5] [send] via NET/IBext/1/GDRDMA
worker-1:5783:5865 [5] NCCL INFO Channel 10/0 : 5[5] -> 13[5] [send] via NET/IBext/1/GDRDMA
worker-1:5783:5865 [5] NCCL INFO Channel 11/0 : 5[5] -> 13[5] [send] via NET/IBext/1/GDRDMA
worker-1:5783:5865 [5] NCCL INFO Channel 12/0 : 5[5] -> 13[5] [send] via NET/IBext/1/GDRDMA
worker-1:5783:5865 [5] NCCL INFO Channel 14/0 : 5[5] -> 13[5] [send] via NET/IBext/1/GDRDMA
/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
worker-1:5783:5865 [5] NCCL INFO Channel 15/0 : 5[5] -> 13[5] [send] via NET/IBext/1/GDRDMA
worker-1:5783:5865 [5] NCCL INFO Connected NVLS tree
worker-1:5783:5865 [5] NCCL INFO threadThresholds 8/8/64 | 128/8/64 | 512 | 512
/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
worker-1:5788:5870 [1] NCCL INFO Channel 06/0 : 1[1] -> 2[2] via P2P/CUMEM
worker-1:5788:5870 [1] NCCL INFO Channel 07/0 : 1[1] -> 2[2] via P2P/CUMEM
worker-1:5788:5870 [1] NCCL INFO Channel 08/0 : 1[1] -> 2[2] via P2P/CUMEM
worker-1:5788:5870 [1] NCCL INFO Channel 09/0 : 1[1] -> 2[2] via P2P/CUMEM
worker-1:5788:5870 [1] NCCL INFO Channel 11/0 : 1[1] -> 2[2] via P2P/CUMEM
worker-1:5788:5870 [1] NCCL INFO Channel 12/0 : 1[1] -> 2[2] via P2P/CUMEM
worker-1:5788:5870 [1] NCCL INFO Channel 13/0 : 1[1] -> 2[2] via P2P/CUMEM
worker-1:5788:5870 [1] NCCL INFO Channel 14/0 : 1[1] -> 2[2] via P2P/CUMEM
worker-1:5788:5870 [1] NCCL INFO Channel 15/0 : 1[1] -> 2[2] via P2P/CUMEM
worker-1:5788:5870 [1] NCCL INFO Channel 01/0 : 9[1] -> 1[1] [receive] via NET/IBext/5/GDRDMA
worker-1:5788:5870 [1] NCCL INFO Channel 09/0 : 9[1] -> 1[1] [receive] via NET/IBext/5/GDRDMA
worker-1:5788:5870 [1] NCCL INFO Channel 01/0 : 1[1] -> 9[1] [send] via NET/IBext/5/GDRDMA
worker-1:5788:5870 [1] NCCL INFO Channel 09/0 : 1[1] -> 9[1] [send] via NET/IBext/5/GDRDMA
worker-1:5788:5870 [1] NCCL INFO Channel 00/0 : 1[1] -> 0[0] via P2P/CUMEM
worker-1:5788:5870 [1] NCCL INFO Channel 08/0 : 1[1] -> 0[0] via P2P/CUMEM
worker-1:5788:5870 [1] NCCL INFO Connected all trees
worker-1:5788:5870 [1] NCCL INFO NVLS comm 0x56195ea363f0 headRank 1 nHeads 8 buffSize 4194304 memSize 2097152 nvlsPerRankSize 201326592 nvlsTotalSize 1610612736
worker-1:5788:5870 [1] NCCL INFO Channel 00/0 : 9[1] -> 1[1] [receive] via NET/IBext/5/GDRDMA
worker-1:5788:5870 [1] NCCL INFO Channel 02/0 : 9[1] -> 1[1] [receive] via NET/IBext/5/GDRDMA
worker-1:5788:5870 [1] NCCL INFO Channel 03/0 : 9[1] -> 1[1] [receive] via NET/IBext/5/GDRDMA
worker-1:5788:5870 [1] NCCL INFO Channel 04/0 : 9[1] -> 1[1] [receive] via NET/IBext/5/GDRDMA
worker-1:5788:5870 [1] NCCL INFO Channel 05/0 : 9[1] -> 1[1] [receive] via NET/IBext/5/GDRDMA
worker-1:5788:5870 [1] NCCL INFO Channel 06/0 : 9[1] -> 1[1] [receive] via NET/IBext/5/GDRDMA
worker-1:5788:5870 [1] NCCL INFO Channel 07/0 : 9[1] -> 1[1] [receive] via NET/IBext/5/GDRDMA
worker-1:5788:5870 [1] NCCL INFO Channel 08/0 : 9[1] -> 1[1] [receive] via NET/IBext/5/GDRDMA
worker-1:5788:5870 [1] NCCL INFO Channel 10/0 : 9[1] -> 1[1] [receive] via NET/IBext/5/GDRDMA
worker-1:5788:5870 [1] NCCL INFO Channel 11/0 : 9[1] -> 1[1] [receive] via NET/IBext/5/GDRDMA
worker-1:5788:5870 [1] NCCL INFO Channel 12/0 : 9[1] -> 1[1] [receive] via NET/IBext/5/GDRDMA
worker-1:5788:5870 [1] NCCL INFO Channel 13/0 : 9[1] -> 1[1] [receive] via NET/IBext/5/GDRDMA
worker-1:5788:5870 [1] NCCL INFO Channel 14/0 : 9[1] -> 1[1] [receive] via NET/IBext/5/GDRDMA
worker-1:5788:5870 [1] NCCL INFO Channel 15/0 : 9[1] -> 1[1] [receive] via NET/IBext/5/GDRDMA
worker-1:5788:5870 [1] NCCL INFO Channel 00/0 : 1[1] -> 9[1] [send] via NET/IBext/5/GDRDMA
worker-1:5788:5870 [1] NCCL INFO Channel 02/0 : 1[1] -> 9[1] [send] via NET/IBext/5/GDRDMA
worker-1:5788:5870 [1] NCCL INFO Channel 03/0 : 1[1] -> 9[1] [send] via NET/IBext/5/GDRDMA
worker-1:5788:5870 [1] NCCL INFO Channel 04/0 : 1[1] -> 9[1] [send] via NET/IBext/5/GDRDMA
worker-1:5788:5870 [1] NCCL INFO Channel 05/0 : 1[1] -> 9[1] [send] via NET/IBext/5/GDRDMA
worker-1:5788:5870 [1] NCCL INFO Channel 06/0 : 1[1] -> 9[1] [send] via NET/IBext/5/GDRDMA
worker-1:5788:5870 [1] NCCL INFO Channel 07/0 : 1[1] -> 9[1] [send] via NET/IBext/5/GDRDMA
worker-1:5788:5870 [1] NCCL INFO Channel 08/0 : 1[1] -> 9[1] [send] via NET/IBext/5/GDRDMA
worker-1:5788:5870 [1] NCCL INFO Channel 10/0 : 1[1] -> 9[1] [send] via NET/IBext/5/GDRDMA
worker-1:5788:5870 [1] NCCL INFO Channel 11/0 : 1[1] -> 9[1] [send] via NET/IBext/5/GDRDMA
worker-1:5788:5870 [1] NCCL INFO Channel 12/0 : 1[1] -> 9[1] [send] via NET/IBext/5/GDRDMA
worker-1:5788:5870 [1] NCCL INFO Channel 13/0 : 1[1] -> 9[1] [send] via NET/IBext/5/GDRDMA
worker-1:5788:5870 [1] NCCL INFO Channel 14/0 : 1[1] -> 9[1] [send] via NET/IBext/5/GDRDMA
/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
worker-1:5788:5870 [1] NCCL INFO Channel 15/0 : 1[1] -> 9[1] [send] via NET/IBext/5/GDRDMA
worker-1:5788:5870 [1] NCCL INFO Connected NVLS tree
/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
worker-1:5789:5869 [6] NCCL INFO Channel 06/0 : 6[6] -> 7[7] via P2P/CUMEM
worker-1:5789:5869 [6] NCCL INFO Channel 08/0 : 6[6] -> 7[7] via P2P/CUMEM
worker-1:5789:5869 [6] NCCL INFO Channel 09/0 : 6[6] -> 7[7] via P2P/CUMEM
worker-1:5789:5869 [6] NCCL INFO Channel 10/0 : 6[6] -> 7[7] via P2P/CUMEM
worker-1:5789:5869 [6] NCCL INFO Channel 11/0 : 6[6] -> 7[7] via P2P/CUMEM
worker-1:5789:5869 [6] NCCL INFO Channel 12/0 : 6[6] -> 7[7] via P2P/CUMEM
worker-1:5789:5869 [6] NCCL INFO Channel 13/0 : 6[6] -> 7[7] via P2P/CUMEM
worker-1:5789:5869 [6] NCCL INFO Channel 14/0 : 6[6] -> 7[7] via P2P/CUMEM
worker-1:5789:5869 [6] NCCL INFO Channel 06/0 : 14[6] -> 6[6] [receive] via NET/IBext/2/GDRDMA
worker-1:5789:5869 [6] NCCL INFO Channel 14/0 : 14[6] -> 6[6] [receive] via NET/IBext/2/GDRDMA
worker-1:5789:5869 [6] NCCL INFO Channel 06/0 : 6[6] -> 14[6] [send] via NET/IBext/2/GDRDMA
worker-1:5789:5869 [6] NCCL INFO Channel 14/0 : 6[6] -> 14[6] [send] via NET/IBext/2/GDRDMA
/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
worker-1:5789:5869 [6] NCCL INFO Channel 05/0 : 6[6] -> 5[5] via P2P/CUMEM
worker-1:5789:5869 [6] NCCL INFO Channel 13/0 : 6[6] -> 5[5] via P2P/CUMEM
worker-1:5789:5869 [6] NCCL INFO Connected all trees
worker-1:5789:5869 [6] NCCL INFO NVLS comm 0x564f0897bdf0 headRank 6 nHeads 8 buffSize 4194304 memSize 2097152 nvlsPerRankSize 201326592 nvlsTotalSize 1610612736
worker-1:5789:5869 [6] NCCL INFO Channel 00/0 : 14[6] -> 6[6] [receive] via NET/IBext/2/GDRDMA
worker-1:5789:5869 [6] NCCL INFO Channel 01/0 : 14[6] -> 6[6] [receive] via NET/IBext/2/GDRDMA
worker-1:5789:5869 [6] NCCL INFO Channel 02/0 : 14[6] -> 6[6] [receive] via NET/IBext/2/GDRDMA
worker-1:5789:5869 [6] NCCL INFO Channel 03/0 : 14[6] -> 6[6] [receive] via NET/IBext/2/GDRDMA
worker-1:5789:5869 [6] NCCL INFO Channel 04/0 : 14[6] -> 6[6] [receive] via NET/IBext/2/GDRDMA
worker-1:5789:5869 [6] NCCL INFO Channel 05/0 : 14[6] -> 6[6] [receive] via NET/IBext/2/GDRDMA
/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
worker-1:5789:5869 [6] NCCL INFO Channel 07/0 : 14[6] -> 6[6] [receive] via NET/IBext/2/GDRDMA
worker-1:5789:5869 [6] NCCL INFO Channel 08/0 : 14[6] -> 6[6] [receive] via NET/IBext/2/GDRDMA
worker-1:5789:5869 [6] NCCL INFO Channel 09/0 : 14[6] -> 6[6] [receive] via NET/IBext/2/GDRDMA
worker-1:5789:5869 [6] NCCL INFO Channel 10/0 : 14[6] -> 6[6] [receive] via NET/IBext/2/GDRDMA
worker-1:5789:5869 [6] NCCL INFO Channel 11/0 : 14[6] -> 6[6] [receive] via NET/IBext/2/GDRDMA
worker-1:5789:5869 [6] NCCL INFO Channel 12/0 : 14[6] -> 6[6] [receive] via NET/IBext/2/GDRDMA
worker-1:5789:5869 [6] NCCL INFO Channel 13/0 : 14[6] -> 6[6] [receive] via NET/IBext/2/GDRDMA
worker-1:5789:5869 [6] NCCL INFO Channel 15/0 : 14[6] -> 6[6] [receive] via NET/IBext/2/GDRDMA
worker-1:5789:5869 [6] NCCL INFO Channel 00/0 : 6[6] -> 14[6] [send] via NET/IBext/2/GDRDMA
worker-1:5789:5869 [6] NCCL INFO Channel 01/0 : 6[6] -> 14[6] [send] via NET/IBext/2/GDRDMA
/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
worker-1:5789:5869 [6] NCCL INFO Channel 02/0 : 6[6] -> 14[6] [send] via NET/IBext/2/GDRDMA
worker-1:5789:5869 [6] NCCL INFO Channel 03/0 : 6[6] -> 14[6] [send] via NET/IBext/2/GDRDMA
worker-1:5789:5869 [6] NCCL INFO Channel 04/0 : 6[6] -> 14[6] [send] via NET/IBext/2/GDRDMA
worker-1:5789:5869 [6] NCCL INFO Channel 05/0 : 6[6] -> 14[6] [send] via NET/IBext/2/GDRDMA
worker-1:5789:5869 [6] NCCL INFO Channel 07/0 : 6[6] -> 14[6] [send] via NET/IBext/2/GDRDMA
worker-1:5789:5869 [6] NCCL INFO Channel 08/0 : 6[6] -> 14[6] [send] via NET/IBext/2/GDRDMA
worker-1:5789:5869 [6] NCCL INFO Channel 09/0 : 6[6] -> 14[6] [send] via NET/IBext/2/GDRDMA
worker-1:5789:5869 [6] NCCL INFO Channel 10/0 : 6[6] -> 14[6] [send] via NET/IBext/2/GDRDMA
worker-1:5789:5869 [6] NCCL INFO Channel 11/0 : 6[6] -> 14[6] [send] via NET/IBext/2/GDRDMA
worker-1:5789:5869 [6] NCCL INFO Channel 12/0 : 6[6] -> 14[6] [send] via NET/IBext/2/GDRDMA
worker-1:5789:5869 [6] NCCL INFO Channel 13/0 : 6[6] -> 14[6] [send] via NET/IBext/2/GDRDMA
/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
worker-1:5789:5869 [6] NCCL INFO Channel 15/0 : 6[6] -> 14[6] [send] via NET/IBext/2/GDRDMA
worker-1:5789:5869 [6] NCCL INFO Connected NVLS tree
worker-1:5789:5869 [6] NCCL INFO threadThresholds 8/8/64 | 128/8/64 | 512 | 512
/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Configure sharded model for LatentDiffusion
Deleting key model.diffusion_model.time_embed.0.weight from state_dict.
Deleting key model.diffusion_model.time_embed.0.bias from state_dict.
Deleting key model.diffusion_model.time_embed.2.weight from state_dict.
Deleting key model.diffusion_model.time_embed.2.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.0.0.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.0.0.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.1.0.in_layers.0.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.1.0.in_layers.0.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.1.0.in_layers.2.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.1.0.in_layers.2.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.1.0.emb_layers.1.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.1.0.emb_layers.1.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.1.0.out_layers.0.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.1.0.out_layers.0.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.1.0.out_layers.3.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.1.0.out_layers.3.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.1.1.norm.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.1.1.norm.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.1.1.proj_in.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.1.1.proj_in.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.1.1.transformer_blocks.0.attn1.to_q.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.1.1.transformer_blocks.0.attn1.to_k.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.1.1.transformer_blocks.0.attn1.to_v.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.1.1.transformer_blocks.0.attn1.to_out.0.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.1.1.transformer_blocks.0.attn1.to_out.0.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.1.1.transformer_blocks.0.ff.net.0.proj.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.1.1.transformer_blocks.0.ff.net.0.proj.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.1.1.transformer_blocks.0.ff.net.2.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.1.1.transformer_blocks.0.ff.net.2.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.1.1.transformer_blocks.0.attn2.to_q.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.1.1.transformer_blocks.0.attn2.to_k.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.1.1.transformer_blocks.0.attn2.to_v.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.1.1.transformer_blocks.0.attn2.to_out.0.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.1.1.transformer_blocks.0.attn2.to_out.0.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.1.1.transformer_blocks.0.norm1.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.1.1.transformer_blocks.0.norm1.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.1.1.transformer_blocks.0.norm2.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.1.1.transformer_blocks.0.norm2.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.1.1.transformer_blocks.0.norm3.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.1.1.transformer_blocks.0.norm3.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.1.1.proj_out.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.1.1.proj_out.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.2.0.in_layers.0.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.2.0.in_layers.0.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.2.0.in_layers.2.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.2.0.in_layers.2.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.2.0.emb_layers.1.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.2.0.emb_layers.1.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.2.0.out_layers.0.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.2.0.out_layers.0.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.2.0.out_layers.3.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.2.0.out_layers.3.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.2.1.norm.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.2.1.norm.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.2.1.proj_in.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.2.1.proj_in.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.2.1.transformer_blocks.0.attn1.to_q.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.2.1.transformer_blocks.0.attn1.to_k.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.2.1.transformer_blocks.0.attn1.to_v.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.2.1.transformer_blocks.0.attn1.to_out.0.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.2.1.transformer_blocks.0.attn1.to_out.0.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.2.1.transformer_blocks.0.ff.net.0.proj.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.2.1.transformer_blocks.0.ff.net.0.proj.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.2.1.transformer_blocks.0.ff.net.2.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.2.1.transformer_blocks.0.ff.net.2.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.2.1.transformer_blocks.0.attn2.to_q.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.2.1.transformer_blocks.0.attn2.to_k.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.2.1.transformer_blocks.0.attn2.to_v.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.2.1.transformer_blocks.0.attn2.to_out.0.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.2.1.transformer_blocks.0.attn2.to_out.0.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.2.1.transformer_blocks.0.norm1.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.2.1.transformer_blocks.0.norm1.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.2.1.transformer_blocks.0.norm2.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.2.1.transformer_blocks.0.norm2.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.2.1.transformer_blocks.0.norm3.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.2.1.transformer_blocks.0.norm3.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.2.1.proj_out.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.2.1.proj_out.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.3.0.op.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.3.0.op.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.4.0.in_layers.0.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.4.0.in_layers.0.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.4.0.in_layers.2.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.4.0.in_layers.2.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.4.0.emb_layers.1.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.4.0.emb_layers.1.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.4.0.out_layers.0.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.4.0.out_layers.0.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.4.0.out_layers.3.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.4.0.out_layers.3.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.4.0.skip_connection.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.4.0.skip_connection.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.4.1.norm.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.4.1.norm.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.4.1.proj_in.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.4.1.proj_in.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.4.1.transformer_blocks.0.attn1.to_q.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.4.1.transformer_blocks.0.attn1.to_k.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.4.1.transformer_blocks.0.attn1.to_v.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.4.1.transformer_blocks.0.attn1.to_out.0.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.4.1.transformer_blocks.0.attn1.to_out.0.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.4.1.transformer_blocks.0.ff.net.0.proj.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.4.1.transformer_blocks.0.ff.net.0.proj.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.4.1.transformer_blocks.0.ff.net.2.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.4.1.transformer_blocks.0.ff.net.2.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.4.1.transformer_blocks.0.attn2.to_q.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.4.1.transformer_blocks.0.attn2.to_k.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.4.1.transformer_blocks.0.attn2.to_v.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.4.1.transformer_blocks.0.attn2.to_out.0.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.4.1.transformer_blocks.0.attn2.to_out.0.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.4.1.transformer_blocks.0.norm1.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.4.1.transformer_blocks.0.norm1.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.4.1.transformer_blocks.0.norm2.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.4.1.transformer_blocks.0.norm2.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.4.1.transformer_blocks.0.norm3.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.4.1.transformer_blocks.0.norm3.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.4.1.proj_out.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.4.1.proj_out.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.5.0.in_layers.0.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.5.0.in_layers.0.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.5.0.in_layers.2.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.5.0.in_layers.2.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.5.0.emb_layers.1.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.5.0.emb_layers.1.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.5.0.out_layers.0.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.5.0.out_layers.0.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.5.0.out_layers.3.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.5.0.out_layers.3.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.5.1.norm.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.5.1.norm.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.5.1.proj_in.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.5.1.proj_in.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.5.1.transformer_blocks.0.attn1.to_q.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.5.1.transformer_blocks.0.attn1.to_k.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.5.1.transformer_blocks.0.attn1.to_v.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.5.1.transformer_blocks.0.attn1.to_out.0.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.5.1.transformer_blocks.0.attn1.to_out.0.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.5.1.transformer_blocks.0.ff.net.0.proj.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.5.1.transformer_blocks.0.ff.net.0.proj.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.5.1.transformer_blocks.0.ff.net.2.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.5.1.transformer_blocks.0.ff.net.2.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.5.1.transformer_blocks.0.attn2.to_q.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.5.1.transformer_blocks.0.attn2.to_k.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.5.1.transformer_blocks.0.attn2.to_v.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.5.1.transformer_blocks.0.attn2.to_out.0.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.5.1.transformer_blocks.0.attn2.to_out.0.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.5.1.transformer_blocks.0.norm1.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.5.1.transformer_blocks.0.norm1.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.5.1.transformer_blocks.0.norm2.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.5.1.transformer_blocks.0.norm2.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.5.1.transformer_blocks.0.norm3.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.5.1.transformer_blocks.0.norm3.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.5.1.proj_out.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.5.1.proj_out.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.6.0.op.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.6.0.op.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.7.0.in_layers.0.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.7.0.in_layers.0.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.7.0.in_layers.2.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.7.0.in_layers.2.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.7.0.emb_layers.1.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.7.0.emb_layers.1.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.7.0.out_layers.0.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.7.0.out_layers.0.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.7.0.out_layers.3.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.7.0.out_layers.3.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.7.0.skip_connection.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.7.0.skip_connection.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.7.1.norm.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.7.1.norm.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.7.1.proj_in.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.7.1.proj_in.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.7.1.transformer_blocks.0.attn1.to_q.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.7.1.transformer_blocks.0.attn1.to_k.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.7.1.transformer_blocks.0.attn1.to_v.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.7.1.transformer_blocks.0.attn1.to_out.0.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.7.1.transformer_blocks.0.attn1.to_out.0.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.7.1.transformer_blocks.0.ff.net.0.proj.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.7.1.transformer_blocks.0.ff.net.0.proj.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.7.1.transformer_blocks.0.ff.net.2.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.7.1.transformer_blocks.0.ff.net.2.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.7.1.transformer_blocks.0.attn2.to_q.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.7.1.transformer_blocks.0.attn2.to_k.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.7.1.transformer_blocks.0.attn2.to_v.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.7.1.transformer_blocks.0.attn2.to_out.0.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.7.1.transformer_blocks.0.attn2.to_out.0.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.7.1.transformer_blocks.0.norm1.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.7.1.transformer_blocks.0.norm1.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.7.1.transformer_blocks.0.norm2.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.7.1.transformer_blocks.0.norm2.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.7.1.transformer_blocks.0.norm3.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.7.1.transformer_blocks.0.norm3.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.7.1.proj_out.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.7.1.proj_out.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.8.0.in_layers.0.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.8.0.in_layers.0.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.8.0.in_layers.2.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.8.0.in_layers.2.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.8.0.emb_layers.1.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.8.0.emb_layers.1.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.8.0.out_layers.0.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.8.0.out_layers.0.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.8.0.out_layers.3.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.8.0.out_layers.3.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.8.1.norm.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.8.1.norm.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.8.1.proj_in.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.8.1.proj_in.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.8.1.transformer_blocks.0.attn1.to_q.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.8.1.transformer_blocks.0.attn1.to_k.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.8.1.transformer_blocks.0.attn1.to_v.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.8.1.transformer_blocks.0.attn1.to_out.0.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.8.1.transformer_blocks.0.attn1.to_out.0.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.8.1.transformer_blocks.0.ff.net.0.proj.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.8.1.transformer_blocks.0.ff.net.0.proj.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.8.1.transformer_blocks.0.ff.net.2.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.8.1.transformer_blocks.0.ff.net.2.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.8.1.transformer_blocks.0.attn2.to_q.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.8.1.transformer_blocks.0.attn2.to_k.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.8.1.transformer_blocks.0.attn2.to_v.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.8.1.transformer_blocks.0.attn2.to_out.0.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.8.1.transformer_blocks.0.attn2.to_out.0.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.8.1.transformer_blocks.0.norm1.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.8.1.transformer_blocks.0.norm1.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.8.1.transformer_blocks.0.norm2.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.8.1.transformer_blocks.0.norm2.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.8.1.transformer_blocks.0.norm3.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.8.1.transformer_blocks.0.norm3.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.8.1.proj_out.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.8.1.proj_out.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.9.0.op.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.9.0.op.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.10.0.in_layers.0.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.10.0.in_layers.0.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.10.0.in_layers.2.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.10.0.in_layers.2.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.10.0.emb_layers.1.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.10.0.emb_layers.1.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.10.0.out_layers.0.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.10.0.out_layers.0.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.10.0.out_layers.3.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.10.0.out_layers.3.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.11.0.in_layers.0.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.11.0.in_layers.0.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.11.0.in_layers.2.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.11.0.in_layers.2.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.11.0.emb_layers.1.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.11.0.emb_layers.1.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.11.0.out_layers.0.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.11.0.out_layers.0.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.11.0.out_layers.3.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.11.0.out_layers.3.bias from state_dict.
Deleting key model.diffusion_model.middle_block.0.in_layers.0.weight from state_dict.
Deleting key model.diffusion_model.middle_block.0.in_layers.0.bias from state_dict.
Deleting key model.diffusion_model.middle_block.0.in_layers.2.weight from state_dict.
Deleting key model.diffusion_model.middle_block.0.in_layers.2.bias from state_dict.
Deleting key model.diffusion_model.middle_block.0.emb_layers.1.weight from state_dict.
Deleting key model.diffusion_model.middle_block.0.emb_layers.1.bias from state_dict.
Deleting key model.diffusion_model.middle_block.0.out_layers.0.weight from state_dict.
Deleting key model.diffusion_model.middle_block.0.out_layers.0.bias from state_dict.
Deleting key model.diffusion_model.middle_block.0.out_layers.3.weight from state_dict.
Deleting key model.diffusion_model.middle_block.0.out_layers.3.bias from state_dict.
Deleting key model.diffusion_model.middle_block.1.norm.weight from state_dict.
Deleting key model.diffusion_model.middle_block.1.norm.bias from state_dict.
Deleting key model.diffusion_model.middle_block.1.proj_in.weight from state_dict.
Deleting key model.diffusion_model.middle_block.1.proj_in.bias from state_dict.
Deleting key model.diffusion_model.middle_block.1.transformer_blocks.0.attn1.to_q.weight from state_dict.
Deleting key model.diffusion_model.middle_block.1.transformer_blocks.0.attn1.to_k.weight from state_dict.
Deleting key model.diffusion_model.middle_block.1.transformer_blocks.0.attn1.to_v.weight from state_dict.
Deleting key model.diffusion_model.middle_block.1.transformer_blocks.0.attn1.to_out.0.weight from state_dict.
Deleting key model.diffusion_model.middle_block.1.transformer_blocks.0.attn1.to_out.0.bias from state_dict.
Deleting key model.diffusion_model.middle_block.1.transformer_blocks.0.ff.net.0.proj.weight from state_dict.
Deleting key model.diffusion_model.middle_block.1.transformer_blocks.0.ff.net.0.proj.bias from state_dict.
Deleting key model.diffusion_model.middle_block.1.transformer_blocks.0.ff.net.2.weight from state_dict.
Deleting key model.diffusion_model.middle_block.1.transformer_blocks.0.ff.net.2.bias from state_dict.
Deleting key model.diffusion_model.middle_block.1.transformer_blocks.0.attn2.to_q.weight from state_dict.
Deleting key model.diffusion_model.middle_block.1.transformer_blocks.0.attn2.to_k.weight from state_dict.
Deleting key model.diffusion_model.middle_block.1.transformer_blocks.0.attn2.to_v.weight from state_dict.
Deleting key model.diffusion_model.middle_block.1.transformer_blocks.0.attn2.to_out.0.weight from state_dict.
Deleting key model.diffusion_model.middle_block.1.transformer_blocks.0.attn2.to_out.0.bias from state_dict.
Deleting key model.diffusion_model.middle_block.1.transformer_blocks.0.norm1.weight from state_dict.
Deleting key model.diffusion_model.middle_block.1.transformer_blocks.0.norm1.bias from state_dict.
Deleting key model.diffusion_model.middle_block.1.transformer_blocks.0.norm2.weight from state_dict.
Deleting key model.diffusion_model.middle_block.1.transformer_blocks.0.norm2.bias from state_dict.
Deleting key model.diffusion_model.middle_block.1.transformer_blocks.0.norm3.weight from state_dict.
Deleting key model.diffusion_model.middle_block.1.transformer_blocks.0.norm3.bias from state_dict.
Deleting key model.diffusion_model.middle_block.1.proj_out.weight from state_dict.
Deleting key model.diffusion_model.middle_block.1.proj_out.bias from state_dict.
Deleting key model.diffusion_model.middle_block.2.in_layers.0.weight from state_dict.
Deleting key model.diffusion_model.middle_block.2.in_layers.0.bias from state_dict.
Deleting key model.diffusion_model.middle_block.2.in_layers.2.weight from state_dict.
Deleting key model.diffusion_model.middle_block.2.in_layers.2.bias from state_dict.
Deleting key model.diffusion_model.middle_block.2.emb_layers.1.weight from state_dict.
Deleting key model.diffusion_model.middle_block.2.emb_layers.1.bias from state_dict.
Deleting key model.diffusion_model.middle_block.2.out_layers.0.weight from state_dict.
Deleting key model.diffusion_model.middle_block.2.out_layers.0.bias from state_dict.
Deleting key model.diffusion_model.middle_block.2.out_layers.3.weight from state_dict.
Deleting key model.diffusion_model.middle_block.2.out_layers.3.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.0.0.in_layers.0.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.0.0.in_layers.0.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.0.0.in_layers.2.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.0.0.in_layers.2.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.0.0.emb_layers.1.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.0.0.emb_layers.1.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.0.0.out_layers.0.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.0.0.out_layers.0.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.0.0.out_layers.3.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.0.0.out_layers.3.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.0.0.skip_connection.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.0.0.skip_connection.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.1.0.in_layers.0.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.1.0.in_layers.0.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.1.0.in_layers.2.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.1.0.in_layers.2.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.1.0.emb_layers.1.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.1.0.emb_layers.1.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.1.0.out_layers.0.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.1.0.out_layers.0.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.1.0.out_layers.3.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.1.0.out_layers.3.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.1.0.skip_connection.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.1.0.skip_connection.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.2.0.in_layers.0.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.2.0.in_layers.0.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.2.0.in_layers.2.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.2.0.in_layers.2.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.2.0.emb_layers.1.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.2.0.emb_layers.1.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.2.0.out_layers.0.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.2.0.out_layers.0.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.2.0.out_layers.3.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.2.0.out_layers.3.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.2.0.skip_connection.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.2.0.skip_connection.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.2.1.conv.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.2.1.conv.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.3.0.in_layers.0.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.3.0.in_layers.0.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.3.0.in_layers.2.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.3.0.in_layers.2.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.3.0.emb_layers.1.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.3.0.emb_layers.1.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.3.0.out_layers.0.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.3.0.out_layers.0.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.3.0.out_layers.3.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.3.0.out_layers.3.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.3.0.skip_connection.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.3.0.skip_connection.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.3.1.norm.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.3.1.norm.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.3.1.proj_in.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.3.1.proj_in.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.3.1.transformer_blocks.0.attn1.to_q.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.3.1.transformer_blocks.0.attn1.to_k.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.3.1.transformer_blocks.0.attn1.to_v.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.3.1.transformer_blocks.0.attn1.to_out.0.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.3.1.transformer_blocks.0.attn1.to_out.0.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.3.1.transformer_blocks.0.ff.net.0.proj.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.3.1.transformer_blocks.0.ff.net.0.proj.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.3.1.transformer_blocks.0.ff.net.2.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.3.1.transformer_blocks.0.ff.net.2.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.3.1.transformer_blocks.0.attn2.to_q.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.3.1.transformer_blocks.0.attn2.to_k.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.3.1.transformer_blocks.0.attn2.to_v.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.3.1.transformer_blocks.0.attn2.to_out.0.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.3.1.transformer_blocks.0.attn2.to_out.0.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.3.1.transformer_blocks.0.norm1.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.3.1.transformer_blocks.0.norm1.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.3.1.transformer_blocks.0.norm2.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.3.1.transformer_blocks.0.norm2.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.3.1.transformer_blocks.0.norm3.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.3.1.transformer_blocks.0.norm3.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.3.1.proj_out.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.3.1.proj_out.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.4.0.in_layers.0.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.4.0.in_layers.0.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.4.0.in_layers.2.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.4.0.in_layers.2.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.4.0.emb_layers.1.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.4.0.emb_layers.1.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.4.0.out_layers.0.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.4.0.out_layers.0.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.4.0.out_layers.3.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.4.0.out_layers.3.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.4.0.skip_connection.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.4.0.skip_connection.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.4.1.norm.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.4.1.norm.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.4.1.proj_in.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.4.1.proj_in.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.4.1.transformer_blocks.0.attn1.to_q.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.4.1.transformer_blocks.0.attn1.to_k.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.4.1.transformer_blocks.0.attn1.to_v.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.4.1.transformer_blocks.0.attn1.to_out.0.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.4.1.transformer_blocks.0.attn1.to_out.0.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.4.1.transformer_blocks.0.ff.net.0.proj.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.4.1.transformer_blocks.0.ff.net.0.proj.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.4.1.transformer_blocks.0.ff.net.2.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.4.1.transformer_blocks.0.ff.net.2.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.4.1.transformer_blocks.0.attn2.to_q.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.4.1.transformer_blocks.0.attn2.to_k.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.4.1.transformer_blocks.0.attn2.to_v.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.4.1.transformer_blocks.0.attn2.to_out.0.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.4.1.transformer_blocks.0.attn2.to_out.0.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.4.1.transformer_blocks.0.norm1.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.4.1.transformer_blocks.0.norm1.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.4.1.transformer_blocks.0.norm2.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.4.1.transformer_blocks.0.norm2.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.4.1.transformer_blocks.0.norm3.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.4.1.transformer_blocks.0.norm3.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.4.1.proj_out.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.4.1.proj_out.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.5.0.in_layers.0.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.5.0.in_layers.0.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.5.0.in_layers.2.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.5.0.in_layers.2.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.5.0.emb_layers.1.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.5.0.emb_layers.1.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.5.0.out_layers.0.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.5.0.out_layers.0.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.5.0.out_layers.3.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.5.0.out_layers.3.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.5.0.skip_connection.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.5.0.skip_connection.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.5.1.norm.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.5.1.norm.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.5.1.proj_in.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.5.1.proj_in.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.5.1.transformer_blocks.0.attn1.to_q.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.5.1.transformer_blocks.0.attn1.to_k.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.5.1.transformer_blocks.0.attn1.to_v.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.5.1.transformer_blocks.0.attn1.to_out.0.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.5.1.transformer_blocks.0.attn1.to_out.0.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.5.1.transformer_blocks.0.ff.net.0.proj.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.5.1.transformer_blocks.0.ff.net.0.proj.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.5.1.transformer_blocks.0.ff.net.2.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.5.1.transformer_blocks.0.ff.net.2.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.5.1.transformer_blocks.0.attn2.to_q.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.5.1.transformer_blocks.0.attn2.to_k.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.5.1.transformer_blocks.0.attn2.to_v.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.5.1.transformer_blocks.0.attn2.to_out.0.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.5.1.transformer_blocks.0.attn2.to_out.0.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.5.1.transformer_blocks.0.norm1.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.5.1.transformer_blocks.0.norm1.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.5.1.transformer_blocks.0.norm2.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.5.1.transformer_blocks.0.norm2.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.5.1.transformer_blocks.0.norm3.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.5.1.transformer_blocks.0.norm3.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.5.1.proj_out.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.5.1.proj_out.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.5.2.conv.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.5.2.conv.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.6.0.in_layers.0.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.6.0.in_layers.0.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.6.0.in_layers.2.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.6.0.in_layers.2.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.6.0.emb_layers.1.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.6.0.emb_layers.1.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.6.0.out_layers.0.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.6.0.out_layers.0.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.6.0.out_layers.3.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.6.0.out_layers.3.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.6.0.skip_connection.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.6.0.skip_connection.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.6.1.norm.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.6.1.norm.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.6.1.proj_in.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.6.1.proj_in.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.6.1.transformer_blocks.0.attn1.to_q.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.6.1.transformer_blocks.0.attn1.to_k.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.6.1.transformer_blocks.0.attn1.to_v.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.6.1.transformer_blocks.0.attn1.to_out.0.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.6.1.transformer_blocks.0.attn1.to_out.0.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.6.1.transformer_blocks.0.ff.net.0.proj.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.6.1.transformer_blocks.0.ff.net.0.proj.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.6.1.transformer_blocks.0.ff.net.2.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.6.1.transformer_blocks.0.ff.net.2.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.6.1.transformer_blocks.0.attn2.to_q.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.6.1.transformer_blocks.0.attn2.to_k.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.6.1.transformer_blocks.0.attn2.to_v.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.6.1.transformer_blocks.0.attn2.to_out.0.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.6.1.transformer_blocks.0.attn2.to_out.0.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.6.1.transformer_blocks.0.norm1.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.6.1.transformer_blocks.0.norm1.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.6.1.transformer_blocks.0.norm2.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.6.1.transformer_blocks.0.norm2.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.6.1.transformer_blocks.0.norm3.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.6.1.transformer_blocks.0.norm3.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.6.1.proj_out.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.6.1.proj_out.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.7.0.in_layers.0.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.7.0.in_layers.0.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.7.0.in_layers.2.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.7.0.in_layers.2.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.7.0.emb_layers.1.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.7.0.emb_layers.1.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.7.0.out_layers.0.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.7.0.out_layers.0.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.7.0.out_layers.3.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.7.0.out_layers.3.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.7.0.skip_connection.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.7.0.skip_connection.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.7.1.norm.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.7.1.norm.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.7.1.proj_in.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.7.1.proj_in.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.7.1.transformer_blocks.0.attn1.to_q.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.7.1.transformer_blocks.0.attn1.to_k.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.7.1.transformer_blocks.0.attn1.to_v.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.7.1.transformer_blocks.0.attn1.to_out.0.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.7.1.transformer_blocks.0.attn1.to_out.0.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.7.1.transformer_blocks.0.ff.net.0.proj.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.7.1.transformer_blocks.0.ff.net.0.proj.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.7.1.transformer_blocks.0.ff.net.2.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.7.1.transformer_blocks.0.ff.net.2.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.7.1.transformer_blocks.0.attn2.to_q.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.7.1.transformer_blocks.0.attn2.to_k.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.7.1.transformer_blocks.0.attn2.to_v.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.7.1.transformer_blocks.0.attn2.to_out.0.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.7.1.transformer_blocks.0.attn2.to_out.0.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.7.1.transformer_blocks.0.norm1.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.7.1.transformer_blocks.0.norm1.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.7.1.transformer_blocks.0.norm2.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.7.1.transformer_blocks.0.norm2.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.7.1.transformer_blocks.0.norm3.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.7.1.transformer_blocks.0.norm3.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.7.1.proj_out.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.7.1.proj_out.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.8.0.in_layers.0.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.8.0.in_layers.0.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.8.0.in_layers.2.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.8.0.in_layers.2.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.8.0.emb_layers.1.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.8.0.emb_layers.1.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.8.0.out_layers.0.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.8.0.out_layers.0.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.8.0.out_layers.3.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.8.0.out_layers.3.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.8.0.skip_connection.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.8.0.skip_connection.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.8.1.norm.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.8.1.norm.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.8.1.proj_in.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.8.1.proj_in.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.8.1.transformer_blocks.0.attn1.to_q.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.8.1.transformer_blocks.0.attn1.to_k.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.8.1.transformer_blocks.0.attn1.to_v.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.8.1.transformer_blocks.0.attn1.to_out.0.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.8.1.transformer_blocks.0.attn1.to_out.0.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.8.1.transformer_blocks.0.ff.net.0.proj.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.8.1.transformer_blocks.0.ff.net.0.proj.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.8.1.transformer_blocks.0.ff.net.2.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.8.1.transformer_blocks.0.ff.net.2.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.8.1.transformer_blocks.0.attn2.to_q.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.8.1.transformer_blocks.0.attn2.to_k.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.8.1.transformer_blocks.0.attn2.to_v.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.8.1.transformer_blocks.0.attn2.to_out.0.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.8.1.transformer_blocks.0.attn2.to_out.0.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.8.1.transformer_blocks.0.norm1.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.8.1.transformer_blocks.0.norm1.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.8.1.transformer_blocks.0.norm2.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.8.1.transformer_blocks.0.norm2.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.8.1.transformer_blocks.0.norm3.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.8.1.transformer_blocks.0.norm3.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.8.1.proj_out.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.8.1.proj_out.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.8.2.conv.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.8.2.conv.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.9.0.in_layers.0.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.9.0.in_layers.0.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.9.0.in_layers.2.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.9.0.in_layers.2.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.9.0.emb_layers.1.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.9.0.emb_layers.1.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.9.0.out_layers.0.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.9.0.out_layers.0.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.9.0.out_layers.3.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.9.0.out_layers.3.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.9.0.skip_connection.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.9.0.skip_connection.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.9.1.norm.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.9.1.norm.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.9.1.proj_in.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.9.1.proj_in.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.9.1.transformer_blocks.0.attn1.to_q.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.9.1.transformer_blocks.0.attn1.to_k.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.9.1.transformer_blocks.0.attn1.to_v.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.9.1.transformer_blocks.0.attn1.to_out.0.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.9.1.transformer_blocks.0.attn1.to_out.0.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.9.1.transformer_blocks.0.ff.net.0.proj.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.9.1.transformer_blocks.0.ff.net.0.proj.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.9.1.transformer_blocks.0.ff.net.2.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.9.1.transformer_blocks.0.ff.net.2.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.9.1.transformer_blocks.0.attn2.to_q.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.9.1.transformer_blocks.0.attn2.to_k.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.9.1.transformer_blocks.0.attn2.to_v.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.9.1.transformer_blocks.0.attn2.to_out.0.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.9.1.transformer_blocks.0.attn2.to_out.0.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.9.1.transformer_blocks.0.norm1.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.9.1.transformer_blocks.0.norm1.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.9.1.transformer_blocks.0.norm2.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.9.1.transformer_blocks.0.norm2.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.9.1.transformer_blocks.0.norm3.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.9.1.transformer_blocks.0.norm3.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.9.1.proj_out.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.9.1.proj_out.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.10.0.in_layers.0.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.10.0.in_layers.0.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.10.0.in_layers.2.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.10.0.in_layers.2.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.10.0.emb_layers.1.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.10.0.emb_layers.1.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.10.0.out_layers.0.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.10.0.out_layers.0.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.10.0.out_layers.3.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.10.0.out_layers.3.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.10.0.skip_connection.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.10.0.skip_connection.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.10.1.norm.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.10.1.norm.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.10.1.proj_in.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.10.1.proj_in.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.10.1.transformer_blocks.0.attn1.to_q.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.10.1.transformer_blocks.0.attn1.to_k.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.10.1.transformer_blocks.0.attn1.to_v.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.10.1.transformer_blocks.0.attn1.to_out.0.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.10.1.transformer_blocks.0.attn1.to_out.0.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.10.1.transformer_blocks.0.ff.net.0.proj.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.10.1.transformer_blocks.0.ff.net.0.proj.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.10.1.transformer_blocks.0.ff.net.2.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.10.1.transformer_blocks.0.ff.net.2.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.10.1.transformer_blocks.0.attn2.to_q.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.10.1.transformer_blocks.0.attn2.to_k.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.10.1.transformer_blocks.0.attn2.to_v.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.10.1.transformer_blocks.0.attn2.to_out.0.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.10.1.transformer_blocks.0.attn2.to_out.0.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.10.1.transformer_blocks.0.norm1.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.10.1.transformer_blocks.0.norm1.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.10.1.transformer_blocks.0.norm2.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.10.1.transformer_blocks.0.norm2.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.10.1.transformer_blocks.0.norm3.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.10.1.transformer_blocks.0.norm3.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.10.1.proj_out.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.10.1.proj_out.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.11.0.in_layers.0.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.11.0.in_layers.0.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.11.0.in_layers.2.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.11.0.in_layers.2.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.11.0.emb_layers.1.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.11.0.emb_layers.1.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.11.0.out_layers.0.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.11.0.out_layers.0.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.11.0.out_layers.3.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.11.0.out_layers.3.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.11.0.skip_connection.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.11.0.skip_connection.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.11.1.norm.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.11.1.norm.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.11.1.proj_in.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.11.1.proj_in.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.11.1.transformer_blocks.0.attn1.to_q.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.11.1.transformer_blocks.0.attn1.to_k.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.11.1.transformer_blocks.0.attn1.to_v.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.11.1.transformer_blocks.0.attn1.to_out.0.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.11.1.transformer_blocks.0.attn1.to_out.0.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.11.1.transformer_blocks.0.ff.net.0.proj.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.11.1.transformer_blocks.0.ff.net.0.proj.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.11.1.transformer_blocks.0.ff.net.2.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.11.1.transformer_blocks.0.ff.net.2.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.11.1.transformer_blocks.0.attn2.to_q.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.11.1.transformer_blocks.0.attn2.to_k.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.11.1.transformer_blocks.0.attn2.to_v.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.11.1.transformer_blocks.0.attn2.to_out.0.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.11.1.transformer_blocks.0.attn2.to_out.0.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.11.1.transformer_blocks.0.norm1.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.11.1.transformer_blocks.0.norm1.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.11.1.transformer_blocks.0.norm2.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.11.1.transformer_blocks.0.norm2.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.11.1.transformer_blocks.0.norm3.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.11.1.transformer_blocks.0.norm3.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.11.1.proj_out.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.11.1.proj_out.bias from state_dict.
Deleting key model.diffusion_model.out.0.weight from state_dict.
Deleting key model.diffusion_model.out.0.bias from state_dict.
Deleting key model.diffusion_model.out.2.weight from state_dict.
Deleting key model.diffusion_model.out.2.bias from state_dict.
Restored from /checkpoints/sd/512-base-ema.ckpt with 686 missing and 2 unexpected keys
Missing Keys:
 ['model.diffusion_model.time_embed.0.weight', 'model.diffusion_model.time_embed.0.bias', 'model.diffusion_model.time_embed.2.weight', 'model.diffusion_model.time_embed.2.bias', 'model.diffusion_model.input_blocks.0.0.weight', 'model.diffusion_model.input_blocks.0.0.bias', 'model.diffusion_model.input_blocks.1.0.in_layers.0.weight', 'model.diffusion_model.input_blocks.1.0.in_layers.0.bias', 'model.diffusion_model.input_blocks.1.0.in_layers.2.weight', 'model.diffusion_model.input_blocks.1.0.in_layers.2.bias', 'model.diffusion_model.input_blocks.1.0.emb_layers.1.weight', 'model.diffusion_model.input_blocks.1.0.emb_layers.1.bias', 'model.diffusion_model.input_blocks.1.0.out_layers.0.weight', 'model.diffusion_model.input_blocks.1.0.out_layers.0.bias', 'model.diffusion_model.input_blocks.1.0.out_layers.3.weight', 'model.diffusion_model.input_blocks.1.0.out_layers.3.bias', 'model.diffusion_model.input_blocks.1.1.norm.weight', 'model.diffusion_model.input_blocks.1.1.norm.bias', 'model.diffusion_model.input_blocks.1.1.proj_in.weight', 'model.diffusion_model.input_blocks.1.1.proj_in.bias', 'model.diffusion_model.input_blocks.1.1.transformer_blocks.0.attn1.to_q.weight', 'model.diffusion_model.input_blocks.1.1.transformer_blocks.0.attn1.to_k.weight', 'model.diffusion_model.input_blocks.1.1.transformer_blocks.0.attn1.to_v.weight', 'model.diffusion_model.input_blocks.1.1.transformer_blocks.0.attn1.to_out.0.weight', 'model.diffusion_model.input_blocks.1.1.transformer_blocks.0.attn1.to_out.0.bias', 'model.diffusion_model.input_blocks.1.1.transformer_blocks.0.ff.net.0.proj.weight', 'model.diffusion_model.input_blocks.1.1.transformer_blocks.0.ff.net.0.proj.bias', 'model.diffusion_model.input_blocks.1.1.transformer_blocks.0.ff.net.2.weight', 'model.diffusion_model.input_blocks.1.1.transformer_blocks.0.ff.net.2.bias', 'model.diffusion_model.input_blocks.1.1.transformer_blocks.0.attn2.to_q.weight', 'model.diffusion_model.input_blocks.1.1.transformer_blocks.0.attn2.to_k.weight', 'model.diffusion_model.input_blocks.1.1.transformer_blocks.0.attn2.to_v.weight', 'model.diffusion_model.input_blocks.1.1.transformer_blocks.0.attn2.to_out.0.weight', 'model.diffusion_model.input_blocks.1.1.transformer_blocks.0.attn2.to_out.0.bias', 'model.diffusion_model.input_blocks.1.1.transformer_blocks.0.norm1.weight', 'model.diffusion_model.input_blocks.1.1.transformer_blocks.0.norm1.bias', 'model.diffusion_model.input_blocks.1.1.transformer_blocks.0.norm2.weight', 'model.diffusion_model.input_blocks.1.1.transformer_blocks.0.norm2.bias', 'model.diffusion_model.input_blocks.1.1.transformer_blocks.0.norm3.weight', 'model.diffusion_model.input_blocks.1.1.transformer_blocks.0.norm3.bias', 'model.diffusion_model.input_blocks.1.1.proj_out.weight', 'model.diffusion_model.input_blocks.1.1.proj_out.bias', 'model.diffusion_model.input_blocks.2.0.in_layers.0.weight', 'model.diffusion_model.input_blocks.2.0.in_layers.0.bias', 'model.diffusion_model.input_blocks.2.0.in_layers.2.weight', 'model.diffusion_model.input_blocks.2.0.in_layers.2.bias', 'model.diffusion_model.input_blocks.2.0.emb_layers.1.weight', 'model.diffusion_model.input_blocks.2.0.emb_layers.1.bias', 'model.diffusion_model.input_blocks.2.0.out_layers.0.weight', 'model.diffusion_model.input_blocks.2.0.out_layers.0.bias', 'model.diffusion_model.input_blocks.2.0.out_layers.3.weight', 'model.diffusion_model.input_blocks.2.0.out_layers.3.bias', 'model.diffusion_model.input_blocks.2.1.norm.weight', 'model.diffusion_model.input_blocks.2.1.norm.bias', 'model.diffusion_model.input_blocks.2.1.proj_in.weight', 'model.diffusion_model.input_blocks.2.1.proj_in.bias', 'model.diffusion_model.input_blocks.2.1.transformer_blocks.0.attn1.to_q.weight', 'model.diffusion_model.input_blocks.2.1.transformer_blocks.0.attn1.to_k.weight', 'model.diffusion_model.input_blocks.2.1.transformer_blocks.0.attn1.to_v.weight', 'model.diffusion_model.input_blocks.2.1.transformer_blocks.0.attn1.to_out.0.weight', 'model.diffusion_model.input_blocks.2.1.transformer_blocks.0.attn1.to_out.0.bias', 'model.diffusion_model.input_blocks.2.1.transformer_blocks.0.ff.net.0.proj.weight', 'model.diffusion_model.input_blocks.2.1.transformer_blocks.0.ff.net.0.proj.bias', 'model.diffusion_model.input_blocks.2.1.transformer_blocks.0.ff.net.2.weight', 'model.diffusion_model.input_blocks.2.1.transformer_blocks.0.ff.net.2.bias', 'model.diffusion_model.input_blocks.2.1.transformer_blocks.0.attn2.to_q.weight', 'model.diffusion_model.input_blocks.2.1.transformer_blocks.0.attn2.to_k.weight', 'model.diffusion_model.input_blocks.2.1.transformer_blocks.0.attn2.to_v.weight', 'model.diffusion_model.input_blocks.2.1.transformer_blocks.0.attn2.to_out.0.weight', 'model.diffusion_model.input_blocks.2.1.transformer_blocks.0.attn2.to_out.0.bias', 'model.diffusion_model.input_blocks.2.1.transformer_blocks.0.norm1.weight', 'model.diffusion_model.input_blocks.2.1.transformer_blocks.0.norm1.bias', 'model.diffusion_model.input_blocks.2.1.transformer_blocks.0.norm2.weight', 'model.diffusion_model.input_blocks.2.1.transformer_blocks.0.norm2.bias', 'model.diffusion_model.input_blocks.2.1.transformer_blocks.0.norm3.weight', 'model.diffusion_model.input_blocks.2.1.transformer_blocks.0.norm3.bias', 'model.diffusion_model.input_blocks.2.1.proj_out.weight', 'model.diffusion_model.input_blocks.2.1.proj_out.bias', 'model.diffusion_model.input_blocks.3.0.op.weight', 'model.diffusion_model.input_blocks.3.0.op.bias', 'model.diffusion_model.input_blocks.4.0.in_layers.0.weight', 'model.diffusion_model.input_blocks.4.0.in_layers.0.bias', 'model.diffusion_model.input_blocks.4.0.in_layers.2.weight', 'model.diffusion_model.input_blocks.4.0.in_layers.2.bias', 'model.diffusion_model.input_blocks.4.0.emb_layers.1.weight', 'model.diffusion_model.input_blocks.4.0.emb_layers.1.bias', 'model.diffusion_model.input_blocks.4.0.out_layers.0.weight', 'model.diffusion_model.input_blocks.4.0.out_layers.0.bias', 'model.diffusion_model.input_blocks.4.0.out_layers.3.weight', 'model.diffusion_model.input_blocks.4.0.out_layers.3.bias', 'model.diffusion_model.input_blocks.4.0.skip_connection.weight', 'model.diffusion_model.input_blocks.4.0.skip_connection.bias', 'model.diffusion_model.input_blocks.4.1.norm.weight', 'model.diffusion_model.input_blocks.4.1.norm.bias', 'model.diffusion_model.input_blocks.4.1.proj_in.weight', 'model.diffusion_model.input_blocks.4.1.proj_in.bias', 'model.diffusion_model.input_blocks.4.1.transformer_blocks.0.attn1.to_q.weight', 'model.diffusion_model.input_blocks.4.1.transformer_blocks.0.attn1.to_k.weight', 'model.diffusion_model.input_blocks.4.1.transformer_blocks.0.attn1.to_v.weight', 'model.diffusion_model.input_blocks.4.1.transformer_blocks.0.attn1.to_out.0.weight', 'model.diffusion_model.input_blocks.4.1.transformer_blocks.0.attn1.to_out.0.bias', 'model.diffusion_model.input_blocks.4.1.transformer_blocks.0.ff.net.0.proj.weight', 'model.diffusion_model.input_blocks.4.1.transformer_blocks.0.ff.net.0.proj.bias', 'model.diffusion_model.input_blocks.4.1.transformer_blocks.0.ff.net.2.weight', 'model.diffusion_model.input_blocks.4.1.transformer_blocks.0.ff.net.2.bias', 'model.diffusion_model.input_blocks.4.1.transformer_blocks.0.attn2.to_q.weight', 'model.diffusion_model.input_blocks.4.1.transformer_blocks.0.attn2.to_k.weight', 'model.diffusion_model.input_blocks.4.1.transformer_blocks.0.attn2.to_v.weight', 'model.diffusion_model.input_blocks.4.1.transformer_blocks.0.attn2.to_out.0.weight', 'model.diffusion_model.input_blocks.4.1.transformer_blocks.0.attn2.to_out.0.bias', 'model.diffusion_model.input_blocks.4.1.transformer_blocks.0.norm1.weight', 'model.diffusion_model.input_blocks.4.1.transformer_blocks.0.norm1.bias', 'model.diffusion_model.input_blocks.4.1.transformer_blocks.0.norm2.weight', 'model.diffusion_model.input_blocks.4.1.transformer_blocks.0.norm2.bias', 'model.diffusion_model.input_blocks.4.1.transformer_blocks.0.norm3.weight', 'model.diffusion_model.input_blocks.4.1.transformer_blocks.0.norm3.bias', 'model.diffusion_model.input_blocks.4.1.proj_out.weight', 'model.diffusion_model.input_blocks.4.1.proj_out.bias', 'model.diffusion_model.input_blocks.5.0.in_layers.0.weight', 'model.diffusion_model.input_blocks.5.0.in_layers.0.bias', 'model.diffusion_model.input_blocks.5.0.in_layers.2.weight', 'model.diffusion_model.input_blocks.5.0.in_layers.2.bias', 'model.diffusion_model.input_blocks.5.0.emb_layers.1.weight', 'model.diffusion_model.input_blocks.5.0.emb_layers.1.bias', 'model.diffusion_model.input_blocks.5.0.out_layers.0.weight', 'model.diffusion_model.input_blocks.5.0.out_layers.0.bias', 'model.diffusion_model.input_blocks.5.0.out_layers.3.weight', 'model.diffusion_model.input_blocks.5.0.out_layers.3.bias', 'model.diffusion_model.input_blocks.5.1.norm.weight', 'model.diffusion_model.input_blocks.5.1.norm.bias', 'model.diffusion_model.input_blocks.5.1.proj_in.weight', 'model.diffusion_model.input_blocks.5.1.proj_in.bias', 'model.diffusion_model.input_blocks.5.1.transformer_blocks.0.attn1.to_q.weight', 'model.diffusion_model.input_blocks.5.1.transformer_blocks.0.attn1.to_k.weight', 'model.diffusion_model.input_blocks.5.1.transformer_blocks.0.attn1.to_v.weight', 'model.diffusion_model.input_blocks.5.1.transformer_blocks.0.attn1.to_out.0.weight', 'model.diffusion_model.input_blocks.5.1.transformer_blocks.0.attn1.to_out.0.bias', 'model.diffusion_model.input_blocks.5.1.transformer_blocks.0.ff.net.0.proj.weight', 'model.diffusion_model.input_blocks.5.1.transformer_blocks.0.ff.net.0.proj.bias', 'model.diffusion_model.input_blocks.5.1.transformer_blocks.0.ff.net.2.weight', 'model.diffusion_model.input_blocks.5.1.transformer_blocks.0.ff.net.2.bias', 'model.diffusion_model.input_blocks.5.1.transformer_blocks.0.attn2.to_q.weight', 'model.diffusion_model.input_blocks.5.1.transformer_blocks.0.attn2.to_k.weight', 'model.diffusion_model.input_blocks.5.1.transformer_blocks.0.attn2.to_v.weight', 'model.diffusion_model.input_blocks.5.1.transformer_blocks.0.attn2.to_out.0.weight', 'model.diffusion_model.input_blocks.5.1.transformer_blocks.0.attn2.to_out.0.bias', 'model.diffusion_model.input_blocks.5.1.transformer_blocks.0.norm1.weight', 'model.diffusion_model.input_blocks.5.1.transformer_blocks.0.norm1.bias', 'model.diffusion_model.input_blocks.5.1.transformer_blocks.0.norm2.weight', 'model.diffusion_model.input_blocks.5.1.transformer_blocks.0.norm2.bias', 'model.diffusion_model.input_blocks.5.1.transformer_blocks.0.norm3.weight', 'model.diffusion_model.input_blocks.5.1.transformer_blocks.0.norm3.bias', 'model.diffusion_model.input_blocks.5.1.proj_out.weight', 'model.diffusion_model.input_blocks.5.1.proj_out.bias', 'model.diffusion_model.input_blocks.6.0.op.weight', 'model.diffusion_model.input_blocks.6.0.op.bias', 'model.diffusion_model.input_blocks.7.0.in_layers.0.weight', 'model.diffusion_model.input_blocks.7.0.in_layers.0.bias', 'model.diffusion_model.input_blocks.7.0.in_layers.2.weight', 'model.diffusion_model.input_blocks.7.0.in_layers.2.bias', 'model.diffusion_model.input_blocks.7.0.emb_layers.1.weight', 'model.diffusion_model.input_blocks.7.0.emb_layers.1.bias', 'model.diffusion_model.input_blocks.7.0.out_layers.0.weight', 'model.diffusion_model.input_blocks.7.0.out_layers.0.bias', 'model.diffusion_model.input_blocks.7.0.out_layers.3.weight', 'model.diffusion_model.input_blocks.7.0.out_layers.3.bias', 'model.diffusion_model.input_blocks.7.0.skip_connection.weight', 'model.diffusion_model.input_blocks.7.0.skip_connection.bias', 'model.diffusion_model.input_blocks.7.1.norm.weight', 'model.diffusion_model.input_blocks.7.1.norm.bias', 'model.diffusion_model.input_blocks.7.1.proj_in.weight', 'model.diffusion_model.input_blocks.7.1.proj_in.bias', 'model.diffusion_model.input_blocks.7.1.transformer_blocks.0.attn1.to_q.weight', 'model.diffusion_model.input_blocks.7.1.transformer_blocks.0.attn1.to_k.weight', 'model.diffusion_model.input_blocks.7.1.transformer_blocks.0.attn1.to_v.weight', 'model.diffusion_model.input_blocks.7.1.transformer_blocks.0.attn1.to_out.0.weight', 'model.diffusion_model.input_blocks.7.1.transformer_blocks.0.attn1.to_out.0.bias', 'model.diffusion_model.input_blocks.7.1.transformer_blocks.0.ff.net.0.proj.weight', 'model.diffusion_model.input_blocks.7.1.transformer_blocks.0.ff.net.0.proj.bias', 'model.diffusion_model.input_blocks.7.1.transformer_blocks.0.ff.net.2.weight', 'model.diffusion_model.input_blocks.7.1.transformer_blocks.0.ff.net.2.bias', 'model.diffusion_model.input_blocks.7.1.transformer_blocks.0.attn2.to_q.weight', 'model.diffusion_model.input_blocks.7.1.transformer_blocks.0.attn2.to_k.weight', 'model.diffusion_model.input_blocks.7.1.transformer_blocks.0.attn2.to_v.weight', 'model.diffusion_model.input_blocks.7.1.transformer_blocks.0.attn2.to_out.0.weight', 'model.diffusion_model.input_blocks.7.1.transformer_blocks.0.attn2.to_out.0.bias', 'model.diffusion_model.input_blocks.7.1.transformer_blocks.0.norm1.weight', 'model.diffusion_model.input_blocks.7.1.transformer_blocks.0.norm1.bias', 'model.diffusion_model.input_blocks.7.1.transformer_blocks.0.norm2.weight', 'model.diffusion_model.input_blocks.7.1.transformer_blocks.0.norm2.bias', 'model.diffusion_model.input_blocks.7.1.transformer_blocks.0.norm3.weight', 'model.diffusion_model.input_blocks.7.1.transformer_blocks.0.norm3.bias', 'model.diffusion_model.input_blocks.7.1.proj_out.weight', 'model.diffusion_model.input_blocks.7.1.proj_out.bias', 'model.diffusion_model.input_blocks.8.0.in_layers.0.weight', 'model.diffusion_model.input_blocks.8.0.in_layers.0.bias', 'model.diffusion_model.input_blocks.8.0.in_layers.2.weight', 'model.diffusion_model.input_blocks.8.0.in_layers.2.bias', 'model.diffusion_model.input_blocks.8.0.emb_layers.1.weight', 'model.diffusion_model.input_blocks.8.0.emb_layers.1.bias', 'model.diffusion_model.input_blocks.8.0.out_layers.0.weight', 'model.diffusion_model.input_blocks.8.0.out_layers.0.bias', 'model.diffusion_model.input_blocks.8.0.out_layers.3.weight', 'model.diffusion_model.input_blocks.8.0.out_layers.3.bias', 'model.diffusion_model.input_blocks.8.1.norm.weight', 'model.diffusion_model.input_blocks.8.1.norm.bias', 'model.diffusion_model.input_blocks.8.1.proj_in.weight', 'model.diffusion_model.input_blocks.8.1.proj_in.bias', 'model.diffusion_model.input_blocks.8.1.transformer_blocks.0.attn1.to_q.weight', 'model.diffusion_model.input_blocks.8.1.transformer_blocks.0.attn1.to_k.weight', 'model.diffusion_model.input_blocks.8.1.transformer_blocks.0.attn1.to_v.weight', 'model.diffusion_model.input_blocks.8.1.transformer_blocks.0.attn1.to_out.0.weight', 'model.diffusion_model.input_blocks.8.1.transformer_blocks.0.attn1.to_out.0.bias', 'model.diffusion_model.input_blocks.8.1.transformer_blocks.0.ff.net.0.proj.weight', 'model.diffusion_model.input_blocks.8.1.transformer_blocks.0.ff.net.0.proj.bias', 'model.diffusion_model.input_blocks.8.1.transformer_blocks.0.ff.net.2.weight', 'model.diffusion_model.input_blocks.8.1.transformer_blocks.0.ff.net.2.bias', 'model.diffusion_model.input_blocks.8.1.transformer_blocks.0.attn2.to_q.weight', 'model.diffusion_model.input_blocks.8.1.transformer_blocks.0.attn2.to_k.weight', 'model.diffusion_model.input_blocks.8.1.transformer_blocks.0.attn2.to_v.weight', 'model.diffusion_model.input_blocks.8.1.transformer_blocks.0.attn2.to_out.0.weight', 'model.diffusion_model.input_blocks.8.1.transformer_blocks.0.attn2.to_out.0.bias', 'model.diffusion_model.input_blocks.8.1.transformer_blocks.0.norm1.weight', 'model.diffusion_model.input_blocks.8.1.transformer_blocks.0.norm1.bias', 'model.diffusion_model.input_blocks.8.1.transformer_blocks.0.norm2.weight', 'model.diffusion_model.input_blocks.8.1.transformer_blocks.0.norm2.bias', 'model.diffusion_model.input_blocks.8.1.transformer_blocks.0.norm3.weight', 'model.diffusion_model.input_blocks.8.1.transformer_blocks.0.norm3.bias', 'model.diffusion_model.input_blocks.8.1.proj_out.weight', 'model.diffusion_model.input_blocks.8.1.proj_out.bias', 'model.diffusion_model.input_blocks.9.0.op.weight', 'model.diffusion_model.input_blocks.9.0.op.bias', 'model.diffusion_model.input_blocks.10.0.in_layers.0.weight', 'model.diffusion_model.input_blocks.10.0.in_layers.0.bias', 'model.diffusion_model.input_blocks.10.0.in_layers.2.weight', 'model.diffusion_model.input_blocks.10.0.in_layers.2.bias', 'model.diffusion_model.input_blocks.10.0.emb_layers.1.weight', 'model.diffusion_model.input_blocks.10.0.emb_layers.1.bias', 'model.diffusion_model.input_blocks.10.0.out_layers.0.weight', 'model.diffusion_model.input_blocks.10.0.out_layers.0.bias', 'model.diffusion_model.input_blocks.10.0.out_layers.3.weight', 'model.diffusion_model.input_blocks.10.0.out_layers.3.bias', 'model.diffusion_model.input_blocks.11.0.in_layers.0.weight', 'model.diffusion_model.input_blocks.11.0.in_layers.0.bias', 'model.diffusion_model.input_blocks.11.0.in_layers.2.weight', 'model.diffusion_model.input_blocks.11.0.in_layers.2.bias', 'model.diffusion_model.input_blocks.11.0.emb_layers.1.weight', 'model.diffusion_model.input_blocks.11.0.emb_layers.1.bias', 'model.diffusion_model.input_blocks.11.0.out_layers.0.weight', 'model.diffusion_model.input_blocks.11.0.out_layers.0.bias', 'model.diffusion_model.input_blocks.11.0.out_layers.3.weight', 'model.diffusion_model.input_blocks.11.0.out_layers.3.bias', 'model.diffusion_model.middle_block.0.in_layers.0.weight', 'model.diffusion_model.middle_block.0.in_layers.0.bias', 'model.diffusion_model.middle_block.0.in_layers.2.weight', 'model.diffusion_model.middle_block.0.in_layers.2.bias', 'model.diffusion_model.middle_block.0.emb_layers.1.weight', 'model.diffusion_model.middle_block.0.emb_layers.1.bias', 'model.diffusion_model.middle_block.0.out_layers.0.weight', 'model.diffusion_model.middle_block.0.out_layers.0.bias', 'model.diffusion_model.middle_block.0.out_layers.3.weight', 'model.diffusion_model.middle_block.0.out_layers.3.bias', 'model.diffusion_model.middle_block.1.norm.weight', 'model.diffusion_model.middle_block.1.norm.bias', 'model.diffusion_model.middle_block.1.proj_in.weight', 'model.diffusion_model.middle_block.1.proj_in.bias', 'model.diffusion_model.middle_block.1.transformer_blocks.0.attn1.to_q.weight', 'model.diffusion_model.middle_block.1.transformer_blocks.0.attn1.to_k.weight', 'model.diffusion_model.middle_block.1.transformer_blocks.0.attn1.to_v.weight', 'model.diffusion_model.middle_block.1.transformer_blocks.0.attn1.to_out.0.weight', 'model.diffusion_model.middle_block.1.transformer_blocks.0.attn1.to_out.0.bias', 'model.diffusion_model.middle_block.1.transformer_blocks.0.ff.net.0.proj.weight', 'model.diffusion_model.middle_block.1.transformer_blocks.0.ff.net.0.proj.bias', 'model.diffusion_model.middle_block.1.transformer_blocks.0.ff.net.2.weight', 'model.diffusion_model.middle_block.1.transformer_blocks.0.ff.net.2.bias', 'model.diffusion_model.middle_block.1.transformer_blocks.0.attn2.to_q.weight', 'model.diffusion_model.middle_block.1.transformer_blocks.0.attn2.to_k.weight', 'model.diffusion_model.middle_block.1.transformer_blocks.0.attn2.to_v.weight', 'model.diffusion_model.middle_block.1.transformer_blocks.0.attn2.to_out.0.weight', 'model.diffusion_model.middle_block.1.transformer_blocks.0.attn2.to_out.0.bias', 'model.diffusion_model.middle_block.1.transformer_blocks.0.norm1.weight', 'model.diffusion_model.middle_block.1.transformer_blocks.0.norm1.bias', 'model.diffusion_model.middle_block.1.transformer_blocks.0.norm2.weight', 'model.diffusion_model.middle_block.1.transformer_blocks.0.norm2.bias', 'model.diffusion_model.middle_block.1.transformer_blocks.0.norm3.weight', 'model.diffusion_model.middle_block.1.transformer_blocks.0.norm3.bias', 'model.diffusion_model.middle_block.1.proj_out.weight', 'model.diffusion_model.middle_block.1.proj_out.bias', 'model.diffusion_model.middle_block.2.in_layers.0.weight', 'model.diffusion_model.middle_block.2.in_layers.0.bias', 'model.diffusion_model.middle_block.2.in_layers.2.weight', 'model.diffusion_model.middle_block.2.in_layers.2.bias', 'model.diffusion_model.middle_block.2.emb_layers.1.weight', 'model.diffusion_model.middle_block.2.emb_layers.1.bias', 'model.diffusion_model.middle_block.2.out_layers.0.weight', 'model.diffusion_model.middle_block.2.out_layers.0.bias', 'model.diffusion_model.middle_block.2.out_layers.3.weight', 'model.diffusion_model.middle_block.2.out_layers.3.bias', 'model.diffusion_model.output_blocks.0.0.in_layers.0.weight', 'model.diffusion_model.output_blocks.0.0.in_layers.0.bias', 'model.diffusion_model.output_blocks.0.0.in_layers.2.weight', 'model.diffusion_model.output_blocks.0.0.in_layers.2.bias', 'model.diffusion_model.output_blocks.0.0.emb_layers.1.weight', 'model.diffusion_model.output_blocks.0.0.emb_layers.1.bias', 'model.diffusion_model.output_blocks.0.0.out_layers.0.weight', 'model.diffusion_model.output_blocks.0.0.out_layers.0.bias', 'model.diffusion_model.output_blocks.0.0.out_layers.3.weight', 'model.diffusion_model.output_blocks.0.0.out_layers.3.bias', 'model.diffusion_model.output_blocks.0.0.skip_connection.weight', 'model.diffusion_model.output_blocks.0.0.skip_connection.bias', 'model.diffusion_model.output_blocks.1.0.in_layers.0.weight', 'model.diffusion_model.output_blocks.1.0.in_layers.0.bias', 'model.diffusion_model.output_blocks.1.0.in_layers.2.weight', 'model.diffusion_model.output_blocks.1.0.in_layers.2.bias', 'model.diffusion_model.output_blocks.1.0.emb_layers.1.weight', 'model.diffusion_model.output_blocks.1.0.emb_layers.1.bias', 'model.diffusion_model.output_blocks.1.0.out_layers.0.weight', 'model.diffusion_model.output_blocks.1.0.out_layers.0.bias', 'model.diffusion_model.output_blocks.1.0.out_layers.3.weight', 'model.diffusion_model.output_blocks.1.0.out_layers.3.bias', 'model.diffusion_model.output_blocks.1.0.skip_connection.weight', 'model.diffusion_model.output_blocks.1.0.skip_connection.bias', 'model.diffusion_model.output_blocks.2.0.in_layers.0.weight', 'model.diffusion_model.output_blocks.2.0.in_layers.0.bias', 'model.diffusion_model.output_blocks.2.0.in_layers.2.weight', 'model.diffusion_model.output_blocks.2.0.in_layers.2.bias', 'model.diffusion_model.output_blocks.2.0.emb_layers.1.weight', 'model.diffusion_model.output_blocks.2.0.emb_layers.1.bias', 'model.diffusion_model.output_blocks.2.0.out_layers.0.weight', 'model.diffusion_model.output_blocks.2.0.out_layers.0.bias', 'model.diffusion_model.output_blocks.2.0.out_layers.3.weight', 'model.diffusion_model.output_blocks.2.0.out_layers.3.bias', 'model.diffusion_model.output_blocks.2.0.skip_connection.weight', 'model.diffusion_model.output_blocks.2.0.skip_connection.bias', 'model.diffusion_model.output_blocks.2.1.conv.weight', 'model.diffusion_model.output_blocks.2.1.conv.bias', 'model.diffusion_model.output_blocks.3.0.in_layers.0.weight', 'model.diffusion_model.output_blocks.3.0.in_layers.0.bias', 'model.diffusion_model.output_blocks.3.0.in_layers.2.weight', 'model.diffusion_model.output_blocks.3.0.in_layers.2.bias', 'model.diffusion_model.output_blocks.3.0.emb_layers.1.weight', 'model.diffusion_model.output_blocks.3.0.emb_layers.1.bias', 'model.diffusion_model.output_blocks.3.0.out_layers.0.weight', 'model.diffusion_model.output_blocks.3.0.out_layers.0.bias', 'model.diffusion_model.output_blocks.3.0.out_layers.3.weight', 'model.diffusion_model.output_blocks.3.0.out_layers.3.bias', 'model.diffusion_model.output_blocks.3.0.skip_connection.weight', 'model.diffusion_model.output_blocks.3.0.skip_connection.bias', 'model.diffusion_model.output_blocks.3.1.norm.weight', 'model.diffusion_model.output_blocks.3.1.norm.bias', 'model.diffusion_model.output_blocks.3.1.proj_in.weight', 'model.diffusion_model.output_blocks.3.1.proj_in.bias', 'model.diffusion_model.output_blocks.3.1.transformer_blocks.0.attn1.to_q.weight', 'model.diffusion_model.output_blocks.3.1.transformer_blocks.0.attn1.to_k.weight', 'model.diffusion_model.output_blocks.3.1.transformer_blocks.0.attn1.to_v.weight', 'model.diffusion_model.output_blocks.3.1.transformer_blocks.0.attn1.to_out.0.weight', 'model.diffusion_model.output_blocks.3.1.transformer_blocks.0.attn1.to_out.0.bias', 'model.diffusion_model.output_blocks.3.1.transformer_blocks.0.ff.net.0.proj.weight', 'model.diffusion_model.output_blocks.3.1.transformer_blocks.0.ff.net.0.proj.bias', 'model.diffusion_model.output_blocks.3.1.transformer_blocks.0.ff.net.2.weight', 'model.diffusion_model.output_blocks.3.1.transformer_blocks.0.ff.net.2.bias', 'model.diffusion_model.output_blocks.3.1.transformer_blocks.0.attn2.to_q.weight', 'model.diffusion_model.output_blocks.3.1.transformer_blocks.0.attn2.to_k.weight', 'model.diffusion_model.output_blocks.3.1.transformer_blocks.0.attn2.to_v.weight', 'model.diffusion_model.output_blocks.3.1.transformer_blocks.0.attn2.to_out.0.weight', 'model.diffusion_model.output_blocks.3.1.transformer_blocks.0.attn2.to_out.0.bias', 'model.diffusion_model.output_blocks.3.1.transformer_blocks.0.norm1.weight', 'model.diffusion_model.output_blocks.3.1.transformer_blocks.0.norm1.bias', 'model.diffusion_model.output_blocks.3.1.transformer_blocks.0.norm2.weight', 'model.diffusion_model.output_blocks.3.1.transformer_blocks.0.norm2.bias', 'model.diffusion_model.output_blocks.3.1.transformer_blocks.0.norm3.weight', 'model.diffusion_model.output_blocks.3.1.transformer_blocks.0.norm3.bias', 'model.diffusion_model.output_blocks.3.1.proj_out.weight', 'model.diffusion_model.output_blocks.3.1.proj_out.bias', 'model.diffusion_model.output_blocks.4.0.in_layers.0.weight', 'model.diffusion_model.output_blocks.4.0.in_layers.0.bias', 'model.diffusion_model.output_blocks.4.0.in_layers.2.weight', 'model.diffusion_model.output_blocks.4.0.in_layers.2.bias', 'model.diffusion_model.output_blocks.4.0.emb_layers.1.weight', 'model.diffusion_model.output_blocks.4.0.emb_layers.1.bias', 'model.diffusion_model.output_blocks.4.0.out_layers.0.weight', 'model.diffusion_model.output_blocks.4.0.out_layers.0.bias', 'model.diffusion_model.output_blocks.4.0.out_layers.3.weight', 'model.diffusion_model.output_blocks.4.0.out_layers.3.bias', 'model.diffusion_model.output_blocks.4.0.skip_connection.weight', 'model.diffusion_model.output_blocks.4.0.skip_connection.bias', 'model.diffusion_model.output_blocks.4.1.norm.weight', 'model.diffusion_model.output_blocks.4.1.norm.bias', 'model.diffusion_model.output_blocks.4.1.proj_in.weight', 'model.diffusion_model.output_blocks.4.1.proj_in.bias', 'model.diffusion_model.output_blocks.4.1.transformer_blocks.0.attn1.to_q.weight', 'model.diffusion_model.output_blocks.4.1.transformer_blocks.0.attn1.to_k.weight', 'model.diffusion_model.output_blocks.4.1.transformer_blocks.0.attn1.to_v.weight', 'model.diffusion_model.output_blocks.4.1.transformer_blocks.0.attn1.to_out.0.weight', 'model.diffusion_model.output_blocks.4.1.transformer_blocks.0.attn1.to_out.0.bias', 'model.diffusion_model.output_blocks.4.1.transformer_blocks.0.ff.net.0.proj.weight', 'model.diffusion_model.output_blocks.4.1.transformer_blocks.0.ff.net.0.proj.bias', 'model.diffusion_model.output_blocks.4.1.transformer_blocks.0.ff.net.2.weight', 'model.diffusion_model.output_blocks.4.1.transformer_blocks.0.ff.net.2.bias', 'model.diffusion_model.output_blocks.4.1.transformer_blocks.0.attn2.to_q.weight', 'model.diffusion_model.output_blocks.4.1.transformer_blocks.0.attn2.to_k.weight', 'model.diffusion_model.output_blocks.4.1.transformer_blocks.0.attn2.to_v.weight', 'model.diffusion_model.output_blocks.4.1.transformer_blocks.0.attn2.to_out.0.weight', 'model.diffusion_model.output_blocks.4.1.transformer_blocks.0.attn2.to_out.0.bias', 'model.diffusion_model.output_blocks.4.1.transformer_blocks.0.norm1.weight', 'model.diffusion_model.output_blocks.4.1.transformer_blocks.0.norm1.bias', 'model.diffusion_model.output_blocks.4.1.transformer_blocks.0.norm2.weight', 'model.diffusion_model.output_blocks.4.1.transformer_blocks.0.norm2.bias', 'model.diffusion_model.output_blocks.4.1.transformer_blocks.0.norm3.weight', 'model.diffusion_model.output_blocks.4.1.transformer_blocks.0.norm3.bias', 'model.diffusion_model.output_blocks.4.1.proj_out.weight', 'model.diffusion_model.output_blocks.4.1.proj_out.bias', 'model.diffusion_model.output_blocks.5.0.in_layers.0.weight', 'model.diffusion_model.output_blocks.5.0.in_layers.0.bias', 'model.diffusion_model.output_blocks.5.0.in_layers.2.weight', 'model.diffusion_model.output_blocks.5.0.in_layers.2.bias', 'model.diffusion_model.output_blocks.5.0.emb_layers.1.weight', 'model.diffusion_model.output_blocks.5.0.emb_layers.1.bias', 'model.diffusion_model.output_blocks.5.0.out_layers.0.weight', 'model.diffusion_model.output_blocks.5.0.out_layers.0.bias', 'model.diffusion_model.output_blocks.5.0.out_layers.3.weight', 'model.diffusion_model.output_blocks.5.0.out_layers.3.bias', 'model.diffusion_model.output_blocks.5.0.skip_connection.weight', 'model.diffusion_model.output_blocks.5.0.skip_connection.bias', 'model.diffusion_model.output_blocks.5.1.norm.weight', 'model.diffusion_model.output_blocks.5.1.norm.bias', 'model.diffusion_model.output_blocks.5.1.proj_in.weight', 'model.diffusion_model.output_blocks.5.1.proj_in.bias', 'model.diffusion_model.output_blocks.5.1.transformer_blocks.0.attn1.to_q.weight', 'model.diffusion_model.output_blocks.5.1.transformer_blocks.0.attn1.to_k.weight', 'model.diffusion_model.output_blocks.5.1.transformer_blocks.0.attn1.to_v.weight', 'model.diffusion_model.output_blocks.5.1.transformer_blocks.0.attn1.to_out.0.weight', 'model.diffusion_model.output_blocks.5.1.transformer_blocks.0.attn1.to_out.0.bias', 'model.diffusion_model.output_blocks.5.1.transformer_blocks.0.ff.net.0.proj.weight', 'model.diffusion_model.output_blocks.5.1.transformer_blocks.0.ff.net.0.proj.bias', 'model.diffusion_model.output_blocks.5.1.transformer_blocks.0.ff.net.2.weight', 'model.diffusion_model.output_blocks.5.1.transformer_blocks.0.ff.net.2.bias', 'model.diffusion_model.output_blocks.5.1.transformer_blocks.0.attn2.to_q.weight', 'model.diffusion_model.output_blocks.5.1.transformer_blocks.0.attn2.to_k.weight', 'model.diffusion_model.output_blocks.5.1.transformer_blocks.0.attn2.to_v.weight', 'model.diffusion_model.output_blocks.5.1.transformer_blocks.0.attn2.to_out.0.weight', 'model.diffusion_model.output_blocks.5.1.transformer_blocks.0.attn2.to_out.0.bias', 'model.diffusion_model.output_blocks.5.1.transformer_blocks.0.norm1.weight', 'model.diffusion_model.output_blocks.5.1.transformer_blocks.0.norm1.bias', 'model.diffusion_model.output_blocks.5.1.transformer_blocks.0.norm2.weight', 'model.diffusion_model.output_blocks.5.1.transformer_blocks.0.norm2.bias', 'model.diffusion_model.output_blocks.5.1.transformer_blocks.0.norm3.weight', 'model.diffusion_model.output_blocks.5.1.transformer_blocks.0.norm3.bias', 'model.diffusion_model.output_blocks.5.1.proj_out.weight', 'model.diffusion_model.output_blocks.5.1.proj_out.bias', 'model.diffusion_model.output_blocks.5.2.conv.weight', 'model.diffusion_model.output_blocks.5.2.conv.bias', 'model.diffusion_model.output_blocks.6.0.in_layers.0.weight', 'model.diffusion_model.output_blocks.6.0.in_layers.0.bias', 'model.diffusion_model.output_blocks.6.0.in_layers.2.weight', 'model.diffusion_model.output_blocks.6.0.in_layers.2.bias', 'model.diffusion_model.output_blocks.6.0.emb_layers.1.weight', 'model.diffusion_model.output_blocks.6.0.emb_layers.1.bias', 'model.diffusion_model.output_blocks.6.0.out_layers.0.weight', 'model.diffusion_model.output_blocks.6.0.out_layers.0.bias', 'model.diffusion_model.output_blocks.6.0.out_layers.3.weight', 'model.diffusion_model.output_blocks.6.0.out_layers.3.bias', 'model.diffusion_model.output_blocks.6.0.skip_connection.weight', 'model.diffusion_model.output_blocks.6.0.skip_connection.bias', 'model.diffusion_model.output_blocks.6.1.norm.weight', 'model.diffusion_model.output_blocks.6.1.norm.bias', 'model.diffusion_model.output_blocks.6.1.proj_in.weight', 'model.diffusion_model.output_blocks.6.1.proj_in.bias', 'model.diffusion_model.output_blocks.6.1.transformer_blocks.0.attn1.to_q.weight', 'model.diffusion_model.output_blocks.6.1.transformer_blocks.0.attn1.to_k.weight', 'model.diffusion_model.output_blocks.6.1.transformer_blocks.0.attn1.to_v.weight', 'model.diffusion_model.output_blocks.6.1.transformer_blocks.0.attn1.to_out.0.weight', 'model.diffusion_model.output_blocks.6.1.transformer_blocks.0.attn1.to_out.0.bias', 'model.diffusion_model.output_blocks.6.1.transformer_blocks.0.ff.net.0.proj.weight', 'model.diffusion_model.output_blocks.6.1.transformer_blocks.0.ff.net.0.proj.bias', 'model.diffusion_model.output_blocks.6.1.transformer_blocks.0.ff.net.2.weight', 'model.diffusion_model.output_blocks.6.1.transformer_blocks.0.ff.net.2.bias', 'model.diffusion_model.output_blocks.6.1.transformer_blocks.0.attn2.to_q.weight', 'model.diffusion_model.output_blocks.6.1.transformer_blocks.0.attn2.to_k.weight', 'model.diffusion_model.output_blocks.6.1.transformer_blocks.0.attn2.to_v.weight', 'model.diffusion_model.output_blocks.6.1.transformer_blocks.0.attn2.to_out.0.weight', 'model.diffusion_model.output_blocks.6.1.transformer_blocks.0.attn2.to_out.0.bias', 'model.diffusion_model.output_blocks.6.1.transformer_blocks.0.norm1.weight', 'model.diffusion_model.output_blocks.6.1.transformer_blocks.0.norm1.bias', 'model.diffusion_model.output_blocks.6.1.transformer_blocks.0.norm2.weight', 'model.diffusion_model.output_blocks.6.1.transformer_blocks.0.norm2.bias', 'model.diffusion_model.output_blocks.6.1.transformer_blocks.0.norm3.weight', 'model.diffusion_model.output_blocks.6.1.transformer_blocks.0.norm3.bias', 'model.diffusion_model.output_blocks.6.1.proj_out.weight', 'model.diffusion_model.output_blocks.6.1.proj_out.bias', 'model.diffusion_model.output_blocks.7.0.in_layers.0.weight', 'model.diffusion_model.output_blocks.7.0.in_layers.0.bias', 'model.diffusion_model.output_blocks.7.0.in_layers.2.weight', 'model.diffusion_model.output_blocks.7.0.in_layers.2.bias', 'model.diffusion_model.output_blocks.7.0.emb_layers.1.weight', 'model.diffusion_model.output_blocks.7.0.emb_layers.1.bias', 'model.diffusion_model.output_blocks.7.0.out_layers.0.weight', 'model.diffusion_model.output_blocks.7.0.out_layers.0.bias', 'model.diffusion_model.output_blocks.7.0.out_layers.3.weight', 'model.diffusion_model.output_blocks.7.0.out_layers.3.bias', 'model.diffusion_model.output_blocks.7.0.skip_connection.weight', 'model.diffusion_model.output_blocks.7.0.skip_connection.bias', 'model.diffusion_model.output_blocks.7.1.norm.weight', 'model.diffusion_model.output_blocks.7.1.norm.bias', 'model.diffusion_model.output_blocks.7.1.proj_in.weight', 'model.diffusion_model.output_blocks.7.1.proj_in.bias', 'model.diffusion_model.output_blocks.7.1.transformer_blocks.0.attn1.to_q.weight', 'model.diffusion_model.output_blocks.7.1.transformer_blocks.0.attn1.to_k.weight', 'model.diffusion_model.output_blocks.7.1.transformer_blocks.0.attn1.to_v.weight', 'model.diffusion_model.output_blocks.7.1.transformer_blocks.0.attn1.to_out.0.weight', 'model.diffusion_model.output_blocks.7.1.transformer_blocks.0.attn1.to_out.0.bias', 'model.diffusion_model.output_blocks.7.1.transformer_blocks.0.ff.net.0.proj.weight', 'model.diffusion_model.output_blocks.7.1.transformer_blocks.0.ff.net.0.proj.bias', 'model.diffusion_model.output_blocks.7.1.transformer_blocks.0.ff.net.2.weight', 'model.diffusion_model.output_blocks.7.1.transformer_blocks.0.ff.net.2.bias', 'model.diffusion_model.output_blocks.7.1.transformer_blocks.0.attn2.to_q.weight', 'model.diffusion_model.output_blocks.7.1.transformer_blocks.0.attn2.to_k.weight', 'model.diffusion_model.output_blocks.7.1.transformer_blocks.0.attn2.to_v.weight', 'model.diffusion_model.output_blocks.7.1.transformer_blocks.0.attn2.to_out.0.weight', 'model.diffusion_model.output_blocks.7.1.transformer_blocks.0.attn2.to_out.0.bias', 'model.diffusion_model.output_blocks.7.1.transformer_blocks.0.norm1.weight', 'model.diffusion_model.output_blocks.7.1.transformer_blocks.0.norm1.bias', 'model.diffusion_model.output_blocks.7.1.transformer_blocks.0.norm2.weight', 'model.diffusion_model.output_blocks.7.1.transformer_blocks.0.norm2.bias', 'model.diffusion_model.output_blocks.7.1.transformer_blocks.0.norm3.weight', 'model.diffusion_model.output_blocks.7.1.transformer_blocks.0.norm3.bias', 'model.diffusion_model.output_blocks.7.1.proj_out.weight', 'model.diffusion_model.output_blocks.7.1.proj_out.bias', 'model.diffusion_model.output_blocks.8.0.in_layers.0.weight', 'model.diffusion_model.output_blocks.8.0.in_layers.0.bias', 'model.diffusion_model.output_blocks.8.0.in_layers.2.weight', 'model.diffusion_model.output_blocks.8.0.in_layers.2.bias', 'model.diffusion_model.output_blocks.8.0.emb_layers.1.weight', 'model.diffusion_model.output_blocks.8.0.emb_layers.1.bias', 'model.diffusion_model.output_blocks.8.0.out_layers.0.weight', 'model.diffusion_model.output_blocks.8.0.out_layers.0.bias', 'model.diffusion_model.output_blocks.8.0.out_layers.3.weight', 'model.diffusion_model.output_blocks.8.0.out_layers.3.bias', 'model.diffusion_model.output_blocks.8.0.skip_connection.weight', 'model.diffusion_model.output_blocks.8.0.skip_connection.bias', 'model.diffusion_model.output_blocks.8.1.norm.weight', 'model.diffusion_model.output_blocks.8.1.norm.bias', 'model.diffusion_model.output_blocks.8.1.proj_in.weight', 'model.diffusion_model.output_blocks.8.1.proj_in.bias', 'model.diffusion_model.output_blocks.8.1.transformer_blocks.0.attn1.to_q.weight', 'model.diffusion_model.output_blocks.8.1.transformer_blocks.0.attn1.to_k.weight', 'model.diffusion_model.output_blocks.8.1.transformer_blocks.0.attn1.to_v.weight', 'model.diffusion_model.output_blocks.8.1.transformer_blocks.0.attn1.to_out.0.weight', 'model.diffusion_model.output_blocks.8.1.transformer_blocks.0.attn1.to_out.0.bias', 'model.diffusion_model.output_blocks.8.1.transformer_blocks.0.ff.net.0.proj.weight', 'model.diffusion_model.output_blocks.8.1.transformer_blocks.0.ff.net.0.proj.bias', 'model.diffusion_model.output_blocks.8.1.transformer_blocks.0.ff.net.2.weight', 'model.diffusion_model.output_blocks.8.1.transformer_blocks.0.ff.net.2.bias', 'model.diffusion_model.output_blocks.8.1.transformer_blocks.0.attn2.to_q.weight', 'model.diffusion_model.output_blocks.8.1.transformer_blocks.0.attn2.to_k.weight', 'model.diffusion_model.output_blocks.8.1.transformer_blocks.0.attn2.to_v.weight', 'model.diffusion_model.output_blocks.8.1.transformer_blocks.0.attn2.to_out.0.weight', 'model.diffusion_model.output_blocks.8.1.transformer_blocks.0.attn2.to_out.0.bias', 'model.diffusion_model.output_blocks.8.1.transformer_blocks.0.norm1.weight', 'model.diffusion_model.output_blocks.8.1.transformer_blocks.0.norm1.bias', 'model.diffusion_model.output_blocks.8.1.transformer_blocks.0.norm2.weight', 'model.diffusion_model.output_blocks.8.1.transformer_blocks.0.norm2.bias', 'model.diffusion_model.output_blocks.8.1.transformer_blocks.0.norm3.weight', 'model.diffusion_model.output_blocks.8.1.transformer_blocks.0.norm3.bias', 'model.diffusion_model.output_blocks.8.1.proj_out.weight', 'model.diffusion_model.output_blocks.8.1.proj_out.bias', 'model.diffusion_model.output_blocks.8.2.conv.weight', 'model.diffusion_model.output_blocks.8.2.conv.bias', 'model.diffusion_model.output_blocks.9.0.in_layers.0.weight', 'model.diffusion_model.output_blocks.9.0.in_layers.0.bias', 'model.diffusion_model.output_blocks.9.0.in_layers.2.weight', 'model.diffusion_model.output_blocks.9.0.in_layers.2.bias', 'model.diffusion_model.output_blocks.9.0.emb_layers.1.weight', 'model.diffusion_model.output_blocks.9.0.emb_layers.1.bias', 'model.diffusion_model.output_blocks.9.0.out_layers.0.weight', 'model.diffusion_model.output_blocks.9.0.out_layers.0.bias', 'model.diffusion_model.output_blocks.9.0.out_layers.3.weight', 'model.diffusion_model.output_blocks.9.0.out_layers.3.bias', 'model.diffusion_model.output_blocks.9.0.skip_connection.weight', 'model.diffusion_model.output_blocks.9.0.skip_connection.bias', 'model.diffusion_model.output_blocks.9.1.norm.weight', 'model.diffusion_model.output_blocks.9.1.norm.bias', 'model.diffusion_model.output_blocks.9.1.proj_in.weight', 'model.diffusion_model.output_blocks.9.1.proj_in.bias', 'model.diffusion_model.output_blocks.9.1.transformer_blocks.0.attn1.to_q.weight', 'model.diffusion_model.output_blocks.9.1.transformer_blocks.0.attn1.to_k.weight', 'model.diffusion_model.output_blocks.9.1.transformer_blocks.0.attn1.to_v.weight', 'model.diffusion_model.output_blocks.9.1.transformer_blocks.0.attn1.to_out.0.weight', 'model.diffusion_model.output_blocks.9.1.transformer_blocks.0.attn1.to_out.0.bias', 'model.diffusion_model.output_blocks.9.1.transformer_blocks.0.ff.net.0.proj.weight', 'model.diffusion_model.output_blocks.9.1.transformer_blocks.0.ff.net.0.proj.bias', 'model.diffusion_model.output_blocks.9.1.transformer_blocks.0.ff.net.2.weight', 'model.diffusion_model.output_blocks.9.1.transformer_blocks.0.ff.net.2.bias', 'model.diffusion_model.output_blocks.9.1.transformer_blocks.0.attn2.to_q.weight', 'model.diffusion_model.output_blocks.9.1.transformer_blocks.0.attn2.to_k.weight', 'model.diffusion_model.output_blocks.9.1.transformer_blocks.0.attn2.to_v.weight', 'model.diffusion_model.output_blocks.9.1.transformer_blocks.0.attn2.to_out.0.weight', 'model.diffusion_model.output_blocks.9.1.transformer_blocks.0.attn2.to_out.0.bias', 'model.diffusion_model.output_blocks.9.1.transformer_blocks.0.norm1.weight', 'model.diffusion_model.output_blocks.9.1.transformer_blocks.0.norm1.bias', 'model.diffusion_model.output_blocks.9.1.transformer_blocks.0.norm2.weight', 'model.diffusion_model.output_blocks.9.1.transformer_blocks.0.norm2.bias', 'model.diffusion_model.output_blocks.9.1.transformer_blocks.0.norm3.weight', 'model.diffusion_model.output_blocks.9.1.transformer_blocks.0.norm3.bias', 'model.diffusion_model.output_blocks.9.1.proj_out.weight', 'model.diffusion_model.output_blocks.9.1.proj_out.bias', 'model.diffusion_model.output_blocks.10.0.in_layers.0.weight', 'model.diffusion_model.output_blocks.10.0.in_layers.0.bias', 'model.diffusion_model.output_blocks.10.0.in_layers.2.weight', 'model.diffusion_model.output_blocks.10.0.in_layers.2.bias', 'model.diffusion_model.output_blocks.10.0.emb_layers.1.weight', 'model.diffusion_model.output_blocks.10.0.emb_layers.1.bias', 'model.diffusion_model.output_blocks.10.0.out_layers.0.weight', 'model.diffusion_model.output_blocks.10.0.out_layers.0.bias', 'model.diffusion_model.output_blocks.10.0.out_layers.3.weight', 'model.diffusion_model.output_blocks.10.0.out_layers.3.bias', 'model.diffusion_model.output_blocks.10.0.skip_connection.weight', 'model.diffusion_model.output_blocks.10.0.skip_connection.bias', 'model.diffusion_model.output_blocks.10.1.norm.weight', 'model.diffusion_model.output_blocks.10.1.norm.bias', 'model.diffusion_model.output_blocks.10.1.proj_in.weight', 'model.diffusion_model.output_blocks.10.1.proj_in.bias', 'model.diffusion_model.output_blocks.10.1.transformer_blocks.0.attn1.to_q.weight', 'model.diffusion_model.output_blocks.10.1.transformer_blocks.0.attn1.to_k.weight', 'model.diffusion_model.output_blocks.10.1.transformer_blocks.0.attn1.to_v.weight', 'model.diffusion_model.output_blocks.10.1.transformer_blocks.0.attn1.to_out.0.weight', 'model.diffusion_model.output_blocks.10.1.transformer_blocks.0.attn1.to_out.0.bias', 'model.diffusion_model.output_blocks.10.1.transformer_blocks.0.ff.net.0.proj.weight', 'model.diffusion_model.output_blocks.10.1.transformer_blocks.0.ff.net.0.proj.bias', 'model.diffusion_model.output_blocks.10.1.transformer_blocks.0.ff.net.2.weight', 'model.diffusion_model.output_blocks.10.1.transformer_blocks.0.ff.net.2.bias', 'model.diffusion_model.output_blocks.10.1.transformer_blocks.0.attn2.to_q.weight', 'model.diffusion_model.output_blocks.10.1.transformer_blocks.0.attn2.to_k.weight', 'model.diffusion_model.output_blocks.10.1.transformer_blocks.0.attn2.to_v.weight', 'model.diffusion_model.output_blocks.10.1.transformer_blocks.0.attn2.to_out.0.weight', 'model.diffusion_model.output_blocks.10.1.transformer_blocks.0.attn2.to_out.0.bias', 'model.diffusion_model.output_blocks.10.1.transformer_blocks.0.norm1.weight', 'model.diffusion_model.output_blocks.10.1.transformer_blocks.0.norm1.bias', 'model.diffusion_model.output_blocks.10.1.transformer_blocks.0.norm2.weight', 'model.diffusion_model.output_blocks.10.1.transformer_blocks.0.norm2.bias', 'model.diffusion_model.output_blocks.10.1.transformer_blocks.0.norm3.weight', 'model.diffusion_model.output_blocks.10.1.transformer_blocks.0.norm3.bias', 'model.diffusion_model.output_blocks.10.1.proj_out.weight', 'model.diffusion_model.output_blocks.10.1.proj_out.bias', 'model.diffusion_model.output_blocks.11.0.in_layers.0.weight', 'model.diffusion_model.output_blocks.11.0.in_layers.0.bias', 'model.diffusion_model.output_blocks.11.0.in_layers.2.weight', 'model.diffusion_model.output_blocks.11.0.in_layers.2.bias', 'model.diffusion_model.output_blocks.11.0.emb_layers.1.weight', 'model.diffusion_model.output_blocks.11.0.emb_layers.1.bias', 'model.diffusion_model.output_blocks.11.0.out_layers.0.weight', 'model.diffusion_model.output_blocks.11.0.out_layers.0.bias', 'model.diffusion_model.output_blocks.11.0.out_layers.3.weight', 'model.diffusion_model.output_blocks.11.0.out_layers.3.bias', 'model.diffusion_model.output_blocks.11.0.skip_connection.weight', 'model.diffusion_model.output_blocks.11.0.skip_connection.bias', 'model.diffusion_model.output_blocks.11.1.norm.weight', 'model.diffusion_model.output_blocks.11.1.norm.bias', 'model.diffusion_model.output_blocks.11.1.proj_in.weight', 'model.diffusion_model.output_blocks.11.1.proj_in.bias', 'model.diffusion_model.output_blocks.11.1.transformer_blocks.0.attn1.to_q.weight', 'model.diffusion_model.output_blocks.11.1.transformer_blocks.0.attn1.to_k.weight', 'model.diffusion_model.output_blocks.11.1.transformer_blocks.0.attn1.to_v.weight', 'model.diffusion_model.output_blocks.11.1.transformer_blocks.0.attn1.to_out.0.weight', 'model.diffusion_model.output_blocks.11.1.transformer_blocks.0.attn1.to_out.0.bias', 'model.diffusion_model.output_blocks.11.1.transformer_blocks.0.ff.net.0.proj.weight', 'model.diffusion_model.output_blocks.11.1.transformer_blocks.0.ff.net.0.proj.bias', 'model.diffusion_model.output_blocks.11.1.transformer_blocks.0.ff.net.2.weight', 'model.diffusion_model.output_blocks.11.1.transformer_blocks.0.ff.net.2.bias', 'model.diffusion_model.output_blocks.11.1.transformer_blocks.0.attn2.to_q.weight', 'model.diffusion_model.output_blocks.11.1.transformer_blocks.0.attn2.to_k.weight', 'model.diffusion_model.output_blocks.11.1.transformer_blocks.0.attn2.to_v.weight', 'model.diffusion_model.output_blocks.11.1.transformer_blocks.0.attn2.to_out.0.weight', 'model.diffusion_model.output_blocks.11.1.transformer_blocks.0.attn2.to_out.0.bias', 'model.diffusion_model.output_blocks.11.1.transformer_blocks.0.norm1.weight', 'model.diffusion_model.output_blocks.11.1.transformer_blocks.0.norm1.bias', 'model.diffusion_model.output_blocks.11.1.transformer_blocks.0.norm2.weight', 'model.diffusion_model.output_blocks.11.1.transformer_blocks.0.norm2.bias', 'model.diffusion_model.output_blocks.11.1.transformer_blocks.0.norm3.weight', 'model.diffusion_model.output_blocks.11.1.transformer_blocks.0.norm3.bias', 'model.diffusion_model.output_blocks.11.1.proj_out.weight', 'model.diffusion_model.output_blocks.11.1.proj_out.bias', 'model.diffusion_model.out.0.weight', 'model.diffusion_model.out.0.bias', 'model.diffusion_model.out.2.weight', 'model.diffusion_model.out.2.bias']

Unexpected Keys:
 ['model_ema.decay', 'model_ema.num_updates']
building MemoryEfficientAttnBlock with 512 in_channels...
Working with z of shape (1, 4, 32, 32) = 4096 dimensions.
building MemoryEfficientAttnBlock with 512 in_channels...
Deleting key model.diffusion_model.time_embed.0.weight from state_dict.
Deleting key model.diffusion_model.time_embed.0.bias from state_dict.
Deleting key model.diffusion_model.time_embed.2.weight from state_dict.
Deleting key model.diffusion_model.time_embed.2.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.0.0.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.0.0.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.1.0.in_layers.0.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.1.0.in_layers.0.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.1.0.in_layers.2.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.1.0.in_layers.2.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.1.0.emb_layers.1.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.1.0.emb_layers.1.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.1.0.out_layers.0.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.1.0.out_layers.0.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.1.0.out_layers.3.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.1.0.out_layers.3.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.1.1.norm.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.1.1.norm.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.1.1.proj_in.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.1.1.proj_in.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.1.1.transformer_blocks.0.attn1.to_q.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.1.1.transformer_blocks.0.attn1.to_k.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.1.1.transformer_blocks.0.attn1.to_v.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.1.1.transformer_blocks.0.attn1.to_out.0.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.1.1.transformer_blocks.0.attn1.to_out.0.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.1.1.transformer_blocks.0.ff.net.0.proj.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.1.1.transformer_blocks.0.ff.net.0.proj.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.1.1.transformer_blocks.0.ff.net.2.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.1.1.transformer_blocks.0.ff.net.2.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.1.1.transformer_blocks.0.attn2.to_q.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.1.1.transformer_blocks.0.attn2.to_k.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.1.1.transformer_blocks.0.attn2.to_v.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.1.1.transformer_blocks.0.attn2.to_out.0.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.1.1.transformer_blocks.0.attn2.to_out.0.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.1.1.transformer_blocks.0.norm1.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.1.1.transformer_blocks.0.norm1.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.1.1.transformer_blocks.0.norm2.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.1.1.transformer_blocks.0.norm2.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.1.1.transformer_blocks.0.norm3.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.1.1.transformer_blocks.0.norm3.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.1.1.proj_out.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.1.1.proj_out.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.2.0.in_layers.0.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.2.0.in_layers.0.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.2.0.in_layers.2.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.2.0.in_layers.2.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.2.0.emb_layers.1.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.2.0.emb_layers.1.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.2.0.out_layers.0.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.2.0.out_layers.0.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.2.0.out_layers.3.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.2.0.out_layers.3.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.2.1.norm.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.2.1.norm.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.2.1.proj_in.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.2.1.proj_in.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.2.1.transformer_blocks.0.attn1.to_q.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.2.1.transformer_blocks.0.attn1.to_k.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.2.1.transformer_blocks.0.attn1.to_v.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.2.1.transformer_blocks.0.attn1.to_out.0.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.2.1.transformer_blocks.0.attn1.to_out.0.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.2.1.transformer_blocks.0.ff.net.0.proj.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.2.1.transformer_blocks.0.ff.net.0.proj.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.2.1.transformer_blocks.0.ff.net.2.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.2.1.transformer_blocks.0.ff.net.2.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.2.1.transformer_blocks.0.attn2.to_q.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.2.1.transformer_blocks.0.attn2.to_k.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.2.1.transformer_blocks.0.attn2.to_v.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.2.1.transformer_blocks.0.attn2.to_out.0.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.2.1.transformer_blocks.0.attn2.to_out.0.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.2.1.transformer_blocks.0.norm1.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.2.1.transformer_blocks.0.norm1.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.2.1.transformer_blocks.0.norm2.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.2.1.transformer_blocks.0.norm2.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.2.1.transformer_blocks.0.norm3.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.2.1.transformer_blocks.0.norm3.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.2.1.proj_out.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.2.1.proj_out.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.3.0.op.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.3.0.op.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.4.0.in_layers.0.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.4.0.in_layers.0.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.4.0.in_layers.2.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.4.0.in_layers.2.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.4.0.emb_layers.1.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.4.0.emb_layers.1.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.4.0.out_layers.0.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.4.0.out_layers.0.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.4.0.out_layers.3.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.4.0.out_layers.3.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.4.0.skip_connection.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.4.0.skip_connection.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.4.1.norm.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.4.1.norm.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.4.1.proj_in.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.4.1.proj_in.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.4.1.transformer_blocks.0.attn1.to_q.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.4.1.transformer_blocks.0.attn1.to_k.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.4.1.transformer_blocks.0.attn1.to_v.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.4.1.transformer_blocks.0.attn1.to_out.0.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.4.1.transformer_blocks.0.attn1.to_out.0.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.4.1.transformer_blocks.0.ff.net.0.proj.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.4.1.transformer_blocks.0.ff.net.0.proj.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.4.1.transformer_blocks.0.ff.net.2.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.4.1.transformer_blocks.0.ff.net.2.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.4.1.transformer_blocks.0.attn2.to_q.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.4.1.transformer_blocks.0.attn2.to_k.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.4.1.transformer_blocks.0.attn2.to_v.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.4.1.transformer_blocks.0.attn2.to_out.0.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.4.1.transformer_blocks.0.attn2.to_out.0.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.4.1.transformer_blocks.0.norm1.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.4.1.transformer_blocks.0.norm1.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.4.1.transformer_blocks.0.norm2.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.4.1.transformer_blocks.0.norm2.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.4.1.transformer_blocks.0.norm3.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.4.1.transformer_blocks.0.norm3.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.4.1.proj_out.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.4.1.proj_out.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.5.0.in_layers.0.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.5.0.in_layers.0.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.5.0.in_layers.2.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.5.0.in_layers.2.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.5.0.emb_layers.1.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.5.0.emb_layers.1.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.5.0.out_layers.0.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.5.0.out_layers.0.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.5.0.out_layers.3.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.5.0.out_layers.3.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.5.1.norm.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.5.1.norm.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.5.1.proj_in.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.5.1.proj_in.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.5.1.transformer_blocks.0.attn1.to_q.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.5.1.transformer_blocks.0.attn1.to_k.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.5.1.transformer_blocks.0.attn1.to_v.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.5.1.transformer_blocks.0.attn1.to_out.0.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.5.1.transformer_blocks.0.attn1.to_out.0.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.5.1.transformer_blocks.0.ff.net.0.proj.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.5.1.transformer_blocks.0.ff.net.0.proj.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.5.1.transformer_blocks.0.ff.net.2.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.5.1.transformer_blocks.0.ff.net.2.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.5.1.transformer_blocks.0.attn2.to_q.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.5.1.transformer_blocks.0.attn2.to_k.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.5.1.transformer_blocks.0.attn2.to_v.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.5.1.transformer_blocks.0.attn2.to_out.0.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.5.1.transformer_blocks.0.attn2.to_out.0.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.5.1.transformer_blocks.0.norm1.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.5.1.transformer_blocks.0.norm1.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.5.1.transformer_blocks.0.norm2.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.5.1.transformer_blocks.0.norm2.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.5.1.transformer_blocks.0.norm3.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.5.1.transformer_blocks.0.norm3.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.5.1.proj_out.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.5.1.proj_out.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.6.0.op.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.6.0.op.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.7.0.in_layers.0.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.7.0.in_layers.0.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.7.0.in_layers.2.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.7.0.in_layers.2.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.7.0.emb_layers.1.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.7.0.emb_layers.1.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.7.0.out_layers.0.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.7.0.out_layers.0.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.7.0.out_layers.3.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.7.0.out_layers.3.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.7.0.skip_connection.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.7.0.skip_connection.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.7.1.norm.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.7.1.norm.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.7.1.proj_in.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.7.1.proj_in.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.7.1.transformer_blocks.0.attn1.to_q.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.7.1.transformer_blocks.0.attn1.to_k.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.7.1.transformer_blocks.0.attn1.to_v.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.7.1.transformer_blocks.0.attn1.to_out.0.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.7.1.transformer_blocks.0.attn1.to_out.0.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.7.1.transformer_blocks.0.ff.net.0.proj.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.7.1.transformer_blocks.0.ff.net.0.proj.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.7.1.transformer_blocks.0.ff.net.2.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.7.1.transformer_blocks.0.ff.net.2.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.7.1.transformer_blocks.0.attn2.to_q.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.7.1.transformer_blocks.0.attn2.to_k.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.7.1.transformer_blocks.0.attn2.to_v.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.7.1.transformer_blocks.0.attn2.to_out.0.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.7.1.transformer_blocks.0.attn2.to_out.0.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.7.1.transformer_blocks.0.norm1.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.7.1.transformer_blocks.0.norm1.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.7.1.transformer_blocks.0.norm2.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.7.1.transformer_blocks.0.norm2.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.7.1.transformer_blocks.0.norm3.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.7.1.transformer_blocks.0.norm3.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.7.1.proj_out.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.7.1.proj_out.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.8.0.in_layers.0.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.8.0.in_layers.0.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.8.0.in_layers.2.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.8.0.in_layers.2.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.8.0.emb_layers.1.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.8.0.emb_layers.1.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.8.0.out_layers.0.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.8.0.out_layers.0.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.8.0.out_layers.3.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.8.0.out_layers.3.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.8.1.norm.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.8.1.norm.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.8.1.proj_in.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.8.1.proj_in.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.8.1.transformer_blocks.0.attn1.to_q.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.8.1.transformer_blocks.0.attn1.to_k.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.8.1.transformer_blocks.0.attn1.to_v.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.8.1.transformer_blocks.0.attn1.to_out.0.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.8.1.transformer_blocks.0.attn1.to_out.0.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.8.1.transformer_blocks.0.ff.net.0.proj.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.8.1.transformer_blocks.0.ff.net.0.proj.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.8.1.transformer_blocks.0.ff.net.2.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.8.1.transformer_blocks.0.ff.net.2.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.8.1.transformer_blocks.0.attn2.to_q.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.8.1.transformer_blocks.0.attn2.to_k.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.8.1.transformer_blocks.0.attn2.to_v.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.8.1.transformer_blocks.0.attn2.to_out.0.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.8.1.transformer_blocks.0.attn2.to_out.0.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.8.1.transformer_blocks.0.norm1.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.8.1.transformer_blocks.0.norm1.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.8.1.transformer_blocks.0.norm2.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.8.1.transformer_blocks.0.norm2.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.8.1.transformer_blocks.0.norm3.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.8.1.transformer_blocks.0.norm3.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.8.1.proj_out.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.8.1.proj_out.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.9.0.op.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.9.0.op.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.10.0.in_layers.0.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.10.0.in_layers.0.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.10.0.in_layers.2.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.10.0.in_layers.2.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.10.0.emb_layers.1.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.10.0.emb_layers.1.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.10.0.out_layers.0.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.10.0.out_layers.0.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.10.0.out_layers.3.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.10.0.out_layers.3.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.11.0.in_layers.0.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.11.0.in_layers.0.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.11.0.in_layers.2.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.11.0.in_layers.2.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.11.0.emb_layers.1.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.11.0.emb_layers.1.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.11.0.out_layers.0.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.11.0.out_layers.0.bias from state_dict.
Deleting key model.diffusion_model.input_blocks.11.0.out_layers.3.weight from state_dict.
Deleting key model.diffusion_model.input_blocks.11.0.out_layers.3.bias from state_dict.
Deleting key model.diffusion_model.middle_block.0.in_layers.0.weight from state_dict.
Deleting key model.diffusion_model.middle_block.0.in_layers.0.bias from state_dict.
Deleting key model.diffusion_model.middle_block.0.in_layers.2.weight from state_dict.
Deleting key model.diffusion_model.middle_block.0.in_layers.2.bias from state_dict.
Deleting key model.diffusion_model.middle_block.0.emb_layers.1.weight from state_dict.
Deleting key model.diffusion_model.middle_block.0.emb_layers.1.bias from state_dict.
Deleting key model.diffusion_model.middle_block.0.out_layers.0.weight from state_dict.
Deleting key model.diffusion_model.middle_block.0.out_layers.0.bias from state_dict.
Deleting key model.diffusion_model.middle_block.0.out_layers.3.weight from state_dict.
Deleting key model.diffusion_model.middle_block.0.out_layers.3.bias from state_dict.
Deleting key model.diffusion_model.middle_block.1.norm.weight from state_dict.
Deleting key model.diffusion_model.middle_block.1.norm.bias from state_dict.
Deleting key model.diffusion_model.middle_block.1.proj_in.weight from state_dict.
Deleting key model.diffusion_model.middle_block.1.proj_in.bias from state_dict.
Deleting key model.diffusion_model.middle_block.1.transformer_blocks.0.attn1.to_q.weight from state_dict.
Deleting key model.diffusion_model.middle_block.1.transformer_blocks.0.attn1.to_k.weight from state_dict.
Deleting key model.diffusion_model.middle_block.1.transformer_blocks.0.attn1.to_v.weight from state_dict.
Deleting key model.diffusion_model.middle_block.1.transformer_blocks.0.attn1.to_out.0.weight from state_dict.
Deleting key model.diffusion_model.middle_block.1.transformer_blocks.0.attn1.to_out.0.bias from state_dict.
Deleting key model.diffusion_model.middle_block.1.transformer_blocks.0.ff.net.0.proj.weight from state_dict.
Deleting key model.diffusion_model.middle_block.1.transformer_blocks.0.ff.net.0.proj.bias from state_dict.
Deleting key model.diffusion_model.middle_block.1.transformer_blocks.0.ff.net.2.weight from state_dict.
Deleting key model.diffusion_model.middle_block.1.transformer_blocks.0.ff.net.2.bias from state_dict.
Deleting key model.diffusion_model.middle_block.1.transformer_blocks.0.attn2.to_q.weight from state_dict.
Deleting key model.diffusion_model.middle_block.1.transformer_blocks.0.attn2.to_k.weight from state_dict.
Deleting key model.diffusion_model.middle_block.1.transformer_blocks.0.attn2.to_v.weight from state_dict.
Deleting key model.diffusion_model.middle_block.1.transformer_blocks.0.attn2.to_out.0.weight from state_dict.
Deleting key model.diffusion_model.middle_block.1.transformer_blocks.0.attn2.to_out.0.bias from state_dict.
Deleting key model.diffusion_model.middle_block.1.transformer_blocks.0.norm1.weight from state_dict.
Deleting key model.diffusion_model.middle_block.1.transformer_blocks.0.norm1.bias from state_dict.
Deleting key model.diffusion_model.middle_block.1.transformer_blocks.0.norm2.weight from state_dict.
Deleting key model.diffusion_model.middle_block.1.transformer_blocks.0.norm2.bias from state_dict.
Deleting key model.diffusion_model.middle_block.1.transformer_blocks.0.norm3.weight from state_dict.
Deleting key model.diffusion_model.middle_block.1.transformer_blocks.0.norm3.bias from state_dict.
Deleting key model.diffusion_model.middle_block.1.proj_out.weight from state_dict.
Deleting key model.diffusion_model.middle_block.1.proj_out.bias from state_dict.
Deleting key model.diffusion_model.middle_block.2.in_layers.0.weight from state_dict.
Deleting key model.diffusion_model.middle_block.2.in_layers.0.bias from state_dict.
Deleting key model.diffusion_model.middle_block.2.in_layers.2.weight from state_dict.
Deleting key model.diffusion_model.middle_block.2.in_layers.2.bias from state_dict.
Deleting key model.diffusion_model.middle_block.2.emb_layers.1.weight from state_dict.
Deleting key model.diffusion_model.middle_block.2.emb_layers.1.bias from state_dict.
Deleting key model.diffusion_model.middle_block.2.out_layers.0.weight from state_dict.
Deleting key model.diffusion_model.middle_block.2.out_layers.0.bias from state_dict.
Deleting key model.diffusion_model.middle_block.2.out_layers.3.weight from state_dict.
Deleting key model.diffusion_model.middle_block.2.out_layers.3.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.0.0.in_layers.0.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.0.0.in_layers.0.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.0.0.in_layers.2.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.0.0.in_layers.2.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.0.0.emb_layers.1.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.0.0.emb_layers.1.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.0.0.out_layers.0.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.0.0.out_layers.0.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.0.0.out_layers.3.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.0.0.out_layers.3.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.0.0.skip_connection.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.0.0.skip_connection.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.1.0.in_layers.0.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.1.0.in_layers.0.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.1.0.in_layers.2.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.1.0.in_layers.2.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.1.0.emb_layers.1.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.1.0.emb_layers.1.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.1.0.out_layers.0.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.1.0.out_layers.0.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.1.0.out_layers.3.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.1.0.out_layers.3.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.1.0.skip_connection.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.1.0.skip_connection.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.2.0.in_layers.0.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.2.0.in_layers.0.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.2.0.in_layers.2.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.2.0.in_layers.2.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.2.0.emb_layers.1.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.2.0.emb_layers.1.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.2.0.out_layers.0.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.2.0.out_layers.0.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.2.0.out_layers.3.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.2.0.out_layers.3.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.2.0.skip_connection.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.2.0.skip_connection.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.2.1.conv.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.2.1.conv.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.3.0.in_layers.0.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.3.0.in_layers.0.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.3.0.in_layers.2.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.3.0.in_layers.2.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.3.0.emb_layers.1.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.3.0.emb_layers.1.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.3.0.out_layers.0.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.3.0.out_layers.0.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.3.0.out_layers.3.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.3.0.out_layers.3.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.3.0.skip_connection.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.3.0.skip_connection.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.3.1.norm.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.3.1.norm.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.3.1.proj_in.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.3.1.proj_in.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.3.1.transformer_blocks.0.attn1.to_q.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.3.1.transformer_blocks.0.attn1.to_k.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.3.1.transformer_blocks.0.attn1.to_v.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.3.1.transformer_blocks.0.attn1.to_out.0.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.3.1.transformer_blocks.0.attn1.to_out.0.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.3.1.transformer_blocks.0.ff.net.0.proj.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.3.1.transformer_blocks.0.ff.net.0.proj.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.3.1.transformer_blocks.0.ff.net.2.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.3.1.transformer_blocks.0.ff.net.2.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.3.1.transformer_blocks.0.attn2.to_q.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.3.1.transformer_blocks.0.attn2.to_k.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.3.1.transformer_blocks.0.attn2.to_v.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.3.1.transformer_blocks.0.attn2.to_out.0.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.3.1.transformer_blocks.0.attn2.to_out.0.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.3.1.transformer_blocks.0.norm1.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.3.1.transformer_blocks.0.norm1.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.3.1.transformer_blocks.0.norm2.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.3.1.transformer_blocks.0.norm2.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.3.1.transformer_blocks.0.norm3.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.3.1.transformer_blocks.0.norm3.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.3.1.proj_out.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.3.1.proj_out.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.4.0.in_layers.0.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.4.0.in_layers.0.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.4.0.in_layers.2.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.4.0.in_layers.2.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.4.0.emb_layers.1.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.4.0.emb_layers.1.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.4.0.out_layers.0.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.4.0.out_layers.0.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.4.0.out_layers.3.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.4.0.out_layers.3.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.4.0.skip_connection.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.4.0.skip_connection.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.4.1.norm.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.4.1.norm.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.4.1.proj_in.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.4.1.proj_in.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.4.1.transformer_blocks.0.attn1.to_q.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.4.1.transformer_blocks.0.attn1.to_k.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.4.1.transformer_blocks.0.attn1.to_v.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.4.1.transformer_blocks.0.attn1.to_out.0.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.4.1.transformer_blocks.0.attn1.to_out.0.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.4.1.transformer_blocks.0.ff.net.0.proj.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.4.1.transformer_blocks.0.ff.net.0.proj.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.4.1.transformer_blocks.0.ff.net.2.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.4.1.transformer_blocks.0.ff.net.2.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.4.1.transformer_blocks.0.attn2.to_q.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.4.1.transformer_blocks.0.attn2.to_k.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.4.1.transformer_blocks.0.attn2.to_v.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.4.1.transformer_blocks.0.attn2.to_out.0.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.4.1.transformer_blocks.0.attn2.to_out.0.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.4.1.transformer_blocks.0.norm1.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.4.1.transformer_blocks.0.norm1.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.4.1.transformer_blocks.0.norm2.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.4.1.transformer_blocks.0.norm2.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.4.1.transformer_blocks.0.norm3.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.4.1.transformer_blocks.0.norm3.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.4.1.proj_out.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.4.1.proj_out.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.5.0.in_layers.0.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.5.0.in_layers.0.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.5.0.in_layers.2.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.5.0.in_layers.2.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.5.0.emb_layers.1.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.5.0.emb_layers.1.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.5.0.out_layers.0.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.5.0.out_layers.0.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.5.0.out_layers.3.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.5.0.out_layers.3.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.5.0.skip_connection.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.5.0.skip_connection.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.5.1.norm.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.5.1.norm.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.5.1.proj_in.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.5.1.proj_in.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.5.1.transformer_blocks.0.attn1.to_q.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.5.1.transformer_blocks.0.attn1.to_k.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.5.1.transformer_blocks.0.attn1.to_v.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.5.1.transformer_blocks.0.attn1.to_out.0.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.5.1.transformer_blocks.0.attn1.to_out.0.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.5.1.transformer_blocks.0.ff.net.0.proj.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.5.1.transformer_blocks.0.ff.net.0.proj.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.5.1.transformer_blocks.0.ff.net.2.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.5.1.transformer_blocks.0.ff.net.2.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.5.1.transformer_blocks.0.attn2.to_q.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.5.1.transformer_blocks.0.attn2.to_k.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.5.1.transformer_blocks.0.attn2.to_v.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.5.1.transformer_blocks.0.attn2.to_out.0.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.5.1.transformer_blocks.0.attn2.to_out.0.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.5.1.transformer_blocks.0.norm1.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.5.1.transformer_blocks.0.norm1.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.5.1.transformer_blocks.0.norm2.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.5.1.transformer_blocks.0.norm2.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.5.1.transformer_blocks.0.norm3.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.5.1.transformer_blocks.0.norm3.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.5.1.proj_out.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.5.1.proj_out.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.5.2.conv.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.5.2.conv.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.6.0.in_layers.0.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.6.0.in_layers.0.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.6.0.in_layers.2.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.6.0.in_layers.2.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.6.0.emb_layers.1.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.6.0.emb_layers.1.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.6.0.out_layers.0.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.6.0.out_layers.0.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.6.0.out_layers.3.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.6.0.out_layers.3.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.6.0.skip_connection.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.6.0.skip_connection.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.6.1.norm.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.6.1.norm.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.6.1.proj_in.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.6.1.proj_in.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.6.1.transformer_blocks.0.attn1.to_q.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.6.1.transformer_blocks.0.attn1.to_k.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.6.1.transformer_blocks.0.attn1.to_v.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.6.1.transformer_blocks.0.attn1.to_out.0.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.6.1.transformer_blocks.0.attn1.to_out.0.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.6.1.transformer_blocks.0.ff.net.0.proj.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.6.1.transformer_blocks.0.ff.net.0.proj.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.6.1.transformer_blocks.0.ff.net.2.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.6.1.transformer_blocks.0.ff.net.2.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.6.1.transformer_blocks.0.attn2.to_q.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.6.1.transformer_blocks.0.attn2.to_k.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.6.1.transformer_blocks.0.attn2.to_v.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.6.1.transformer_blocks.0.attn2.to_out.0.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.6.1.transformer_blocks.0.attn2.to_out.0.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.6.1.transformer_blocks.0.norm1.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.6.1.transformer_blocks.0.norm1.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.6.1.transformer_blocks.0.norm2.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.6.1.transformer_blocks.0.norm2.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.6.1.transformer_blocks.0.norm3.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.6.1.transformer_blocks.0.norm3.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.6.1.proj_out.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.6.1.proj_out.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.7.0.in_layers.0.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.7.0.in_layers.0.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.7.0.in_layers.2.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.7.0.in_layers.2.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.7.0.emb_layers.1.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.7.0.emb_layers.1.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.7.0.out_layers.0.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.7.0.out_layers.0.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.7.0.out_layers.3.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.7.0.out_layers.3.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.7.0.skip_connection.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.7.0.skip_connection.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.7.1.norm.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.7.1.norm.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.7.1.proj_in.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.7.1.proj_in.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.7.1.transformer_blocks.0.attn1.to_q.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.7.1.transformer_blocks.0.attn1.to_k.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.7.1.transformer_blocks.0.attn1.to_v.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.7.1.transformer_blocks.0.attn1.to_out.0.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.7.1.transformer_blocks.0.attn1.to_out.0.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.7.1.transformer_blocks.0.ff.net.0.proj.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.7.1.transformer_blocks.0.ff.net.0.proj.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.7.1.transformer_blocks.0.ff.net.2.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.7.1.transformer_blocks.0.ff.net.2.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.7.1.transformer_blocks.0.attn2.to_q.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.7.1.transformer_blocks.0.attn2.to_k.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.7.1.transformer_blocks.0.attn2.to_v.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.7.1.transformer_blocks.0.attn2.to_out.0.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.7.1.transformer_blocks.0.attn2.to_out.0.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.7.1.transformer_blocks.0.norm1.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.7.1.transformer_blocks.0.norm1.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.7.1.transformer_blocks.0.norm2.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.7.1.transformer_blocks.0.norm2.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.7.1.transformer_blocks.0.norm3.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.7.1.transformer_blocks.0.norm3.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.7.1.proj_out.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.7.1.proj_out.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.8.0.in_layers.0.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.8.0.in_layers.0.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.8.0.in_layers.2.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.8.0.in_layers.2.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.8.0.emb_layers.1.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.8.0.emb_layers.1.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.8.0.out_layers.0.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.8.0.out_layers.0.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.8.0.out_layers.3.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.8.0.out_layers.3.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.8.0.skip_connection.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.8.0.skip_connection.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.8.1.norm.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.8.1.norm.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.8.1.proj_in.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.8.1.proj_in.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.8.1.transformer_blocks.0.attn1.to_q.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.8.1.transformer_blocks.0.attn1.to_k.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.8.1.transformer_blocks.0.attn1.to_v.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.8.1.transformer_blocks.0.attn1.to_out.0.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.8.1.transformer_blocks.0.attn1.to_out.0.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.8.1.transformer_blocks.0.ff.net.0.proj.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.8.1.transformer_blocks.0.ff.net.0.proj.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.8.1.transformer_blocks.0.ff.net.2.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.8.1.transformer_blocks.0.ff.net.2.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.8.1.transformer_blocks.0.attn2.to_q.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.8.1.transformer_blocks.0.attn2.to_k.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.8.1.transformer_blocks.0.attn2.to_v.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.8.1.transformer_blocks.0.attn2.to_out.0.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.8.1.transformer_blocks.0.attn2.to_out.0.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.8.1.transformer_blocks.0.norm1.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.8.1.transformer_blocks.0.norm1.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.8.1.transformer_blocks.0.norm2.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.8.1.transformer_blocks.0.norm2.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.8.1.transformer_blocks.0.norm3.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.8.1.transformer_blocks.0.norm3.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.8.1.proj_out.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.8.1.proj_out.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.8.2.conv.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.8.2.conv.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.9.0.in_layers.0.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.9.0.in_layers.0.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.9.0.in_layers.2.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.9.0.in_layers.2.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.9.0.emb_layers.1.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.9.0.emb_layers.1.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.9.0.out_layers.0.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.9.0.out_layers.0.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.9.0.out_layers.3.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.9.0.out_layers.3.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.9.0.skip_connection.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.9.0.skip_connection.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.9.1.norm.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.9.1.norm.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.9.1.proj_in.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.9.1.proj_in.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.9.1.transformer_blocks.0.attn1.to_q.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.9.1.transformer_blocks.0.attn1.to_k.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.9.1.transformer_blocks.0.attn1.to_v.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.9.1.transformer_blocks.0.attn1.to_out.0.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.9.1.transformer_blocks.0.attn1.to_out.0.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.9.1.transformer_blocks.0.ff.net.0.proj.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.9.1.transformer_blocks.0.ff.net.0.proj.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.9.1.transformer_blocks.0.ff.net.2.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.9.1.transformer_blocks.0.ff.net.2.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.9.1.transformer_blocks.0.attn2.to_q.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.9.1.transformer_blocks.0.attn2.to_k.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.9.1.transformer_blocks.0.attn2.to_v.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.9.1.transformer_blocks.0.attn2.to_out.0.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.9.1.transformer_blocks.0.attn2.to_out.0.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.9.1.transformer_blocks.0.norm1.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.9.1.transformer_blocks.0.norm1.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.9.1.transformer_blocks.0.norm2.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.9.1.transformer_blocks.0.norm2.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.9.1.transformer_blocks.0.norm3.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.9.1.transformer_blocks.0.norm3.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.9.1.proj_out.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.9.1.proj_out.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.10.0.in_layers.0.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.10.0.in_layers.0.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.10.0.in_layers.2.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.10.0.in_layers.2.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.10.0.emb_layers.1.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.10.0.emb_layers.1.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.10.0.out_layers.0.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.10.0.out_layers.0.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.10.0.out_layers.3.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.10.0.out_layers.3.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.10.0.skip_connection.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.10.0.skip_connection.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.10.1.norm.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.10.1.norm.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.10.1.proj_in.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.10.1.proj_in.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.10.1.transformer_blocks.0.attn1.to_q.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.10.1.transformer_blocks.0.attn1.to_k.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.10.1.transformer_blocks.0.attn1.to_v.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.10.1.transformer_blocks.0.attn1.to_out.0.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.10.1.transformer_blocks.0.attn1.to_out.0.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.10.1.transformer_blocks.0.ff.net.0.proj.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.10.1.transformer_blocks.0.ff.net.0.proj.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.10.1.transformer_blocks.0.ff.net.2.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.10.1.transformer_blocks.0.ff.net.2.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.10.1.transformer_blocks.0.attn2.to_q.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.10.1.transformer_blocks.0.attn2.to_k.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.10.1.transformer_blocks.0.attn2.to_v.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.10.1.transformer_blocks.0.attn2.to_out.0.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.10.1.transformer_blocks.0.attn2.to_out.0.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.10.1.transformer_blocks.0.norm1.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.10.1.transformer_blocks.0.norm1.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.10.1.transformer_blocks.0.norm2.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.10.1.transformer_blocks.0.norm2.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.10.1.transformer_blocks.0.norm3.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.10.1.transformer_blocks.0.norm3.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.10.1.proj_out.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.10.1.proj_out.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.11.0.in_layers.0.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.11.0.in_layers.0.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.11.0.in_layers.2.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.11.0.in_layers.2.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.11.0.emb_layers.1.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.11.0.emb_layers.1.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.11.0.out_layers.0.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.11.0.out_layers.0.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.11.0.out_layers.3.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.11.0.out_layers.3.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.11.0.skip_connection.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.11.0.skip_connection.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.11.1.norm.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.11.1.norm.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.11.1.proj_in.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.11.1.proj_in.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.11.1.transformer_blocks.0.attn1.to_q.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.11.1.transformer_blocks.0.attn1.to_k.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.11.1.transformer_blocks.0.attn1.to_v.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.11.1.transformer_blocks.0.attn1.to_out.0.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.11.1.transformer_blocks.0.attn1.to_out.0.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.11.1.transformer_blocks.0.ff.net.0.proj.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.11.1.transformer_blocks.0.ff.net.0.proj.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.11.1.transformer_blocks.0.ff.net.2.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.11.1.transformer_blocks.0.ff.net.2.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.11.1.transformer_blocks.0.attn2.to_q.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.11.1.transformer_blocks.0.attn2.to_k.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.11.1.transformer_blocks.0.attn2.to_v.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.11.1.transformer_blocks.0.attn2.to_out.0.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.11.1.transformer_blocks.0.attn2.to_out.0.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.11.1.transformer_blocks.0.norm1.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.11.1.transformer_blocks.0.norm1.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.11.1.transformer_blocks.0.norm2.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.11.1.transformer_blocks.0.norm2.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.11.1.transformer_blocks.0.norm3.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.11.1.transformer_blocks.0.norm3.bias from state_dict.
Deleting key model.diffusion_model.output_blocks.11.1.proj_out.weight from state_dict.
Deleting key model.diffusion_model.output_blocks.11.1.proj_out.bias from state_dict.
Deleting key model.diffusion_model.out.0.weight from state_dict.
Deleting key model.diffusion_model.out.0.bias from state_dict.
Deleting key model.diffusion_model.out.2.weight from state_dict.
Deleting key model.diffusion_model.out.2.bias from state_dict.
Restored from /checkpoints/sd/512-base-ema.ckpt with 686 missing and 2 unexpected keys
Missing Keys:
 ['model.diffusion_model.time_embed.0.weight', 'model.diffusion_model.time_embed.0.bias', 'model.diffusion_model.time_embed.2.weight', 'model.diffusion_model.time_embed.2.bias', 'model.diffusion_model.input_blocks.0.0.weight', 'model.diffusion_model.input_blocks.0.0.bias', 'model.diffusion_model.input_blocks.1.0.in_layers.0.weight', 'model.diffusion_model.input_blocks.1.0.in_layers.0.bias', 'model.diffusion_model.input_blocks.1.0.in_layers.2.weight', 'model.diffusion_model.input_blocks.1.0.in_layers.2.bias', 'model.diffusion_model.input_blocks.1.0.emb_layers.1.weight', 'model.diffusion_model.input_blocks.1.0.emb_layers.1.bias', 'model.diffusion_model.input_blocks.1.0.out_layers.0.weight', 'model.diffusion_model.input_blocks.1.0.out_layers.0.bias', 'model.diffusion_model.input_blocks.1.0.out_layers.3.weight', 'model.diffusion_model.input_blocks.1.0.out_layers.3.bias', 'model.diffusion_model.input_blocks.1.1.norm.weight', 'model.diffusion_model.input_blocks.1.1.norm.bias', 'model.diffusion_model.input_blocks.1.1.proj_in.weight', 'model.diffusion_model.input_blocks.1.1.proj_in.bias', 'model.diffusion_model.input_blocks.1.1.transformer_blocks.0.attn1.to_q.weight', 'model.diffusion_model.input_blocks.1.1.transformer_blocks.0.attn1.to_k.weight', 'model.diffusion_model.input_blocks.1.1.transformer_blocks.0.attn1.to_v.weight', 'model.diffusion_model.input_blocks.1.1.transformer_blocks.0.attn1.to_out.0.weight', 'model.diffusion_model.input_blocks.1.1.transformer_blocks.0.attn1.to_out.0.bias', 'model.diffusion_model.input_blocks.1.1.transformer_blocks.0.ff.net.0.proj.weight', 'model.diffusion_model.input_blocks.1.1.transformer_blocks.0.ff.net.0.proj.bias', 'model.diffusion_model.input_blocks.1.1.transformer_blocks.0.ff.net.2.weight', 'model.diffusion_model.input_blocks.1.1.transformer_blocks.0.ff.net.2.bias', 'model.diffusion_model.input_blocks.1.1.transformer_blocks.0.attn2.to_q.weight', 'model.diffusion_model.input_blocks.1.1.transformer_blocks.0.attn2.to_k.weight', 'model.diffusion_model.input_blocks.1.1.transformer_blocks.0.attn2.to_v.weight', 'model.diffusion_model.input_blocks.1.1.transformer_blocks.0.attn2.to_out.0.weight', 'model.diffusion_model.input_blocks.1.1.transformer_blocks.0.attn2.to_out.0.bias', 'model.diffusion_model.input_blocks.1.1.transformer_blocks.0.norm1.weight', 'model.diffusion_model.input_blocks.1.1.transformer_blocks.0.norm1.bias', 'model.diffusion_model.input_blocks.1.1.transformer_blocks.0.norm2.weight', 'model.diffusion_model.input_blocks.1.1.transformer_blocks.0.norm2.bias', 'model.diffusion_model.input_blocks.1.1.transformer_blocks.0.norm3.weight', 'model.diffusion_model.input_blocks.1.1.transformer_blocks.0.norm3.bias', 'model.diffusion_model.input_blocks.1.1.proj_out.weight', 'model.diffusion_model.input_blocks.1.1.proj_out.bias', 'model.diffusion_model.input_blocks.2.0.in_layers.0.weight', 'model.diffusion_model.input_blocks.2.0.in_layers.0.bias', 'model.diffusion_model.input_blocks.2.0.in_layers.2.weight', 'model.diffusion_model.input_blocks.2.0.in_layers.2.bias', 'model.diffusion_model.input_blocks.2.0.emb_layers.1.weight', 'model.diffusion_model.input_blocks.2.0.emb_layers.1.bias', 'model.diffusion_model.input_blocks.2.0.out_layers.0.weight', 'model.diffusion_model.input_blocks.2.0.out_layers.0.bias', 'model.diffusion_model.input_blocks.2.0.out_layers.3.weight', 'model.diffusion_model.input_blocks.2.0.out_layers.3.bias', 'model.diffusion_model.input_blocks.2.1.norm.weight', 'model.diffusion_model.input_blocks.2.1.norm.bias', 'model.diffusion_model.input_blocks.2.1.proj_in.weight', 'model.diffusion_model.input_blocks.2.1.proj_in.bias', 'model.diffusion_model.input_blocks.2.1.transformer_blocks.0.attn1.to_q.weight', 'model.diffusion_model.input_blocks.2.1.transformer_blocks.0.attn1.to_k.weight', 'model.diffusion_model.input_blocks.2.1.transformer_blocks.0.attn1.to_v.weight', 'model.diffusion_model.input_blocks.2.1.transformer_blocks.0.attn1.to_out.0.weight', 'model.diffusion_model.input_blocks.2.1.transformer_blocks.0.attn1.to_out.0.bias', 'model.diffusion_model.input_blocks.2.1.transformer_blocks.0.ff.net.0.proj.weight', 'model.diffusion_model.input_blocks.2.1.transformer_blocks.0.ff.net.0.proj.bias', 'model.diffusion_model.input_blocks.2.1.transformer_blocks.0.ff.net.2.weight', 'model.diffusion_model.input_blocks.2.1.transformer_blocks.0.ff.net.2.bias', 'model.diffusion_model.input_blocks.2.1.transformer_blocks.0.attn2.to_q.weight', 'model.diffusion_model.input_blocks.2.1.transformer_blocks.0.attn2.to_k.weight', 'model.diffusion_model.input_blocks.2.1.transformer_blocks.0.attn2.to_v.weight', 'model.diffusion_model.input_blocks.2.1.transformer_blocks.0.attn2.to_out.0.weight', 'model.diffusion_model.input_blocks.2.1.transformer_blocks.0.attn2.to_out.0.bias', 'model.diffusion_model.input_blocks.2.1.transformer_blocks.0.norm1.weight', 'model.diffusion_model.input_blocks.2.1.transformer_blocks.0.norm1.bias', 'model.diffusion_model.input_blocks.2.1.transformer_blocks.0.norm2.weight', 'model.diffusion_model.input_blocks.2.1.transformer_blocks.0.norm2.bias', 'model.diffusion_model.input_blocks.2.1.transformer_blocks.0.norm3.weight', 'model.diffusion_model.input_blocks.2.1.transformer_blocks.0.norm3.bias', 'model.diffusion_model.input_blocks.2.1.proj_out.weight', 'model.diffusion_model.input_blocks.2.1.proj_out.bias', 'model.diffusion_model.input_blocks.3.0.op.weight', 'model.diffusion_model.input_blocks.3.0.op.bias', 'model.diffusion_model.input_blocks.4.0.in_layers.0.weight', 'model.diffusion_model.input_blocks.4.0.in_layers.0.bias', 'model.diffusion_model.input_blocks.4.0.in_layers.2.weight', 'model.diffusion_model.input_blocks.4.0.in_layers.2.bias', 'model.diffusion_model.input_blocks.4.0.emb_layers.1.weight', 'model.diffusion_model.input_blocks.4.0.emb_layers.1.bias', 'model.diffusion_model.input_blocks.4.0.out_layers.0.weight', 'model.diffusion_model.input_blocks.4.0.out_layers.0.bias', 'model.diffusion_model.input_blocks.4.0.out_layers.3.weight', 'model.diffusion_model.input_blocks.4.0.out_layers.3.bias', 'model.diffusion_model.input_blocks.4.0.skip_connection.weight', 'model.diffusion_model.input_blocks.4.0.skip_connection.bias', 'model.diffusion_model.input_blocks.4.1.norm.weight', 'model.diffusion_model.input_blocks.4.1.norm.bias', 'model.diffusion_model.input_blocks.4.1.proj_in.weight', 'model.diffusion_model.input_blocks.4.1.proj_in.bias', 'model.diffusion_model.input_blocks.4.1.transformer_blocks.0.attn1.to_q.weight', 'model.diffusion_model.input_blocks.4.1.transformer_blocks.0.attn1.to_k.weight', 'model.diffusion_model.input_blocks.4.1.transformer_blocks.0.attn1.to_v.weight', 'model.diffusion_model.input_blocks.4.1.transformer_blocks.0.attn1.to_out.0.weight', 'model.diffusion_model.input_blocks.4.1.transformer_blocks.0.attn1.to_out.0.bias', 'model.diffusion_model.input_blocks.4.1.transformer_blocks.0.ff.net.0.proj.weight', 'model.diffusion_model.input_blocks.4.1.transformer_blocks.0.ff.net.0.proj.bias', 'model.diffusion_model.input_blocks.4.1.transformer_blocks.0.ff.net.2.weight', 'model.diffusion_model.input_blocks.4.1.transformer_blocks.0.ff.net.2.bias', 'model.diffusion_model.input_blocks.4.1.transformer_blocks.0.attn2.to_q.weight', 'model.diffusion_model.input_blocks.4.1.transformer_blocks.0.attn2.to_k.weight', 'model.diffusion_model.input_blocks.4.1.transformer_blocks.0.attn2.to_v.weight', 'model.diffusion_model.input_blocks.4.1.transformer_blocks.0.attn2.to_out.0.weight', 'model.diffusion_model.input_blocks.4.1.transformer_blocks.0.attn2.to_out.0.bias', 'model.diffusion_model.input_blocks.4.1.transformer_blocks.0.norm1.weight', 'model.diffusion_model.input_blocks.4.1.transformer_blocks.0.norm1.bias', 'model.diffusion_model.input_blocks.4.1.transformer_blocks.0.norm2.weight', 'model.diffusion_model.input_blocks.4.1.transformer_blocks.0.norm2.bias', 'model.diffusion_model.input_blocks.4.1.transformer_blocks.0.norm3.weight', 'model.diffusion_model.input_blocks.4.1.transformer_blocks.0.norm3.bias', 'model.diffusion_model.input_blocks.4.1.proj_out.weight', 'model.diffusion_model.input_blocks.4.1.proj_out.bias', 'model.diffusion_model.input_blocks.5.0.in_layers.0.weight', 'model.diffusion_model.input_blocks.5.0.in_layers.0.bias', 'model.diffusion_model.input_blocks.5.0.in_layers.2.weight', 'model.diffusion_model.input_blocks.5.0.in_layers.2.bias', 'model.diffusion_model.input_blocks.5.0.emb_layers.1.weight', 'model.diffusion_model.input_blocks.5.0.emb_layers.1.bias', 'model.diffusion_model.input_blocks.5.0.out_layers.0.weight', 'model.diffusion_model.input_blocks.5.0.out_layers.0.bias', 'model.diffusion_model.input_blocks.5.0.out_layers.3.weight', 'model.diffusion_model.input_blocks.5.0.out_layers.3.bias', 'model.diffusion_model.input_blocks.5.1.norm.weight', 'model.diffusion_model.input_blocks.5.1.norm.bias', 'model.diffusion_model.input_blocks.5.1.proj_in.weight', 'model.diffusion_model.input_blocks.5.1.proj_in.bias', 'model.diffusion_model.input_blocks.5.1.transformer_blocks.0.attn1.to_q.weight', 'model.diffusion_model.input_blocks.5.1.transformer_blocks.0.attn1.to_k.weight', 'model.diffusion_model.input_blocks.5.1.transformer_blocks.0.attn1.to_v.weight', 'model.diffusion_model.input_blocks.5.1.transformer_blocks.0.attn1.to_out.0.weight', 'model.diffusion_model.input_blocks.5.1.transformer_blocks.0.attn1.to_out.0.bias', 'model.diffusion_model.input_blocks.5.1.transformer_blocks.0.ff.net.0.proj.weight', 'model.diffusion_model.input_blocks.5.1.transformer_blocks.0.ff.net.0.proj.bias', 'model.diffusion_model.input_blocks.5.1.transformer_blocks.0.ff.net.2.weight', 'model.diffusion_model.input_blocks.5.1.transformer_blocks.0.ff.net.2.bias', 'model.diffusion_model.input_blocks.5.1.transformer_blocks.0.attn2.to_q.weight', 'model.diffusion_model.input_blocks.5.1.transformer_blocks.0.attn2.to_k.weight', 'model.diffusion_model.input_blocks.5.1.transformer_blocks.0.attn2.to_v.weight', 'model.diffusion_model.input_blocks.5.1.transformer_blocks.0.attn2.to_out.0.weight', 'model.diffusion_model.input_blocks.5.1.transformer_blocks.0.attn2.to_out.0.bias', 'model.diffusion_model.input_blocks.5.1.transformer_blocks.0.norm1.weight', 'model.diffusion_model.input_blocks.5.1.transformer_blocks.0.norm1.bias', 'model.diffusion_model.input_blocks.5.1.transformer_blocks.0.norm2.weight', 'model.diffusion_model.input_blocks.5.1.transformer_blocks.0.norm2.bias', 'model.diffusion_model.input_blocks.5.1.transformer_blocks.0.norm3.weight', 'model.diffusion_model.input_blocks.5.1.transformer_blocks.0.norm3.bias', 'model.diffusion_model.input_blocks.5.1.proj_out.weight', 'model.diffusion_model.input_blocks.5.1.proj_out.bias', 'model.diffusion_model.input_blocks.6.0.op.weight', 'model.diffusion_model.input_blocks.6.0.op.bias', 'model.diffusion_model.input_blocks.7.0.in_layers.0.weight', 'model.diffusion_model.input_blocks.7.0.in_layers.0.bias', 'model.diffusion_model.input_blocks.7.0.in_layers.2.weight', 'model.diffusion_model.input_blocks.7.0.in_layers.2.bias', 'model.diffusion_model.input_blocks.7.0.emb_layers.1.weight', 'model.diffusion_model.input_blocks.7.0.emb_layers.1.bias', 'model.diffusion_model.input_blocks.7.0.out_layers.0.weight', 'model.diffusion_model.input_blocks.7.0.out_layers.0.bias', 'model.diffusion_model.input_blocks.7.0.out_layers.3.weight', 'model.diffusion_model.input_blocks.7.0.out_layers.3.bias', 'model.diffusion_model.input_blocks.7.0.skip_connection.weight', 'model.diffusion_model.input_blocks.7.0.skip_connection.bias', 'model.diffusion_model.input_blocks.7.1.norm.weight', 'model.diffusion_model.input_blocks.7.1.norm.bias', 'model.diffusion_model.input_blocks.7.1.proj_in.weight', 'model.diffusion_model.input_blocks.7.1.proj_in.bias', 'model.diffusion_model.input_blocks.7.1.transformer_blocks.0.attn1.to_q.weight', 'model.diffusion_model.input_blocks.7.1.transformer_blocks.0.attn1.to_k.weight', 'model.diffusion_model.input_blocks.7.1.transformer_blocks.0.attn1.to_v.weight', 'model.diffusion_model.input_blocks.7.1.transformer_blocks.0.attn1.to_out.0.weight', 'model.diffusion_model.input_blocks.7.1.transformer_blocks.0.attn1.to_out.0.bias', 'model.diffusion_model.input_blocks.7.1.transformer_blocks.0.ff.net.0.proj.weight', 'model.diffusion_model.input_blocks.7.1.transformer_blocks.0.ff.net.0.proj.bias', 'model.diffusion_model.input_blocks.7.1.transformer_blocks.0.ff.net.2.weight', 'model.diffusion_model.input_blocks.7.1.transformer_blocks.0.ff.net.2.bias', 'model.diffusion_model.input_blocks.7.1.transformer_blocks.0.attn2.to_q.weight', 'model.diffusion_model.input_blocks.7.1.transformer_blocks.0.attn2.to_k.weight', 'model.diffusion_model.input_blocks.7.1.transformer_blocks.0.attn2.to_v.weight', 'model.diffusion_model.input_blocks.7.1.transformer_blocks.0.attn2.to_out.0.weight', 'model.diffusion_model.input_blocks.7.1.transformer_blocks.0.attn2.to_out.0.bias', 'model.diffusion_model.input_blocks.7.1.transformer_blocks.0.norm1.weight', 'model.diffusion_model.input_blocks.7.1.transformer_blocks.0.norm1.bias', 'model.diffusion_model.input_blocks.7.1.transformer_blocks.0.norm2.weight', 'model.diffusion_model.input_blocks.7.1.transformer_blocks.0.norm2.bias', 'model.diffusion_model.input_blocks.7.1.transformer_blocks.0.norm3.weight', 'model.diffusion_model.input_blocks.7.1.transformer_blocks.0.norm3.bias', 'model.diffusion_model.input_blocks.7.1.proj_out.weight', 'model.diffusion_model.input_blocks.7.1.proj_out.bias', 'model.diffusion_model.input_blocks.8.0.in_layers.0.weight', 'model.diffusion_model.input_blocks.8.0.in_layers.0.bias', 'model.diffusion_model.input_blocks.8.0.in_layers.2.weight', 'model.diffusion_model.input_blocks.8.0.in_layers.2.bias', 'model.diffusion_model.input_blocks.8.0.emb_layers.1.weight', 'model.diffusion_model.input_blocks.8.0.emb_layers.1.bias', 'model.diffusion_model.input_blocks.8.0.out_layers.0.weight', 'model.diffusion_model.input_blocks.8.0.out_layers.0.bias', 'model.diffusion_model.input_blocks.8.0.out_layers.3.weight', 'model.diffusion_model.input_blocks.8.0.out_layers.3.bias', 'model.diffusion_model.input_blocks.8.1.norm.weight', 'model.diffusion_model.input_blocks.8.1.norm.bias', 'model.diffusion_model.input_blocks.8.1.proj_in.weight', 'model.diffusion_model.input_blocks.8.1.proj_in.bias', 'model.diffusion_model.input_blocks.8.1.transformer_blocks.0.attn1.to_q.weight', 'model.diffusion_model.input_blocks.8.1.transformer_blocks.0.attn1.to_k.weight', 'model.diffusion_model.input_blocks.8.1.transformer_blocks.0.attn1.to_v.weight', 'model.diffusion_model.input_blocks.8.1.transformer_blocks.0.attn1.to_out.0.weight', 'model.diffusion_model.input_blocks.8.1.transformer_blocks.0.attn1.to_out.0.bias', 'model.diffusion_model.input_blocks.8.1.transformer_blocks.0.ff.net.0.proj.weight', 'model.diffusion_model.input_blocks.8.1.transformer_blocks.0.ff.net.0.proj.bias', 'model.diffusion_model.input_blocks.8.1.transformer_blocks.0.ff.net.2.weight', 'model.diffusion_model.input_blocks.8.1.transformer_blocks.0.ff.net.2.bias', 'model.diffusion_model.input_blocks.8.1.transformer_blocks.0.attn2.to_q.weight', 'model.diffusion_model.input_blocks.8.1.transformer_blocks.0.attn2.to_k.weight', 'model.diffusion_model.input_blocks.8.1.transformer_blocks.0.attn2.to_v.weight', 'model.diffusion_model.input_blocks.8.1.transformer_blocks.0.attn2.to_out.0.weight', 'model.diffusion_model.input_blocks.8.1.transformer_blocks.0.attn2.to_out.0.bias', 'model.diffusion_model.input_blocks.8.1.transformer_blocks.0.norm1.weight', 'model.diffusion_model.input_blocks.8.1.transformer_blocks.0.norm1.bias', 'model.diffusion_model.input_blocks.8.1.transformer_blocks.0.norm2.weight', 'model.diffusion_model.input_blocks.8.1.transformer_blocks.0.norm2.bias', 'model.diffusion_model.input_blocks.8.1.transformer_blocks.0.norm3.weight', 'model.diffusion_model.input_blocks.8.1.transformer_blocks.0.norm3.bias', 'model.diffusion_model.input_blocks.8.1.proj_out.weight', 'model.diffusion_model.input_blocks.8.1.proj_out.bias', 'model.diffusion_model.input_blocks.9.0.op.weight', 'model.diffusion_model.input_blocks.9.0.op.bias', 'model.diffusion_model.input_blocks.10.0.in_layers.0.weight', 'model.diffusion_model.input_blocks.10.0.in_layers.0.bias', 'model.diffusion_model.input_blocks.10.0.in_layers.2.weight', 'model.diffusion_model.input_blocks.10.0.in_layers.2.bias', 'model.diffusion_model.input_blocks.10.0.emb_layers.1.weight', 'model.diffusion_model.input_blocks.10.0.emb_layers.1.bias', 'model.diffusion_model.input_blocks.10.0.out_layers.0.weight', 'model.diffusion_model.input_blocks.10.0.out_layers.0.bias', 'model.diffusion_model.input_blocks.10.0.out_layers.3.weight', 'model.diffusion_model.input_blocks.10.0.out_layers.3.bias', 'model.diffusion_model.input_blocks.11.0.in_layers.0.weight', 'model.diffusion_model.input_blocks.11.0.in_layers.0.bias', 'model.diffusion_model.input_blocks.11.0.in_layers.2.weight', 'model.diffusion_model.input_blocks.11.0.in_layers.2.bias', 'model.diffusion_model.input_blocks.11.0.emb_layers.1.weight', 'model.diffusion_model.input_blocks.11.0.emb_layers.1.bias', 'model.diffusion_model.input_blocks.11.0.out_layers.0.weight', 'model.diffusion_model.input_blocks.11.0.out_layers.0.bias', 'model.diffusion_model.input_blocks.11.0.out_layers.3.weight', 'model.diffusion_model.input_blocks.11.0.out_layers.3.bias', 'model.diffusion_model.middle_block.0.in_layers.0.weight', 'model.diffusion_model.middle_block.0.in_layers.0.bias', 'model.diffusion_model.middle_block.0.in_layers.2.weight', 'model.diffusion_model.middle_block.0.in_layers.2.bias', 'model.diffusion_model.middle_block.0.emb_layers.1.weight', 'model.diffusion_model.middle_block.0.emb_layers.1.bias', 'model.diffusion_model.middle_block.0.out_layers.0.weight', 'model.diffusion_model.middle_block.0.out_layers.0.bias', 'model.diffusion_model.middle_block.0.out_layers.3.weight', 'model.diffusion_model.middle_block.0.out_layers.3.bias', 'model.diffusion_model.middle_block.1.norm.weight', 'model.diffusion_model.middle_block.1.norm.bias', 'model.diffusion_model.middle_block.1.proj_in.weight', 'model.diffusion_model.middle_block.1.proj_in.bias', 'model.diffusion_model.middle_block.1.transformer_blocks.0.attn1.to_q.weight', 'model.diffusion_model.middle_block.1.transformer_blocks.0.attn1.to_k.weight', 'model.diffusion_model.middle_block.1.transformer_blocks.0.attn1.to_v.weight', 'model.diffusion_model.middle_block.1.transformer_blocks.0.attn1.to_out.0.weight', 'model.diffusion_model.middle_block.1.transformer_blocks.0.attn1.to_out.0.bias', 'model.diffusion_model.middle_block.1.transformer_blocks.0.ff.net.0.proj.weight', 'model.diffusion_model.middle_block.1.transformer_blocks.0.ff.net.0.proj.bias', 'model.diffusion_model.middle_block.1.transformer_blocks.0.ff.net.2.weight', 'model.diffusion_model.middle_block.1.transformer_blocks.0.ff.net.2.bias', 'model.diffusion_model.middle_block.1.transformer_blocks.0.attn2.to_q.weight', 'model.diffusion_model.middle_block.1.transformer_blocks.0.attn2.to_k.weight', 'model.diffusion_model.middle_block.1.transformer_blocks.0.attn2.to_v.weight', 'model.diffusion_model.middle_block.1.transformer_blocks.0.attn2.to_out.0.weight', 'model.diffusion_model.middle_block.1.transformer_blocks.0.attn2.to_out.0.bias', 'model.diffusion_model.middle_block.1.transformer_blocks.0.norm1.weight', 'model.diffusion_model.middle_block.1.transformer_blocks.0.norm1.bias', 'model.diffusion_model.middle_block.1.transformer_blocks.0.norm2.weight', 'model.diffusion_model.middle_block.1.transformer_blocks.0.norm2.bias', 'model.diffusion_model.middle_block.1.transformer_blocks.0.norm3.weight', 'model.diffusion_model.middle_block.1.transformer_blocks.0.norm3.bias', 'model.diffusion_model.middle_block.1.proj_out.weight', 'model.diffusion_model.middle_block.1.proj_out.bias', 'model.diffusion_model.middle_block.2.in_layers.0.weight', 'model.diffusion_model.middle_block.2.in_layers.0.bias', 'model.diffusion_model.middle_block.2.in_layers.2.weight', 'model.diffusion_model.middle_block.2.in_layers.2.bias', 'model.diffusion_model.middle_block.2.emb_layers.1.weight', 'model.diffusion_model.middle_block.2.emb_layers.1.bias', 'model.diffusion_model.middle_block.2.out_layers.0.weight', 'model.diffusion_model.middle_block.2.out_layers.0.bias', 'model.diffusion_model.middle_block.2.out_layers.3.weight', 'model.diffusion_model.middle_block.2.out_layers.3.bias', 'model.diffusion_model.output_blocks.0.0.in_layers.0.weight', 'model.diffusion_model.output_blocks.0.0.in_layers.0.bias', 'model.diffusion_model.output_blocks.0.0.in_layers.2.weight', 'model.diffusion_model.output_blocks.0.0.in_layers.2.bias', 'model.diffusion_model.output_blocks.0.0.emb_layers.1.weight', 'model.diffusion_model.output_blocks.0.0.emb_layers.1.bias', 'model.diffusion_model.output_blocks.0.0.out_layers.0.weight', 'model.diffusion_model.output_blocks.0.0.out_layers.0.bias', 'model.diffusion_model.output_blocks.0.0.out_layers.3.weight', 'model.diffusion_model.output_blocks.0.0.out_layers.3.bias', 'model.diffusion_model.output_blocks.0.0.skip_connection.weight', 'model.diffusion_model.output_blocks.0.0.skip_connection.bias', 'model.diffusion_model.output_blocks.1.0.in_layers.0.weight', 'model.diffusion_model.output_blocks.1.0.in_layers.0.bias', 'model.diffusion_model.output_blocks.1.0.in_layers.2.weight', 'model.diffusion_model.output_blocks.1.0.in_layers.2.bias', 'model.diffusion_model.output_blocks.1.0.emb_layers.1.weight', 'model.diffusion_model.output_blocks.1.0.emb_layers.1.bias', 'model.diffusion_model.output_blocks.1.0.out_layers.0.weight', 'model.diffusion_model.output_blocks.1.0.out_layers.0.bias', 'model.diffusion_model.output_blocks.1.0.out_layers.3.weight', 'model.diffusion_model.output_blocks.1.0.out_layers.3.bias', 'model.diffusion_model.output_blocks.1.0.skip_connection.weight', 'model.diffusion_model.output_blocks.1.0.skip_connection.bias', 'model.diffusion_model.output_blocks.2.0.in_layers.0.weight', 'model.diffusion_model.output_blocks.2.0.in_layers.0.bias', 'model.diffusion_model.output_blocks.2.0.in_layers.2.weight', 'model.diffusion_model.output_blocks.2.0.in_layers.2.bias', 'model.diffusion_model.output_blocks.2.0.emb_layers.1.weight', 'model.diffusion_model.output_blocks.2.0.emb_layers.1.bias', 'model.diffusion_model.output_blocks.2.0.out_layers.0.weight', 'model.diffusion_model.output_blocks.2.0.out_layers.0.bias', 'model.diffusion_model.output_blocks.2.0.out_layers.3.weight', 'model.diffusion_model.output_blocks.2.0.out_layers.3.bias', 'model.diffusion_model.output_blocks.2.0.skip_connection.weight', 'model.diffusion_model.output_blocks.2.0.skip_connection.bias', 'model.diffusion_model.output_blocks.2.1.conv.weight', 'model.diffusion_model.output_blocks.2.1.conv.bias', 'model.diffusion_model.output_blocks.3.0.in_layers.0.weight', 'model.diffusion_model.output_blocks.3.0.in_layers.0.bias', 'model.diffusion_model.output_blocks.3.0.in_layers.2.weight', 'model.diffusion_model.output_blocks.3.0.in_layers.2.bias', 'model.diffusion_model.output_blocks.3.0.emb_layers.1.weight', 'model.diffusion_model.output_blocks.3.0.emb_layers.1.bias', 'model.diffusion_model.output_blocks.3.0.out_layers.0.weight', 'model.diffusion_model.output_blocks.3.0.out_layers.0.bias', 'model.diffusion_model.output_blocks.3.0.out_layers.3.weight', 'model.diffusion_model.output_blocks.3.0.out_layers.3.bias', 'model.diffusion_model.output_blocks.3.0.skip_connection.weight', 'model.diffusion_model.output_blocks.3.0.skip_connection.bias', 'model.diffusion_model.output_blocks.3.1.norm.weight', 'model.diffusion_model.output_blocks.3.1.norm.bias', 'model.diffusion_model.output_blocks.3.1.proj_in.weight', 'model.diffusion_model.output_blocks.3.1.proj_in.bias', 'model.diffusion_model.output_blocks.3.1.transformer_blocks.0.attn1.to_q.weight', 'model.diffusion_model.output_blocks.3.1.transformer_blocks.0.attn1.to_k.weight', 'model.diffusion_model.output_blocks.3.1.transformer_blocks.0.attn1.to_v.weight', 'model.diffusion_model.output_blocks.3.1.transformer_blocks.0.attn1.to_out.0.weight', 'model.diffusion_model.output_blocks.3.1.transformer_blocks.0.attn1.to_out.0.bias', 'model.diffusion_model.output_blocks.3.1.transformer_blocks.0.ff.net.0.proj.weight', 'model.diffusion_model.output_blocks.3.1.transformer_blocks.0.ff.net.0.proj.bias', 'model.diffusion_model.output_blocks.3.1.transformer_blocks.0.ff.net.2.weight', 'model.diffusion_model.output_blocks.3.1.transformer_blocks.0.ff.net.2.bias', 'model.diffusion_model.output_blocks.3.1.transformer_blocks.0.attn2.to_q.weight', 'model.diffusion_model.output_blocks.3.1.transformer_blocks.0.attn2.to_k.weight', 'model.diffusion_model.output_blocks.3.1.transformer_blocks.0.attn2.to_v.weight', 'model.diffusion_model.output_blocks.3.1.transformer_blocks.0.attn2.to_out.0.weight', 'model.diffusion_model.output_blocks.3.1.transformer_blocks.0.attn2.to_out.0.bias', 'model.diffusion_model.output_blocks.3.1.transformer_blocks.0.norm1.weight', 'model.diffusion_model.output_blocks.3.1.transformer_blocks.0.norm1.bias', 'model.diffusion_model.output_blocks.3.1.transformer_blocks.0.norm2.weight', 'model.diffusion_model.output_blocks.3.1.transformer_blocks.0.norm2.bias', 'model.diffusion_model.output_blocks.3.1.transformer_blocks.0.norm3.weight', 'model.diffusion_model.output_blocks.3.1.transformer_blocks.0.norm3.bias', 'model.diffusion_model.output_blocks.3.1.proj_out.weight', 'model.diffusion_model.output_blocks.3.1.proj_out.bias', 'model.diffusion_model.output_blocks.4.0.in_layers.0.weight', 'model.diffusion_model.output_blocks.4.0.in_layers.0.bias', 'model.diffusion_model.output_blocks.4.0.in_layers.2.weight', 'model.diffusion_model.output_blocks.4.0.in_layers.2.bias', 'model.diffusion_model.output_blocks.4.0.emb_layers.1.weight', 'model.diffusion_model.output_blocks.4.0.emb_layers.1.bias', 'model.diffusion_model.output_blocks.4.0.out_layers.0.weight', 'model.diffusion_model.output_blocks.4.0.out_layers.0.bias', 'model.diffusion_model.output_blocks.4.0.out_layers.3.weight', 'model.diffusion_model.output_blocks.4.0.out_layers.3.bias', 'model.diffusion_model.output_blocks.4.0.skip_connection.weight', 'model.diffusion_model.output_blocks.4.0.skip_connection.bias', 'model.diffusion_model.output_blocks.4.1.norm.weight', 'model.diffusion_model.output_blocks.4.1.norm.bias', 'model.diffusion_model.output_blocks.4.1.proj_in.weight', 'model.diffusion_model.output_blocks.4.1.proj_in.bias', 'model.diffusion_model.output_blocks.4.1.transformer_blocks.0.attn1.to_q.weight', 'model.diffusion_model.output_blocks.4.1.transformer_blocks.0.attn1.to_k.weight', 'model.diffusion_model.output_blocks.4.1.transformer_blocks.0.attn1.to_v.weight', 'model.diffusion_model.output_blocks.4.1.transformer_blocks.0.attn1.to_out.0.weight', 'model.diffusion_model.output_blocks.4.1.transformer_blocks.0.attn1.to_out.0.bias', 'model.diffusion_model.output_blocks.4.1.transformer_blocks.0.ff.net.0.proj.weight', 'model.diffusion_model.output_blocks.4.1.transformer_blocks.0.ff.net.0.proj.bias', 'model.diffusion_model.output_blocks.4.1.transformer_blocks.0.ff.net.2.weight', 'model.diffusion_model.output_blocks.4.1.transformer_blocks.0.ff.net.2.bias', 'model.diffusion_model.output_blocks.4.1.transformer_blocks.0.attn2.to_q.weight', 'model.diffusion_model.output_blocks.4.1.transformer_blocks.0.attn2.to_k.weight', 'model.diffusion_model.output_blocks.4.1.transformer_blocks.0.attn2.to_v.weight', 'model.diffusion_model.output_blocks.4.1.transformer_blocks.0.attn2.to_out.0.weight', 'model.diffusion_model.output_blocks.4.1.transformer_blocks.0.attn2.to_out.0.bias', 'model.diffusion_model.output_blocks.4.1.transformer_blocks.0.norm1.weight', 'model.diffusion_model.output_blocks.4.1.transformer_blocks.0.norm1.bias', 'model.diffusion_model.output_blocks.4.1.transformer_blocks.0.norm2.weight', 'model.diffusion_model.output_blocks.4.1.transformer_blocks.0.norm2.bias', 'model.diffusion_model.output_blocks.4.1.transformer_blocks.0.norm3.weight', 'model.diffusion_model.output_blocks.4.1.transformer_blocks.0.norm3.bias', 'model.diffusion_model.output_blocks.4.1.proj_out.weight', 'model.diffusion_model.output_blocks.4.1.proj_out.bias', 'model.diffusion_model.output_blocks.5.0.in_layers.0.weight', 'model.diffusion_model.output_blocks.5.0.in_layers.0.bias', 'model.diffusion_model.output_blocks.5.0.in_layers.2.weight', 'model.diffusion_model.output_blocks.5.0.in_layers.2.bias', 'model.diffusion_model.output_blocks.5.0.emb_layers.1.weight', 'model.diffusion_model.output_blocks.5.0.emb_layers.1.bias', 'model.diffusion_model.output_blocks.5.0.out_layers.0.weight', 'model.diffusion_model.output_blocks.5.0.out_layers.0.bias', 'model.diffusion_model.output_blocks.5.0.out_layers.3.weight', 'model.diffusion_model.output_blocks.5.0.out_layers.3.bias', 'model.diffusion_model.output_blocks.5.0.skip_connection.weight', 'model.diffusion_model.output_blocks.5.0.skip_connection.bias', 'model.diffusion_model.output_blocks.5.1.norm.weight', 'model.diffusion_model.output_blocks.5.1.norm.bias', 'model.diffusion_model.output_blocks.5.1.proj_in.weight', 'model.diffusion_model.output_blocks.5.1.proj_in.bias', 'model.diffusion_model.output_blocks.5.1.transformer_blocks.0.attn1.to_q.weight', 'model.diffusion_model.output_blocks.5.1.transformer_blocks.0.attn1.to_k.weight', 'model.diffusion_model.output_blocks.5.1.transformer_blocks.0.attn1.to_v.weight', 'model.diffusion_model.output_blocks.5.1.transformer_blocks.0.attn1.to_out.0.weight', 'model.diffusion_model.output_blocks.5.1.transformer_blocks.0.attn1.to_out.0.bias', 'model.diffusion_model.output_blocks.5.1.transformer_blocks.0.ff.net.0.proj.weight', 'model.diffusion_model.output_blocks.5.1.transformer_blocks.0.ff.net.0.proj.bias', 'model.diffusion_model.output_blocks.5.1.transformer_blocks.0.ff.net.2.weight', 'model.diffusion_model.output_blocks.5.1.transformer_blocks.0.ff.net.2.bias', 'model.diffusion_model.output_blocks.5.1.transformer_blocks.0.attn2.to_q.weight', 'model.diffusion_model.output_blocks.5.1.transformer_blocks.0.attn2.to_k.weight', 'model.diffusion_model.output_blocks.5.1.transformer_blocks.0.attn2.to_v.weight', 'model.diffusion_model.output_blocks.5.1.transformer_blocks.0.attn2.to_out.0.weight', 'model.diffusion_model.output_blocks.5.1.transformer_blocks.0.attn2.to_out.0.bias', 'model.diffusion_model.output_blocks.5.1.transformer_blocks.0.norm1.weight', 'model.diffusion_model.output_blocks.5.1.transformer_blocks.0.norm1.bias', 'model.diffusion_model.output_blocks.5.1.transformer_blocks.0.norm2.weight', 'model.diffusion_model.output_blocks.5.1.transformer_blocks.0.norm2.bias', 'model.diffusion_model.output_blocks.5.1.transformer_blocks.0.norm3.weight', 'model.diffusion_model.output_blocks.5.1.transformer_blocks.0.norm3.bias', 'model.diffusion_model.output_blocks.5.1.proj_out.weight', 'model.diffusion_model.output_blocks.5.1.proj_out.bias', 'model.diffusion_model.output_blocks.5.2.conv.weight', 'model.diffusion_model.output_blocks.5.2.conv.bias', 'model.diffusion_model.output_blocks.6.0.in_layers.0.weight', 'model.diffusion_model.output_blocks.6.0.in_layers.0.bias', 'model.diffusion_model.output_blocks.6.0.in_layers.2.weight', 'model.diffusion_model.output_blocks.6.0.in_layers.2.bias', 'model.diffusion_model.output_blocks.6.0.emb_layers.1.weight', 'model.diffusion_model.output_blocks.6.0.emb_layers.1.bias', 'model.diffusion_model.output_blocks.6.0.out_layers.0.weight', 'model.diffusion_model.output_blocks.6.0.out_layers.0.bias', 'model.diffusion_model.output_blocks.6.0.out_layers.3.weight', 'model.diffusion_model.output_blocks.6.0.out_layers.3.bias', 'model.diffusion_model.output_blocks.6.0.skip_connection.weight', 'model.diffusion_model.output_blocks.6.0.skip_connection.bias', 'model.diffusion_model.output_blocks.6.1.norm.weight', 'model.diffusion_model.output_blocks.6.1.norm.bias', 'model.diffusion_model.output_blocks.6.1.proj_in.weight', 'model.diffusion_model.output_blocks.6.1.proj_in.bias', 'model.diffusion_model.output_blocks.6.1.transformer_blocks.0.attn1.to_q.weight', 'model.diffusion_model.output_blocks.6.1.transformer_blocks.0.attn1.to_k.weight', 'model.diffusion_model.output_blocks.6.1.transformer_blocks.0.attn1.to_v.weight', 'model.diffusion_model.output_blocks.6.1.transformer_blocks.0.attn1.to_out.0.weight', 'model.diffusion_model.output_blocks.6.1.transformer_blocks.0.attn1.to_out.0.bias', 'model.diffusion_model.output_blocks.6.1.transformer_blocks.0.ff.net.0.proj.weight', 'model.diffusion_model.output_blocks.6.1.transformer_blocks.0.ff.net.0.proj.bias', 'model.diffusion_model.output_blocks.6.1.transformer_blocks.0.ff.net.2.weight', 'model.diffusion_model.output_blocks.6.1.transformer_blocks.0.ff.net.2.bias', 'model.diffusion_model.output_blocks.6.1.transformer_blocks.0.attn2.to_q.weight', 'model.diffusion_model.output_blocks.6.1.transformer_blocks.0.attn2.to_k.weight', 'model.diffusion_model.output_blocks.6.1.transformer_blocks.0.attn2.to_v.weight', 'model.diffusion_model.output_blocks.6.1.transformer_blocks.0.attn2.to_out.0.weight', 'model.diffusion_model.output_blocks.6.1.transformer_blocks.0.attn2.to_out.0.bias', 'model.diffusion_model.output_blocks.6.1.transformer_blocks.0.norm1.weight', 'model.diffusion_model.output_blocks.6.1.transformer_blocks.0.norm1.bias', 'model.diffusion_model.output_blocks.6.1.transformer_blocks.0.norm2.weight', 'model.diffusion_model.output_blocks.6.1.transformer_blocks.0.norm2.bias', 'model.diffusion_model.output_blocks.6.1.transformer_blocks.0.norm3.weight', 'model.diffusion_model.output_blocks.6.1.transformer_blocks.0.norm3.bias', 'model.diffusion_model.output_blocks.6.1.proj_out.weight', 'model.diffusion_model.output_blocks.6.1.proj_out.bias', 'model.diffusion_model.output_blocks.7.0.in_layers.0.weight', 'model.diffusion_model.output_blocks.7.0.in_layers.0.bias', 'model.diffusion_model.output_blocks.7.0.in_layers.2.weight', 'model.diffusion_model.output_blocks.7.0.in_layers.2.bias', 'model.diffusion_model.output_blocks.7.0.emb_layers.1.weight', 'model.diffusion_model.output_blocks.7.0.emb_layers.1.bias', 'model.diffusion_model.output_blocks.7.0.out_layers.0.weight', 'model.diffusion_model.output_blocks.7.0.out_layers.0.bias', 'model.diffusion_model.output_blocks.7.0.out_layers.3.weight', 'model.diffusion_model.output_blocks.7.0.out_layers.3.bias', 'model.diffusion_model.output_blocks.7.0.skip_connection.weight', 'model.diffusion_model.output_blocks.7.0.skip_connection.bias', 'model.diffusion_model.output_blocks.7.1.norm.weight', 'model.diffusion_model.output_blocks.7.1.norm.bias', 'model.diffusion_model.output_blocks.7.1.proj_in.weight', 'model.diffusion_model.output_blocks.7.1.proj_in.bias', 'model.diffusion_model.output_blocks.7.1.transformer_blocks.0.attn1.to_q.weight', 'model.diffusion_model.output_blocks.7.1.transformer_blocks.0.attn1.to_k.weight', 'model.diffusion_model.output_blocks.7.1.transformer_blocks.0.attn1.to_v.weight', 'model.diffusion_model.output_blocks.7.1.transformer_blocks.0.attn1.to_out.0.weight', 'model.diffusion_model.output_blocks.7.1.transformer_blocks.0.attn1.to_out.0.bias', 'model.diffusion_model.output_blocks.7.1.transformer_blocks.0.ff.net.0.proj.weight', 'model.diffusion_model.output_blocks.7.1.transformer_blocks.0.ff.net.0.proj.bias', 'model.diffusion_model.output_blocks.7.1.transformer_blocks.0.ff.net.2.weight', 'model.diffusion_model.output_blocks.7.1.transformer_blocks.0.ff.net.2.bias', 'model.diffusion_model.output_blocks.7.1.transformer_blocks.0.attn2.to_q.weight', 'model.diffusion_model.output_blocks.7.1.transformer_blocks.0.attn2.to_k.weight', 'model.diffusion_model.output_blocks.7.1.transformer_blocks.0.attn2.to_v.weight', 'model.diffusion_model.output_blocks.7.1.transformer_blocks.0.attn2.to_out.0.weight', 'model.diffusion_model.output_blocks.7.1.transformer_blocks.0.attn2.to_out.0.bias', 'model.diffusion_model.output_blocks.7.1.transformer_blocks.0.norm1.weight', 'model.diffusion_model.output_blocks.7.1.transformer_blocks.0.norm1.bias', 'model.diffusion_model.output_blocks.7.1.transformer_blocks.0.norm2.weight', 'model.diffusion_model.output_blocks.7.1.transformer_blocks.0.norm2.bias', 'model.diffusion_model.output_blocks.7.1.transformer_blocks.0.norm3.weight', 'model.diffusion_model.output_blocks.7.1.transformer_blocks.0.norm3.bias', 'model.diffusion_model.output_blocks.7.1.proj_out.weight', 'model.diffusion_model.output_blocks.7.1.proj_out.bias', 'model.diffusion_model.output_blocks.8.0.in_layers.0.weight', 'model.diffusion_model.output_blocks.8.0.in_layers.0.bias', 'model.diffusion_model.output_blocks.8.0.in_layers.2.weight', 'model.diffusion_model.output_blocks.8.0.in_layers.2.bias', 'model.diffusion_model.output_blocks.8.0.emb_layers.1.weight', 'model.diffusion_model.output_blocks.8.0.emb_layers.1.bias', 'model.diffusion_model.output_blocks.8.0.out_layers.0.weight', 'model.diffusion_model.output_blocks.8.0.out_layers.0.bias', 'model.diffusion_model.output_blocks.8.0.out_layers.3.weight', 'model.diffusion_model.output_blocks.8.0.out_layers.3.bias', 'model.diffusion_model.output_blocks.8.0.skip_connection.weight', 'model.diffusion_model.output_blocks.8.0.skip_connection.bias', 'model.diffusion_model.output_blocks.8.1.norm.weight', 'model.diffusion_model.output_blocks.8.1.norm.bias', 'model.diffusion_model.output_blocks.8.1.proj_in.weight', 'model.diffusion_model.output_blocks.8.1.proj_in.bias', 'model.diffusion_model.output_blocks.8.1.transformer_blocks.0.attn1.to_q.weight', 'model.diffusion_model.output_blocks.8.1.transformer_blocks.0.attn1.to_k.weight', 'model.diffusion_model.output_blocks.8.1.transformer_blocks.0.attn1.to_v.weight', 'model.diffusion_model.output_blocks.8.1.transformer_blocks.0.attn1.to_out.0.weight', 'model.diffusion_model.output_blocks.8.1.transformer_blocks.0.attn1.to_out.0.bias', 'model.diffusion_model.output_blocks.8.1.transformer_blocks.0.ff.net.0.proj.weight', 'model.diffusion_model.output_blocks.8.1.transformer_blocks.0.ff.net.0.proj.bias', 'model.diffusion_model.output_blocks.8.1.transformer_blocks.0.ff.net.2.weight', 'model.diffusion_model.output_blocks.8.1.transformer_blocks.0.ff.net.2.bias', 'model.diffusion_model.output_blocks.8.1.transformer_blocks.0.attn2.to_q.weight', 'model.diffusion_model.output_blocks.8.1.transformer_blocks.0.attn2.to_k.weight', 'model.diffusion_model.output_blocks.8.1.transformer_blocks.0.attn2.to_v.weight', 'model.diffusion_model.output_blocks.8.1.transformer_blocks.0.attn2.to_out.0.weight', 'model.diffusion_model.output_blocks.8.1.transformer_blocks.0.attn2.to_out.0.bias', 'model.diffusion_model.output_blocks.8.1.transformer_blocks.0.norm1.weight', 'model.diffusion_model.output_blocks.8.1.transformer_blocks.0.norm1.bias', 'model.diffusion_model.output_blocks.8.1.transformer_blocks.0.norm2.weight', 'model.diffusion_model.output_blocks.8.1.transformer_blocks.0.norm2.bias', 'model.diffusion_model.output_blocks.8.1.transformer_blocks.0.norm3.weight', 'model.diffusion_model.output_blocks.8.1.transformer_blocks.0.norm3.bias', 'model.diffusion_model.output_blocks.8.1.proj_out.weight', 'model.diffusion_model.output_blocks.8.1.proj_out.bias', 'model.diffusion_model.output_blocks.8.2.conv.weight', 'model.diffusion_model.output_blocks.8.2.conv.bias', 'model.diffusion_model.output_blocks.9.0.in_layers.0.weight', 'model.diffusion_model.output_blocks.9.0.in_layers.0.bias', 'model.diffusion_model.output_blocks.9.0.in_layers.2.weight', 'model.diffusion_model.output_blocks.9.0.in_layers.2.bias', 'model.diffusion_model.output_blocks.9.0.emb_layers.1.weight', 'model.diffusion_model.output_blocks.9.0.emb_layers.1.bias', 'model.diffusion_model.output_blocks.9.0.out_layers.0.weight', 'model.diffusion_model.output_blocks.9.0.out_layers.0.bias', 'model.diffusion_model.output_blocks.9.0.out_layers.3.weight', 'model.diffusion_model.output_blocks.9.0.out_layers.3.bias', 'model.diffusion_model.output_blocks.9.0.skip_connection.weight', 'model.diffusion_model.output_blocks.9.0.skip_connection.bias', 'model.diffusion_model.output_blocks.9.1.norm.weight', 'model.diffusion_model.output_blocks.9.1.norm.bias', 'model.diffusion_model.output_blocks.9.1.proj_in.weight', 'model.diffusion_model.output_blocks.9.1.proj_in.bias', 'model.diffusion_model.output_blocks.9.1.transformer_blocks.0.attn1.to_q.weight', 'model.diffusion_model.output_blocks.9.1.transformer_blocks.0.attn1.to_k.weight', 'model.diffusion_model.output_blocks.9.1.transformer_blocks.0.attn1.to_v.weight', 'model.diffusion_model.output_blocks.9.1.transformer_blocks.0.attn1.to_out.0.weight', 'model.diffusion_model.output_blocks.9.1.transformer_blocks.0.attn1.to_out.0.bias', 'model.diffusion_model.output_blocks.9.1.transformer_blocks.0.ff.net.0.proj.weight', 'model.diffusion_model.output_blocks.9.1.transformer_blocks.0.ff.net.0.proj.bias', 'model.diffusion_model.output_blocks.9.1.transformer_blocks.0.ff.net.2.weight', 'model.diffusion_model.output_blocks.9.1.transformer_blocks.0.ff.net.2.bias', 'model.diffusion_model.output_blocks.9.1.transformer_blocks.0.attn2.to_q.weight', 'model.diffusion_model.output_blocks.9.1.transformer_blocks.0.attn2.to_k.weight', 'model.diffusion_model.output_blocks.9.1.transformer_blocks.0.attn2.to_v.weight', 'model.diffusion_model.output_blocks.9.1.transformer_blocks.0.attn2.to_out.0.weight', 'model.diffusion_model.output_blocks.9.1.transformer_blocks.0.attn2.to_out.0.bias', 'model.diffusion_model.output_blocks.9.1.transformer_blocks.0.norm1.weight', 'model.diffusion_model.output_blocks.9.1.transformer_blocks.0.norm1.bias', 'model.diffusion_model.output_blocks.9.1.transformer_blocks.0.norm2.weight', 'model.diffusion_model.output_blocks.9.1.transformer_blocks.0.norm2.bias', 'model.diffusion_model.output_blocks.9.1.transformer_blocks.0.norm3.weight', 'model.diffusion_model.output_blocks.9.1.transformer_blocks.0.norm3.bias', 'model.diffusion_model.output_blocks.9.1.proj_out.weight', 'model.diffusion_model.output_blocks.9.1.proj_out.bias', 'model.diffusion_model.output_blocks.10.0.in_layers.0.weight', 'model.diffusion_model.output_blocks.10.0.in_layers.0.bias', 'model.diffusion_model.output_blocks.10.0.in_layers.2.weight', 'model.diffusion_model.output_blocks.10.0.in_layers.2.bias', 'model.diffusion_model.output_blocks.10.0.emb_layers.1.weight', 'model.diffusion_model.output_blocks.10.0.emb_layers.1.bias', 'model.diffusion_model.output_blocks.10.0.out_layers.0.weight', 'model.diffusion_model.output_blocks.10.0.out_layers.0.bias', 'model.diffusion_model.output_blocks.10.0.out_layers.3.weight', 'model.diffusion_model.output_blocks.10.0.out_layers.3.bias', 'model.diffusion_model.output_blocks.10.0.skip_connection.weight', 'model.diffusion_model.output_blocks.10.0.skip_connection.bias', 'model.diffusion_model.output_blocks.10.1.norm.weight', 'model.diffusion_model.output_blocks.10.1.norm.bias', 'model.diffusion_model.output_blocks.10.1.proj_in.weight', 'model.diffusion_model.output_blocks.10.1.proj_in.bias', 'model.diffusion_model.output_blocks.10.1.transformer_blocks.0.attn1.to_q.weight', 'model.diffusion_model.output_blocks.10.1.transformer_blocks.0.attn1.to_k.weight', 'model.diffusion_model.output_blocks.10.1.transformer_blocks.0.attn1.to_v.weight', 'model.diffusion_model.output_blocks.10.1.transformer_blocks.0.attn1.to_out.0.weight', 'model.diffusion_model.output_blocks.10.1.transformer_blocks.0.attn1.to_out.0.bias', 'model.diffusion_model.output_blocks.10.1.transformer_blocks.0.ff.net.0.proj.weight', 'model.diffusion_model.output_blocks.10.1.transformer_blocks.0.ff.net.0.proj.bias', 'model.diffusion_model.output_blocks.10.1.transformer_blocks.0.ff.net.2.weight', 'model.diffusion_model.output_blocks.10.1.transformer_blocks.0.ff.net.2.bias', 'model.diffusion_model.output_blocks.10.1.transformer_blocks.0.attn2.to_q.weight', 'model.diffusion_model.output_blocks.10.1.transformer_blocks.0.attn2.to_k.weight', 'model.diffusion_model.output_blocks.10.1.transformer_blocks.0.attn2.to_v.weight', 'model.diffusion_model.output_blocks.10.1.transformer_blocks.0.attn2.to_out.0.weight', 'model.diffusion_model.output_blocks.10.1.transformer_blocks.0.attn2.to_out.0.bias', 'model.diffusion_model.output_blocks.10.1.transformer_blocks.0.norm1.weight', 'model.diffusion_model.output_blocks.10.1.transformer_blocks.0.norm1.bias', 'model.diffusion_model.output_blocks.10.1.transformer_blocks.0.norm2.weight', 'model.diffusion_model.output_blocks.10.1.transformer_blocks.0.norm2.bias', 'model.diffusion_model.output_blocks.10.1.transformer_blocks.0.norm3.weight', 'model.diffusion_model.output_blocks.10.1.transformer_blocks.0.norm3.bias', 'model.diffusion_model.output_blocks.10.1.proj_out.weight', 'model.diffusion_model.output_blocks.10.1.proj_out.bias', 'model.diffusion_model.output_blocks.11.0.in_layers.0.weight', 'model.diffusion_model.output_blocks.11.0.in_layers.0.bias', 'model.diffusion_model.output_blocks.11.0.in_layers.2.weight', 'model.diffusion_model.output_blocks.11.0.in_layers.2.bias', 'model.diffusion_model.output_blocks.11.0.emb_layers.1.weight', 'model.diffusion_model.output_blocks.11.0.emb_layers.1.bias', 'model.diffusion_model.output_blocks.11.0.out_layers.0.weight', 'model.diffusion_model.output_blocks.11.0.out_layers.0.bias', 'model.diffusion_model.output_blocks.11.0.out_layers.3.weight', 'model.diffusion_model.output_blocks.11.0.out_layers.3.bias', 'model.diffusion_model.output_blocks.11.0.skip_connection.weight', 'model.diffusion_model.output_blocks.11.0.skip_connection.bias', 'model.diffusion_model.output_blocks.11.1.norm.weight', 'model.diffusion_model.output_blocks.11.1.norm.bias', 'model.diffusion_model.output_blocks.11.1.proj_in.weight', 'model.diffusion_model.output_blocks.11.1.proj_in.bias', 'model.diffusion_model.output_blocks.11.1.transformer_blocks.0.attn1.to_q.weight', 'model.diffusion_model.output_blocks.11.1.transformer_blocks.0.attn1.to_k.weight', 'model.diffusion_model.output_blocks.11.1.transformer_blocks.0.attn1.to_v.weight', 'model.diffusion_model.output_blocks.11.1.transformer_blocks.0.attn1.to_out.0.weight', 'model.diffusion_model.output_blocks.11.1.transformer_blocks.0.attn1.to_out.0.bias', 'model.diffusion_model.output_blocks.11.1.transformer_blocks.0.ff.net.0.proj.weight', 'model.diffusion_model.output_blocks.11.1.transformer_blocks.0.ff.net.0.proj.bias', 'model.diffusion_model.output_blocks.11.1.transformer_blocks.0.ff.net.2.weight', 'model.diffusion_model.output_blocks.11.1.transformer_blocks.0.ff.net.2.bias', 'model.diffusion_model.output_blocks.11.1.transformer_blocks.0.attn2.to_q.weight', 'model.diffusion_model.output_blocks.11.1.transformer_blocks.0.attn2.to_k.weight', 'model.diffusion_model.output_blocks.11.1.transformer_blocks.0.attn2.to_v.weight', 'model.diffusion_model.output_blocks.11.1.transformer_blocks.0.attn2.to_out.0.weight', 'model.diffusion_model.output_blocks.11.1.transformer_blocks.0.attn2.to_out.0.bias', 'model.diffusion_model.output_blocks.11.1.transformer_blocks.0.norm1.weight', 'model.diffusion_model.output_blocks.11.1.transformer_blocks.0.norm1.bias', 'model.diffusion_model.output_blocks.11.1.transformer_blocks.0.norm2.weight', 'model.diffusion_model.output_blocks.11.1.transformer_blocks.0.norm2.bias', 'model.diffusion_model.output_blocks.11.1.transformer_blocks.0.norm3.weight', 'model.diffusion_model.output_blocks.11.1.transformer_blocks.0.norm3.bias', 'model.diffusion_model.output_blocks.11.1.proj_out.weight', 'model.diffusion_model.output_blocks.11.1.proj_out.bias', 'model.diffusion_model.out.0.weight', 'model.diffusion_model.out.0.bias', 'model.diffusion_model.out.2.weight', 'model.diffusion_model.out.2.bias']

Unexpected Keys:
 ['model_ema.decay', 'model_ema.num_updates']
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]
LOCAL_RANK: 7 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]
LOCAL_RANK: 5 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]
LOCAL_RANK: 4 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]
LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]
LOCAL_RANK: 6 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]
LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]
LOCAL_RANK: 7 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]
LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]
LOCAL_RANK: 6 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]
LOCAL_RANK: 4 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]
LOCAL_RANK: 5 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]
LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]
LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]
LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]
worker-1:5776:5864 [0] NCCL INFO Channel 01/0Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is None and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is 1024 and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is None and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is 1024 and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is None and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is 1024 and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is None and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is 1024 and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is None and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is 1024 and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is None and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is 1024 and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is None and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is 1024 and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is None and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is 1024 and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is None and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is 1024 and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is None and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is 1024 and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is None and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is 1024 and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is None and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is 1024 and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is None and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is 1024 and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is None and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is 1024 and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is None and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is 1024 and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is None and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is 1024 and using 5 heads.
DiffusionWrapper has 865.91 M params.
:::MLLOG {"namespace": "", "time_ms": 1718487891091, "event_type": "POINT_IN_TIME", "key": "opt_name", "value": "adamw", "metadata": {"file": "ldm/models/diffusion/ddpm.py", "lineno": 1639}}
:::MLLOG {"namespace": "", "time_ms": 1718487891201, "event_type": "POINT_IN_TIME", "key": "opt_adamw_beta_1", "value": 0.9, "metadata": {"file": "ldm/models/diffusion/ddpm.py", "lineno": 1640}}
:::MLLOG {"namespace": "", "time_ms": 1718487891203, "event_type": "POINT_IN_TIME", "key": "opt_adamw_beta_2", "value": 0.999, "metadata": {"file": "ldm/models/diffusion/ddpm.py", "lineno": 1641}}
:::MLLOG {"namespace": "", "time_ms": 1718487891204, "event_type": "POINT_IN_TIME", "key": "opt_adamw_epsilon", "value": 1e-08, "metadata": {"file": "ldm/models/diffusion/ddpm.py", "lineno": 1642}}
:::MLLOG {"namespace": "", "time_ms": 1718487891205, "event_type": "POINT_IN_TIME", "key": "opt_adamw_weight_decay", "value": 0.01, "metadata": {"file": "ldm/models/diffusion/ddpm.py", "lineno": 1643}}
:::MLLOG {"namespace": "", "time_ms": 1718487891206, "event_type": "POINT_IN_TIME", "key": "opt_base_learning_rate", "value": 1.6e-05, "metadata": {"file": "ldm/models/diffusion/ddpm.py", "lineno": 1644}}
:::MLLOG {"namespace": "", "time_ms": 1718487891208, "event_type": "POINT_IN_TIME", "key": "opt_learning_rate_warmup_steps", "value": 1000, "metadata": {"file": "ldm/models/diffusion/ddpm.py", "lineno": 1650}}
Setting up LambdaLR scheduler...
Project config
model:
  base_learning_rate: 1.25e-07
  target: ldm.models.diffusion.ddpm.LatentDiffusion
  params:
    parameterization: v
    linear_start: 0.00085
    linear_end: 0.012
    num_timesteps_cond: 1
    log_every_t: 200
    timesteps: 1000
    first_stage_key: npy
    first_stage_type: moments
    cond_stage_key: txt
    image_size: 64
    channels: 4
    cond_stage_trainable: false
    conditioning_key: crossattn
    monitor: steps
    scale_factor: 0.18215
    use_ema: false
    load_vae: true
    load_unet: false
    load_encoder: true
    validation_config:
      sampler: ddim
      steps: 50
      scale: 8.0
      ddim_eta: 0.0
      prompt_key: caption
      image_fname_key: image_id
      save_images:
        enabled: false
        base_output_dir: /results/inference
      fid:
        enabled: true
        inception_weights_url: https://github.com/mseitzer/pytorch-fid/releases/download/fid_weights/pt_inception-2015-12-05-6726825d.pth
        cache_dir: /checkpoints/inception
        gt_path: /datasets/coco2014/val2014_30k_stats.npz
      clip:
        enabled: true
        clip_version: ViT-H-14
        cache_dir: /checkpoints/clip
    scheduler_config:
      target: ldm.lr_scheduler.LambdaLinearScheduler
      params:
        warm_up_steps:
        - 1000
        cycle_lengths:
        - 10000000000000
        f_start:
        - 1.0e-06
        f_max:
        - 1.0
        f_min:
        - 1.0
    unet_config:
      target: ldm.modules.diffusionmodules.openaimodel.UNetModel
      params:
        use_checkpoint: false
        use_fp16: true
        image_size: 32
        in_channels: 4
        out_channels: 4
        model_channels: 320
        attention_resolutions:
        - 4
        - 2
        - 1
        num_res_blocks: 2
        channel_mult:
        - 1
        - 2
        - 4
        - 4
        num_head_channels: 64
        use_spatial_transformer: true
        use_linear_in_transformer: true
        transformer_depth: 1
        context_dim: 1024
        legacy: false
    first_stage_config:
      target: ldm.models.autoencoder.AutoencoderKL
      params:
        embed_dim: 4
        monitor: val/rec_loss
        ddconfig:
          double_z: true
          z_channels: 4
          resolution: 256
          in_channels: 3
          out_ch: 3
          ch: 128
          ch_mult:
          - 1
          - 2
          - 4
          - 4
          num_res_blocks: 2
          attn_resolutions: []
          dropout: 0.0
        lossconfig:
          target: torch.nn.Identity
    cond_stage_config:
      target: ldm.modules.encoders.modules.FrozenOpenCLIPEmbedder
      params:
        arch: ViT-H-14
        version: laion2b_s32b_b79k
        freeze: true
        layer: penultimate
        cache_dir: /checkpoints/clip
    use_fp16: true
    ckpt: /checkpoints/sd/512-base-ema.ckpt
data:
  target: ldm.data.composable_data_module.ComposableDataModule
  params:
    train:
      target: ldm.data.webdatasets.build_dataloader
      params:
        urls: /datasets/laion-400m/webdataset-moments-filtered/{00000..00831}.tar
        batch_size: 8
        shuffle: 1000
        partial: false
        keep_only_keys:
        - npy
        - txt
        num_workers: 4
        persistent_workers: true
    validation:
      target: ldm.data.tsv.build_dataloader
      params:
        annotations_file: /datasets/coco2014/val2014_30k.tsv
        keys:
        - image_id
        - id
        - caption
        batch_size: 8
        shuffle: false
        num_workers: 1

Lightning config
trainer:
  accelerator: gpu
  num_nodes: 2
  devices: 8
  precision: 16
  logger: false
  log_every_n_steps: 5
  enable_progress_bar: false
  max_epochs: -1
  max_steps: 10000000000000
  val_check_interval: 1000
  enable_checkpointing: true
  num_sanity_val_steps: 0
  strategy:
    target: strategies.DDPStrategy
    params:
      find_unused_parameters: false
modelcheckpoint:
  target: lightning.pytorch.callbacks.ModelCheckpoint
  params:
    save_top_k: -1
    every_n_train_steps: 1000

:::MLLOG {"namespace": "", "time_ms": 1718487891269, "event_type": "INTERVAL_START", "key": "run_start", "value": null, "metadata": {"file": "mlperf_logging_utils.py", "lineno": 88}}

  | Name              | Type                   | Params
-------------------------------------------------------------
0 | model             | DiffusionWrapper       | 865 M 
1 | first_stage_model | AutoencoderKL          | 83.7 M
2 | cond_stage_model  | FrozenOpenCLIPEmbedder | 354 M 
-------------------------------------------------------------
865 M     Trainable params
437 M     Non-trainable params
1.3 B     Total params
2,607.194 Total estimated model params size (MB)
/usr/local/lib/python3.10/dist-packages/lightning/pytorch/loggers/tensorboard.py:188: UserWarning: Could not log computational graph to TensorBoard: The `model.example_input_array` attribute is not set or `input_array` was not given.
  rank_zero_warn(
SLURM auto-requeueing enabled. Setting signal handlers.
SLURM auto-requeueing enabled. Setting signal handlers.
SLURM auto-requeueing enabled. Setting signal handlers.
SLURM auto-requeueing enabled. Setting signal handlers.
SLURM auto-requeueing enabled. Setting signal handlers.
SLURM auto-requeueing enabled. Setting signal handlers.
SLURM auto-requeueing enabled. Setting signal handlers.
SLURM auto-requeueing enabled. Setting signal handlers.
SLURM auto-requeueing enabled. Setting signal handlers.
SLURM auto-requeueing enabled. Setting signal handlers.
SLURM auto-requeueing enabled. Setting signal handlers.
SLURM auto-requeueing enabled. Setting signal handlers.
SLURM auto-requeueing enabled. Setting signal handlers.
SLURM auto-requeueing enabled. Setting signal handlers.
SLURM auto-requeueing enabled. Setting signal handlers.
SLURM auto-requeueing enabled. Setting signal handlers.
/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
worker-1:5778:5868 [3] NCCL INFO threadTSetting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is None and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is 1024 and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is None and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is 1024 and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is None and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is 1024 and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is None and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is 1024 and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is None and using 20 heads.
/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
worker-0:5742:5831 [4] NCCL INFO Channel 11/0 : 12[4]Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is None and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is 1024 and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is None and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is 1024 and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is None and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is 1024 and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is None and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is 1024 and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is None and using 20 heads.
/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is 1024 and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is None and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is 1024 and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is None and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is 1024 and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is None and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is 1024 and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is None and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is 1024 and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is None and using 20 heads.
/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is 1024 and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is None and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is 1024 and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is None and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is 1024 and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is None and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is 1024 and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is None and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is 1024 and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is None and using 20 heads.
/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is 1024 and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is None and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is 1024 and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is None and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is 1024 and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is None and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is 1024 and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is None and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is 1024 and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is None and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is 1024 and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is None and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is 1024 and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is None and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is 1024 and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is None and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is 1024 and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is None and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is 1024 and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is None and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is 1024 and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is None and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is 1024 and using 5 heads.
DiffusionWrapper has 865.91 M params.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is 1024 and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is None and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is 1024 and using 5 heads.
DiffusionWrapper has 865.91 M params.
hresholds 8/8/64 | 128/8/64 | 512 | 512
worker-1:5778:5868 [3] NCCL INFO 16 coll channels, 16 nvls channels, 16 p2p channels, 2 p2p channels per peer
worker-1:5778:5868 [3] NCCL INFO comm 0x557bfad72dd0 rank 3 nranks 16 cudaDev 3 nvmlDev 3 busId 99000 commId 0xfd5d9e8febee040d - Init COMPLETE
worker-0:5745:5832 [0] NCCL INFO Channel 12/0 : 8[0] -> Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is None and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is 1024 and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is None and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is 1024 and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is None and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is 1024 and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is None and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is 1024 and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is None and using 20 heads.
worker-1:5783:5865 [5] NCCSetting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is None and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is 1024 and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is None and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is 1024 and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is None and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is 1024 and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is None and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is 1024 and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is None and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is 1024 and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is None and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is 1024 and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is None and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is 1024 and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is None and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is 1024 and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is None and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is 1024 and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is None and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is 1024 and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is None and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is 1024 and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is None and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is 1024 and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is None and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is 1024 and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is None and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is 1024 and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is None and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is 1024 and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is None and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is 1024 and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is None and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is 1024 and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is None and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is 1024 and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is None and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is 1024 and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is None and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is 1024 and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is None and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is 1024 and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is None and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is 1024 and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is None and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is 1024 and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is None and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is 1024 and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is None and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is 1024 and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is None and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is 1024 and using 5 heads.
DiffusionWrapper has 865.91 M params.
9[1] via P2P/CUMEM
worker-0:5745:5832 [0] NCCL INFO Channel 13/0 : 8[0] -> 9[1] via P2P/CUMEM
worker-0:5745:5832 [0] NCCL INFO Channel 14/0 : 8[0] -> 9[1] via P2P/CUMEM
worker-0:5745:5832 [0] NCCL INFO Channel 15/0 : 8[0] -> 9[1] via P2P/CUMEM
worker-0:5745:5832 [0] NCCL INFO Channel 07/0 : 8[0] -> 15[7] via P2P/CUMEM
worker-0:5745:5832 [0] NCCL INFO Channel 15/0 : 8[0] -> 15[7] via P2P/CUMEM
worker-0:5745:5832 [0] NCCL INFO Channel 00/0 : 0[0] -> 8[0] [receive] via NET/IBext/4/GDRDMA
worker-0:5745:5832 [0] NCCL INFO Channel 08/0 : 0[0] -> 8[0] [receive] via NET/IBext/4/GDRDMA
worker-0:5745:5832 [0] NCCL INFO Channel 00/0 : 8[0] -> 0[0] [send] via NET/IBext/4/GDRDMA
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is 1024 and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is None and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is 1024 and using 5 heads.
DiffusionWrapper has 865.91 M params.
worker-0:5745:5832 [0] NCCL INFO Channel 08/0 : 8[0] -> 0[0] [send] via NET/IBext/4/GDRDMA
L INFO 16 coll channels, 16 nvls channels, 16 p2p channels, 2 p2p channels per peer
worker-1:5783:5865 [5] NCCL INFO comm 0x557b6d2784a0 rank 5 nranks 16 cudaDev 5 nvmlDev 5 busId af000 commId 0xfd5d9e8febee040d - Init COMPLETE
worker-0:5741:583Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is None and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is 1024 and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is None and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is 1024 and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is None and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is 1024 and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is None and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is 1024 and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is None and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is 1024 and using 20 heads.
worker-1:5782:5866 [4] NCCSetting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is None and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is 1024 and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is None and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is 1024 and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is None and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is 1024 and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is None and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is 1024 and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is None and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is None and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is 1024 and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is None and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is 1024 and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is None and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is 1024 and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is None and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is 1024 and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is None and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is 1024 and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is 1024 and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is None and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is 1024 and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is None and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is 1024 and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is None and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is 1024 and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is None and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is 1024 and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is None and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is None and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is 1024 and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is None and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is 1024 and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is None and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is 1024 and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is None and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is 1024 and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is None and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is 1024 and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is 1024 and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is None and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is 1024 and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is None and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is 1024 and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is None and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is 1024 and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is None and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is 1024 and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is None and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is None and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is 1024 and using 5 heads.
DiffusionWrapper has 865.91 M params.
0 [2] NCCL INFO Channel 12/0 : 10[2] -> 11[3] via P2P/CUMEM
worker-0:5741:5830 [2] NCCL INFO Channel 13/0 : 10[2] -> 11[3] via P2P/CUMEM
worker-0:5741:5830 [2] NCCL INFO Channel 14/0 : 10[2] -> 11[3] via P2P/CUMEM
worker-0:5741:5830 [2] NCCL INFO Channel 15/0 : 10[2] -> 11[3] via P2P/CUMEM
worker-0:5741:5830 [2] NCCL INFO Channel 02/0 : 2[2] -> 10[2] [receive] via NET/IBext/6/GDRDMA
worker-0:5741:5830 [2] NCCL INFO Channel 10/0 : 2[2] -> 10[2] [receive] via NET/IBext/6/GDRDMA
worker-0:5741:5830 [2] NCCL INFO Channel 02/0 : 10[2] -> 2[2] [send] via NET/IBext/6/GDRDMA
worker-0:5741:5830 [2] NCCL INFO Channel 10/0 : 10[2] -> 2[2] [send] via NET/IBext/6/GDRDMA
worker-0:5741:5830 [2] NCCL INFO Channel 01/0 : 10[2] -> 9[1] via P2P/CUMEM
/usr/local/lib/python3.10/dist-packages/lightning/pytorch/trainer/connectors/data_connector.py:224: PossibleUserWarning: The dataloader, val_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 160 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  rank_zero_warn(
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is 1024 and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is None and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is 1024 and using 5 heads.
DiffusionWrapper has 865.91 M params.
Training is starting
worker-0:5741:5830 [2] NCCL INFO Channel 09/0 : 10[2] -> 9[1] via P2P/CUMEM
/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
L INFO 16 coll channels, 16 nvls channels, 16 p2p channels, 2 p2p channels per peer
worker-1:5782:5866 [4] NCCL INFO comm 0x560f2e6b1fa0 rank 4 nranks 16 cudaDev 4 nvmlDev 4 busId ab000 commId 0xfd5d9e8febee040d - Init COMPLETE
/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
 -> 13[5] via P2P/CUMEM
worker-0:5742:5831 [4] NCCL INFO Channel 12/0 : 12[4] -> 13[5] via P2P/CUMEM
worker-0:5742:5831 [4] NCCL INFO Channel 14/0 : 12[4] -> 13[5] via P2P/CUMEM
worker-0:5742:5831 [4] NCCL INFO Channel 15/0 : 12[4] -> 13[5] via P2P/CUMEM
worker-0:5742:5831 [4] NCCL INFO Channel 04/0 : 4[4] -> 12[4] [receive] via NET/IBext/0/GDRDMA
worker-0:5742:5831 [4] NCCL INFO Channel 12/0 : 4[4] -> 12[4] [receive] via NET/IBext/0/GDRDMA
worker-0:5742:5831 [4] NCCL INFO Channel 04/0 : 12[4] -> 4[4] [send] via NET/IBext/0/GDRDMA
worker-0:5742:5831 [4] NCCL INFO Channel 12/0 : 12[4] -> 4[4] [send] via NET/IBext/0/GDRDMA
worker-0:5742:5831 [4] NCCL INFO Channel 03/0 : 12[4] -> 11[3] via P2P/CUMEM
worker-0:5742:5831 [4] NCCL INFO Channel 11/0 : 12[4] -> 11[3] via P2P/CUMEM
worker-0:5742:5831 [4] NCCL INFO Connected all trees
worker-0:5742:5831 [4] NCCL INFO NVLS comm 0x55ea104763d0 headRank 4 nHeads 8 buffSize 4194304 memSize 2097152 nvlsPerRankSize 201326592 nvlsTotalSize 1610612736
worker-1:5780:5867 [2] NCCL INFO threadThrSetting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is None and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is 1024 and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is None and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is 1024 and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is None and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is 1024 and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is None and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is 1024 and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is None and using 20 heads.
/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
worker-0:5742:5831 [4] NCCL INFO Channel 00/0 : 4[4] -> 12[4] [receive] via NET/IBext/0/GDRDMA
worker-0:5742:5831 [4] NCCL INFO Channel 01/0 : 4[4] -> 12[4] [receive] via NET/IBext/0/GDRDMA
worker-0:5742:5831 [4] NCCL INFO Channel 02/0 : 4[4] -> 12[4] [receive] via NET/IBext/0/GDRDMA
worker-0:5742:5831 [4] NCCL INFO Channel 03/0 : 4[4] -> 12[4] [receive] via NET/IBext/0/GDRDMA
worker-0:5742:5831 [4] NCCL INFO Channel 05/0 : 4[4] -> 12[4] [receive] via NET/IBext/0/GDRDMA
worker-0:5742:5831 [4] NCCL INFO Channel 06/0 : 4[4] -> 12[4] [receive] via NET/IBext/0/GDRDMA
worker-0:5742:5831 [4] NCCL INFO Channel 07/0 : 4[4] -> 12[4] [receive] via NET/IBext/0/GDRDMA
worker-0:5742:5831 [4] NCCL INFO Channel 08/0 : 4[4] -> 12[4] [receive] via NET/IBext/0/GDRDMA
worker-0:5742:5831 [4] NCCL INFO Channel 09/0 : 4[4] -> 12[4] [receive] via NET/IBext/0/GDRDMA
worker-0:5742:5831 [4] NCCL INFO Channel 10/0 : 4[4] -> 12[4] [receive] via NET/IBext/0/GDRDMA
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is 1024 and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is None and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is 1024 and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is None and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is 1024 and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is None and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is 1024 and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is None and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is 1024 and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is None and using 20 heads.
worker-0:5742:5831 [4] NCCL INFO Channel 11/0 : 4[4] -> 12[4] [receive] via NET/IBext/0/GDRDMA
worker-0:5742:5831 [4] NCCL INFO Channel 13/0 : 4[4] -> 12[4] [receive] via NET/IBext/0/GDRDMA
worker-0:5742:5831 [4] NCCL INFO Channel 14/0 : 4[4] -> 12[4] [receive] via NET/IBext/0/GDRDMA
worker-0:5742:5831 [4] NCCL INFO Channel 15/0 : 4[4] -> 12[4] [receive] via NET/IBext/0/GDRDMA
worker-0:5742:5831 [4] NCCL INFO Channel 00/0 : 12[4] -> 4[4] [send] via NET/IBext/0/GDRDMA
worker-0:5742:5831 [4] NCCL INFO Channel 01/0 : 12[4] -> 4[4] [send] via NET/IBext/0/GDRDMA
worker-0:5742:5831 [4] NCCL INFO Channel 02/0 : 12[4] -> 4[4] [send] via NET/IBext/0/GDRDMA
worker-0:5742:5831 [4] NCCL INFO Channel 03/0 : 12[4] -> 4[4] [send] via NET/IBext/0/GDRDMA
worker-0:5742:5831 [4] NCCL INFO Channel 05/0 : 12[4] -> 4[4] [send] via NET/IBext/0/GDRDMA
worker-0:5742:5831 [4] NCCL INFO Channel 06/0 : 12[4] -> 4[4] [send] via NET/IBext/0/GDRDMA
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is 1024 and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is None and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is 1024 and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is None and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is 1024 and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is None and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is 1024 and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is None and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is 1024 and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is None and using 5 heads.
worker-0:5742:5831 [4] NCCL INFO Channel 07/0 : 12[4] -> 4[4] [send] via NET/IBext/0/GDRDMA
worker-0:5742:5831 [4] NCCL INFO Channel 08/0 : 12[4] -> 4[4] [send] via NET/IBext/0/GDRDMA
worker-0:5742:5831 [4] NCCL INFO Channel 09/0 : 12[4] -> 4[4] [send] via NET/IBext/0/GDRDMA
worker-0:5742:5831 [4] NCCL INFO Channel 10/0 : 12[4] -> 4[4] [send] via NET/IBext/0/GDRDMA
worker-0:5742:5831 [4] NCCL INFO Channel 11/0 : 12[4] -> 4[4] [send] via NET/IBext/0/GDRDMA
worker-0:5742:5831 [4] NCCL INFO Channel 13/0 : 12[4] -> 4[4] [send] via NET/IBext/0/GDRDMA
worker-0:5742:5831 [4] NCCL INFO Channel 14/0 : 12[4] -> 4[4] [send] via NET/IBext/0/GDRDMA
worker-0:5742:5831 [4] NCCL INFO Channel 15/0 : 12[4] -> 4[4] [send] via NET/IBext/0/GDRDMA
worker-0:5742:5831 [4] NCCL INFO Connected NVLS tree
worker-0:5742:5831 [4] NCCL INFO threadThresholds 8/8/64 | 128/8/64 | 512 | 512
worker-0:5742:5831 [4] NCCL INFO 16 coll channels, 16 nvls channels, 16 p2p channels, 2 p2p channels per peer
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is 1024 and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is None and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is 1024 and using 5 heads.
DiffusionWrapper has 865.91 M params.
/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
worker-0:5742:5831 [4] NCCL INFO comm 0x55ea104763d0 rank 12 nranks 16 cudaDev 4 nvmlDev 4 busId ab000 commId 0xfd5d9e8febee040d - Init COMPLETE
esholds 8/8/64 | 128/8/64 | 512 | 512
worker-1:5780:5867 [2] NCCL INFO 16 coll channels, 16 nvls channels, 16 p2p channels, 2 p2p channels per peer
worker-1:5780:5867 [2] NCCL INFO comm 0x558b9d3cada0 rank 2 nranks 16 cudaDev 2 nvmlDev 2 busId 95000 commId 0xfd5d9e8febee040d - Init COMPLETE
worker-0:5745:5832 [0] NCCL INFO Connected all trees
worker-0:5745:5832 [0] NCCL INFO NVLS comm 0x55624bbca340 headRank 0 nHeads 8 buffSize 4194304 memSize 2097152 nvlsPerRankSize 201326592 nvlsTotalSize 1610612736
worker-0:5745:5832 [0] NCCL INFO Channel 01/0 : 0[0] -> 8[0] [receive] via NET/IBext/4/GDRDMA
worker-0:5745:5832 [0] NCCL INFO Channel 02/0 : 0[0] -> 8[0] [receive] via NET/IBext/4/GDRDMA
worker-0:5745:5832 [0] NCCL INFO Channel 03/0 : 0[0] -> 8[0] [receive] via NET/IBext/4/GDRDMA
worker-0:5745:5832 [0] NCCL INFO Channel 04/0 : 0[0] -> 8[0] [receive] via NET/IBext/4/GDRDMA
worker-0:5745:5832 [0] NCCL INFO Channel 05/0 : 0[0] -> 8[0] [receive] via NET/IBext/4/GDRDMA
worker-0:5745:5832 [0] NCCL INFO Channel 06/0 : 0[0] -> 8[0] [receive] via NET/IBext/4/GDRDMA
worker-0:5745:5832 [0] NCCL INFO Channel 07/0 : 0[0] -> 8[0] [receive] via NET/IBext/4/GDRDMA
worker-0:5745:5832 [0] NCCL INFO Channel 09/0 : 0[0] -> 8[0] [receive] via NET/IBext/4/GDRDMA
worker-1:5774:5863 [7] NCCL Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is None and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is 1024 and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is None and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is 1024 and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is None and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is 1024 and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is None and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is 1024 and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is None and using 20 heads.
worker-0:5745:5832 [0] NCCL INFO Channel 10/0 : 0[0] -> 8[0] [receive] via NET/IBext/4/GDRDMA
worker-0:5745:5832 [0] NCCL INFO Channel 11/0 : 0[0] -> 8[0] [receive] via NET/IBext/4/GDRDMA
worker-0:5745:5832 [0] NCCL INFO Channel 12/0 : 0[0] -> 8[0] [receive] via NET/IBext/4/GDRDMA
worker-0:5745:5832 [0] NCCL INFO Channel 13/0 : 0[0] -> 8[0] [receive] via NET/IBext/4/GDRDMA
worker-0:5745:5832 [0] NCCL INFO Channel 14/0 : 0[0] -> 8[0] [receive] via NET/IBext/4/GDRDMA
worker-0:5745:5832 [0] NCCL INFO Channel 15/0 : 0[0] -> 8[0] [receive] via NET/IBext/4/GDRDMA
worker-0:5745:5832 [0] NCCL INFO Channel 01/0 : 8[0] -> 0[0] [send] via NET/IBext/4/GDRDMA
worker-0:5745:5832 [0] NCCL INFO Channel 02/0 : 8[0] -> 0[0] [send] via NET/IBext/4/GDRDMA
worker-0:5745:5832 [0] NCCL INFO Channel 03/0 : 8[0] -> 0[0] [send] via NET/IBext/4/GDRDMA
worker-0:5745:5832 [0] NCCL INFO Channel 04/0 : 8[0] -> 0[0] [send] via NET/IBext/4/GDRDMA
worker-0:5745:5832 [0] NCCL INFO Channel 05/0 : 8[0] -> 0[0] [send] via NET/IBext/4/GDRDMA
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is 1024 and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is None and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is 1024 and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is None and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is 1024 and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is None and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is 1024 and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is None and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is 1024 and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is None and using 20 heads.
worker-0:5745:5832 [0] NCCL INFO Channel 06/0 : 8[0] -> 0[0] [send] via NET/IBext/4/GDRDMA
worker-0:5745:5832 [0] NCCL INFO Channel 07/0 : 8[0] -> 0[0] [send] via NET/IBext/4/GDRDMA
worker-0:5745:5832 [0] NCCL INFO Channel 09/0 : 8[0] -> 0[0] [send] via NET/IBext/4/GDRDMA
worker-0:5745:5832 [0] NCCL INFO Channel 10/0 : 8[0] -> 0[0] [send] via NET/IBext/4/GDRDMA
worker-0:5745:5832 [0] NCCL INFO Channel 11/0 : 8[0] -> 0[0] [send] via NET/IBext/4/GDRDMA
worker-0:5745:5832 [0] NCCL INFO Channel 12/0 : 8[0] -> 0[0] [send] via NET/IBext/4/GDRDMA
worker-0:5745:5832 [0] NCCL INFO Channel 13/0 : 8[0] -> 0[0] [send] via NET/IBext/4/GDRDMA
worker-0:5745:5832 [0] NCCL INFO Channel 14/0 : 8[0] -> 0[0] [send] via NET/IBext/4/GDRDMA
worker-0:5745:5832 [0] NCCL INFO Channel 15/0 : 8[0] -> 0[0] [send] via NET/IBext/4/GDRDMA
worker-0:5745:5832 [0] NCCL INFO Connected NVLS tree
worker-0:5745:5832 [0] NCCL INFO threadThresholds 8/8/64 | 128/8/64 | 512 | 512
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is 1024 and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is None and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is 1024 and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is None and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is 1024 and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is None and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is 1024 and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is None and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is 1024 and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is None and using 5 heads.
worker-0:5745:5832 [0] NCCL INFO 16 coll channels, 16 nvls channels, 16 p2p channels, 2 p2p channels per peer
worker-0:5745:5832 [0] NCCL INFO comm 0x55624bbca340 rank 8 nranks 16 cudaDev 0 nvmlDev 0 busId 8d000 commId 0xfd5d9e8febee040d - Init COMPLETE
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is 1024 and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is None and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is 1024 and using 5 heads.
DiffusionWrapper has 865.91 M params.
/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
worker-0:5741:5830 [2] NCCL INFO Connected all trees
worker-0:5741:5830 [2] NCCL INFO NVLS comm 0x55cc16ec5ad0 headRank 2 nHeads 8 buffSize 4194304 memSize 2097152 nvlsPerRankSize 201326592 nvlsTotalSize 1610612736
worker-0:5741:5830 [2] NCCL INFO Channel 00/0 : 2[2] -> 10[2] [receive] via NET/IBext/6/GDRDMA
worker-0:5741:5830 [2] NCCL INFO Channel 01/0 : 2[2] -> 10[2] [receive] via NET/IBext/6/GDRDMA
worker-0:5741:5830 [2] NCCL INFO Channel 03/0 : 2[2] -> 10[2] [receive] via NET/IBext/6/GDRDMA
worker-0:5741:5830 [2] NCCL INFO Channel 04/0 : 2[2] -> 10[2] [receive] via NET/IBext/6/GDRDMA
worker-0:5741:5830 [2] NCCL INFO Channel 05/0 : 2[2] -> 10[2] [receive] via NET/IBext/6/GDRDMA
worker-0:5741:5830 [2] NCCL INFO Channel 06/0 : 2[2] -> 10[2] [receive] via NET/IBext/6/GDRDMA
worker-0:5741:5830 [2] NCCL INFO Channel 07/0 : 2[2] -> 10[2] [receive] via NET/IBext/6/GDRDMA
worker-0:5741:5830 [2] NCCL INFO Channel 08/0 : 2[2] -> 10[2] [receive] via NET/IBext/6/GDRDMA
/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
INFO 16 coll channels, 16 nvls channels, 16 p2p channels, 2 p2p channels per peer
worker-1:5774:5863 [7] NCCL INFO comm 0x5592d3c98590 rank 7 nranks 16 cudaDev 7 nvmlDev 7 busId b7000 commId 0xfd5d9e8febee040d - Init COMPLETE
/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
worker-0:5741:5830 [2] NCCL INFO Channel 09/0 : 2[2] -> 10[2] [receive] via NET/IBext/6/GDRDMA
worker-0:5741:5830 [2] NCCL INFO Channel 11/0 : 2[2] -> 10[2] [receive] via NET/IBext/6/GDRDMA
worker-0:5741:5830 [2] NCCL INFO Channel 12/0 : 2[2] -> 10[2] [receive] via NET/IBext/6/GDRDMA
worker-0:5741:5830 [2] NCCL INFO Channel 13/0 : 2[2] -> 10[2] [receive] via NET/IBext/6/GDRDMA
worker-0:5741:5830 [2] NCCL INFO Channel 14/0 : 2[2] -> 10[2] [receive] via NET/IBext/6/GDRDMA
worker-0:5741:5830 [2] NCCL INFO Channel 15/0 : 2[2] -> 10[2] [receive] via NET/IBext/6/GDRDMA
worker-0:5741:5830 [2] NCCL INFO Channel 00/0 : 10[2] -> 2[2] [send] via NET/IBext/6/GDRDMA
worker-0:5741:5830 [2] NCCL INFO Channel 01/0 : 10[2] -> 2[2] [send] via NET/IBext/6/GDRDMA
worker-0:5741:5830 [2] NCCL INFO Channel 03/0 : 10[2] -> 2[2] [send] via NET/IBext/6/GDRDMA
worker-0:5741:5830 [2] NCCL INFO Channel 04/0 : 10[2] -> 2[2] [send] via NET/IBext/6/GDRDMA
worker-0:5741:5830 [2] NCCL INFO Channel 05/0 : 10[2] -> 2[2] [send] via NET/IBext/6/GDRDMA
worker-0:5741:5830 [2] NCCL INFO Channel 06/0 : 10[2] -> 2[2] [send] via NET/IBext/6/GDRDMA
worker-0:5741:5830 [2] NCCL INFO Channel 07/0 : 10[2] -> 2[2] [send] via NET/IBext/6/GDRDMA
worker-0:5741:5830 [2] NCCL INFO Channel 08/0 : 10[2] -> 2[2] [send] via NET/IBext/6/GDRDMA
worker-0:5741:5830 [2] NCCL INFO Channel 09/0 : 10[2] -> 2[2] [send] via NET/IBext/6/GDRDMA
worker-0:5741:5830 [2] NCCL INFO Channel 11/0 : 10[2] -> 2[2] [send] via NET/IBext/6/GDRDMA
worker-0:5741:5830 [2] NCCL INFO Channel 12/0 : 10[2] -> 2[2] [send] via NET/IBext/6/GDRDMA
worker-0:5741:5830 [2] NCCL INFO Channel 13/0 : 10[2] -> 2[2] [send] via NET/IBext/6/GDRDMA
worker-0:5741:5830 [2] NCCL INFO Channel 14/0 : 10[2] -> 2[2] [send] via NET/IBext/6/GDRDMA
worker-0:5741:5830 [2] NCCL INFO Channel 15/0 : 10[2] -> 2[2] [send] via NET/IBext/6/GDRDMA
worker-0:5741:5830 [2] NCCL INFO Connected NVLS tree
worker-0:5741:5830 [2] NCCL INFO threadThresholds 8/8/64 | 128/8/64 | 512 | 512
worker-0:5741:5830 [2] NCCL INFO 16 coll channels, 16 nvls channels, 16 p2p channels, 2 p2p channels per peer
worker-0:5741:5830 [2] NCCL INFO comm 0x55cc16ec5ad0 rank 10 nranks 16 cudaDev 2 nvmlDev 2 busId 95000 commId 0xfd5d9e8febee040d - Init COMPLETE
 : 0[0] -> 8[0] [send] via NET/IBext/4/GDRDMA
worker-1:5776:5864 [0] NCCL INFO Channel 02/0 : 0[0] -> 8[0] [send] via NET/IBext/4/GDRDMA
worker-1:5776:5864 [0] NCCL INFO Channel 03/0 : 0[0] -> 8[0] [send] via NET/IBext/4/GDRDMA
worker-1:5776:5864 [0] NCCL INFO Channel 04/0 : 0[0] -> 8[0] [send] via NET/IBext/4/GDRDMA
worker-1:5776:5864 [0] NCCL INFO Channel 05/0 : 0[0] -> 8[0] [send] via NET/IBext/4/GDRDMA
worker-1:5776:5864 [0] NCCL INFO Channel 06/0 : 0[0] -> 8[0] [send] via NET/IBext/4/GDRDMA
worker-1:5776:5864 [0] NCCL INFO Channel 07/0 : 0[0] -> 8[0] [send] via NET/IBext/4/GDRDMA
worker-1:5776:5864 [0] NCCL INFO Channel 09/0 : 0[0] -> 8[0] [send] via NET/IBext/4/GDRDMA
worker-1:5776:5864 [0] NCCL INFO Channel 10/0 : 0[0] -> 8[0] [send] via NET/IBext/4/GDRDMA
worker-1:5776:5864 [0] NCCL INFO Channel 11/0 : 0[0] -> 8[0] [send] via NET/IBext/4/GDRDMA
worker-1:5776:5864 [0] NCCL INFO Channel 12/0 : 0[0] -> 8[0] [send] via NET/IBext/4/GDRDMA
worker-0:5746:5833 [6] NCCL INFO Channel 11/0 : 14[6]Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is None and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is 1024 and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is None and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is 1024 and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is None and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is 1024 and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is None and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is 1024 and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is None and using 20 heads.
worker-1:5776:5864 [0] NCCL INFO Channel 13/0 : 0[0] -> 8[0] [send] via NET/IBext/4/GDRDMA
worker-1:5776:5864 [0] NCCL INFO Channel 14/0 : 0[0] -> 8[0] [send] via NET/IBext/4/GDRDMA
worker-1:5776:5864 [0] NCCL INFO Channel 15/0 : 0[0] -> 8[0] [send] via NET/IBext/4/GDRDMA
worker-1:5776:5864 [0] NCCL INFO Connected NVLS tree
worker-1:5776:5864 [0] NCCL INFO threadThresholds 8/8/64 | 128/8/64 | 512 | 512
worker-1:5776:5864 [0] NCCL INFO 16 coll channels, 16 nvls channels, 16 p2p channels, 2 p2p channels per peer
worker-1:5776:5864 [0] NCCL INFO comm 0x55bd13e90250 rank 0 nranks 16 cudaDev 0 nvmlDev 0 busId 8d000 commId 0xfd5d9e8febee040d - Init COMPLETE
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is 1024 and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is None and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is 1024 and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is None and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is 1024 and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is None and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is 1024 and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is None and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is 1024 and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is None and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is 1024 and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is None and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is 1024 and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is None and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is 1024 and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is None and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is 1024 and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is None and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is 1024 and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is None and using 5 heads.
worker-1:5788:5870 [1] NCCL INFO threadThresholds 8/8/64 | 128/8/64 | 512 | Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is None and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is 1024 and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is None and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is 1024 and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is None and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is 1024 and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is None and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is 1024 and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is None and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is 1024 and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is None and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is 1024 and using 5 heads.
DiffusionWrapper has 865.91 M params.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is 1024 and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is None and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is 1024 and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is None and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is 1024 and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is None and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is 1024 and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is None and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is 1024 and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is None and using 20 heads.
 -> 15[7] via P2P/CUMEM
worker-0:5746:5833 [6] NCCL INFO Channel 12/0 : 14[6] -> 15[7] via P2P/CUMEM
worker-0:5746:5833 [6] NCCL INFO Channel 13/0 : 14[6] -> 15[7] via P2P/CUMEM
worker-0:5746:5833 [6] NCCL INFO Channel 14/0 : 14[6] -> 15[7] via P2P/CUMEM
worker-0:5746:5833 [6] NCCL INFO Channel 06/0 : 6[6] -> 14[6] [receive] via NET/IBext/2/GDRDMA
worker-0:5746:5833 [6] NCCL INFO Channel 14/0 : 6[6] -> 14[6] [receive] via NET/IBext/2/GDRDMA
worker-0:5746:5833 [6] NCCL INFO Channel 06/0 : 14[6] -> 6[6] [send] via NET/IBext/2/GDRDMA
worker-0:5746:5833 [6] NCCL INFO Channel 14/0 : 14[6] -> 6[6] [send] via NET/IBext/2/GDRDMA
worker-0:5746:5833 [6] NCCL INFO Channel 05/0 : 14[6] -> 13[5] via P2P/CUMEM
worker-0:5746:5833 [6] NCCL INFO Channel 13/0 : 14[6] -> 13[5] via P2P/CUMEM
worker-0:5746:5833 [6] NCCL INFO Connected all trees
worker-0:5746:5833 [6] NCCL INFO NVLS comm 0x5560558af130 headRank 6 nHeads 8 buffSize 4194304 memSize 2097152 nvlsPerRankSize 201326592 nvlsTotalSize 1610612736
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is 1024 and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is None and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is 1024 and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is None and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is 1024 and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is None and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is 1024 and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is None and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is 1024 and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is None and using 5 heads.
worker-0:5746:5833 [6] NCCL INFO Channel 00/0 : 6[6] -> 14[6] [receive] via NET/IBext/2/GDRDMA
worker-0:5746:5833 [6] NCCL INFO Channel 01/0 : 6[6] -> 14[6] [receive] via NET/IBext/2/GDRDMA
worker-0:5746:5833 [6] NCCL INFO Channel 02/0 : 6[6] -> 14[6] [receive] via NET/IBext/2/GDRDMA
worker-0:5746:5833 [6] NCCL INFO Channel 03/0 : 6[6] -> 14[6] [receive] via NET/IBext/2/GDRDMA
worker-0:5746:5833 [6] NCCL INFO Channel 04/0 : 6[6] -> 14[6] [receive] via NET/IBext/2/GDRDMA
worker-0:5746:5833 [6] NCCL INFO Channel 05/0 : 6[6] -> 14[6] [receive] via NET/IBext/2/GDRDMA
worker-0:5746:5833 [6] NCCL INFO Channel 07/0 : 6[6] -> 14[6] [receive] via NET/IBext/2/GDRDMA
worker-0:5746:5833 [6] NCCL INFO Channel 08/0 : 6[6] -> 14[6] [receive] via NET/IBext/2/GDRDMA
worker-0:5746:5833 [6] NCCL INFO Channel 09/0 : 6[6] -> 14[6] [receive] via NET/IBext/2/GDRDMA
worker-0:5746:5833 [6] NCCL INFO Channel 10/0 : 6[6] -> 14[6] [receive] via NET/IBext/2/GDRDMA
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is 1024 and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is None and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is 1024 and using 5 heads.
DiffusionWrapper has 865.91 M params.
worker-0:5746:5833 [6] NCCL INFO Channel 11/0 : 6[6] -> 14[6] [receive] via NET/IBext/2/GDRDMA
worker-0:5746:5833 [6] NCCL INFO Channel 12/0 : 6[6] -> 14[6] [receive] via NET/IBext/2/GDRDMA
worker-0:5746:5833 [6] NCCL INFO Channel 13/0 : 6[6] -> 14[6] [receive] via NET/IBext/2/GDRDMA
worker-0:5746:5833 [6] NCCL INFO Channel 15/0 : 6[6] -> 14[6] [receive] via NET/IBext/2/GDRDMA
worker-0:5746:5833 [6] NCCL INFO Channel 00/0 : 14[6] -> 6[6] [send] via NET/IBext/2/GDRDMA
worker-0:5746:5833 [6] NCCL INFO Channel 01/0 : 14[6] -> 6[6] [send] via NET/IBext/2/GDRDMA
worker-0:5746:5833 [6] NCCL INFO Channel 02/0 : 14[6] -> 6[6] [send] via NET/IBext/2/GDRDMA
worker-0:5746:5833 [6] NCCL INFO Channel 03/0 : 14[6] -> 6[6] [send] via NET/IBext/2/GDRDMA
worker-0:5746:5833 [6] NCCL INFO Channel 04/0 : 14[6] -> 6[6] [send] via NET/IBext/2/GDRDMA
worker-0:5746:5833 [6] NCCL INFO Channel 05/0 : 14[6] -> 6[6] [send] via NET/IBext/2/GDRDMA
512
worker-1:5788:5870 [1] NCCL INFO 16 coll channels, 16 nvls channels, 16 p2p channels, 2 p2p channels per peer
worker-1:5788:5870 [1] NCCL INFO comm 0x56195ea363f0 rank 1 nranks 16 cudaDev 1 nvmlDev 1 busId 91000 commId 0xfd5d9e8febee040d - Init COMPLETE
worker-0:5746:5833 [6] NCCL INFO Channel 07/0 : 14[6] -> 6[6] [send] via NET/IBext/2/GDRDMA
worker-0:5746:5833 [6] NCCL INFO Channel 08/0 : 14[6] -> 6[6] [send] via NET/IBext/2/GDRDMA
worker-0:5746:5833 [6] NCCL INFO Channel 09/0 : 14[6] -> 6[6] [send] via NET/IBext/2/GDRDMA
worker-0:5746:5833 [6] NCCL INFO Channel 10/0 : 14[6] -> 6[6] [send] via NET/IBext/2/GDRDMA
worker-0:5746:5833 [6] NCCL INFO Channel 11/0 : 14[6] -> 6[6] [send] via NET/IBext/2/GDRDMA
worker-0:5746:5833 [6] NCCL INFO Channel 12/0 : 14[6] -> 6[6] [send] via NET/IBext/2/GDRDMA
worker-0:5746:5833 [6] NCCL INFO Channel 13/0 : 14[6] -> 6[6] [send] via NET/IBext/2/GDRDMA
worker-0:5746:5833 [6] NCCL INFO Channel 15/0 : 14[6] -> 6[6] [send] via NET/IBext/2/GDRDMA
worker-0:5746:5833 [6] NCCL INFO Connected NVLS tree
worker-0:5746:5833 [6] NCCL INFO threadThresholds 8/8/64 | 128/8/64 | 512 | 512
worker-0:5746:5833 [6] NCCL INFO 16 coll channels, 16 nvls channels, 16 p2p channels, 2 p2p channels per peer
worker-0:5746:5833 [6] NCCL INFO comm 0x5560558af130 rank 14 nranks 16 cudaDev 6 nvmlDev 6 busId b3000 commId 0xfd5d9e8febee040d - Init COMPLETE
worker-1:5789:5869 [6] NCCSetting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is None and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is 1024 and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is None and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is 1024 and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is None and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is 1024 and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is None and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is 1024 and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is None and using 20 heads.
worker-Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is None and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is 1024 and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is None and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is 1024 and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is None and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is 1024 and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is None and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is 1024 and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is None and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is 1024 and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is 1024 and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is None and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is 1024 and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is None and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is 1024 and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is None and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is 1024 and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is None and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is 1024 and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is None and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is None and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is 1024 and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is None and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is 1024 and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is None and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is 1024 and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is None and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is 1024 and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is None and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is 1024 and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is 1024 and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is None and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is 1024 and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is None and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is 1024 and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is None and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is 1024 and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is None and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is 1024 and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is None and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is None and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is 1024 and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is None and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is 1024 and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is None and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is 1024 and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is None and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is 1024 and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is None and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is 1024 and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is 1024 and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is None and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is 1024 and using 5 heads.
DiffusionWrapper has 865.91 M params.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is None and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is 1024 and using 5 heads.
DiffusionWrapper has 865.91 M params.
L INFO 16 coll channels, 16 nvls channels, 16 p2p channels, 2 p2p channels per peer
worker-1:5789:5869 [6] NCCL INFO comm 0x564f0897bdf0 rank 6 nranks 16 cudaDev 6 nvmlDev 6 busId b3000 commId 0xfd5d9e8febee040d - Init COMPLETE
0:5747:5829 [7] NCCL INFO Channel 07/0 : 15[7] -> 8[0] via P2P/CUMEM
worker-0:5747:5829 [7] NCCL INFO Channel 09/0 : 15[7] -> 8[0] via P2P/CUMEM
worker-0:5747:5829 [7] NCCL INFO Channel 10/0 : 15[7] -> 8[0] via P2P/CUMEM
worker-0:5747:5829 [7] NCCL INFO Channel 11/0 : 15[7] -> 8[0] via P2P/CUMEM
worker-0:5747:5829 [7] NCCL INFO Channel 12/0 : 15[7] -> 8[0] via P2P/CUMEM
worker-0:5747:5829 [7] NCCL INFO Channel 13/0 : 15[7] -> 8[0] via P2P/CUMEM
worker-0:5747:5829 [7] NCCL INFO Channel 14/0 : 15[7] -> 8[0] via P2P/CUMEM
worker-0:5747:5829 [7] NCCL INFO Channel 15/0 : 15[7] -> 8[0] via P2P/CUMEM
worker-0:5747:5829 [7] NCCL INFO Channel 06/0 : 15[7] -> 14[6] via P2P/CUMEM
worker-0:5747:5829 [7] NCCL INFO Channel 14/0 : 15[7] -> 14[6] via P2P/CUMEM
worker-0:5747:5829 [7] NCCL INFO Connected all trees
worker-0:5747:5829 [7] NCCL INFO NVLS comm 0x563e6e6cbbe0 headRank 7 nHeads 8 buffSize 4194304 memSize 2097152 nvlsPerRankSize 201326592 nvlsTotalSize 1610612736
worker-0:5747:5829 [7] NCCL INFO Channel 00/0 : 7[7] -> 15[7] [receive] via NET/IBext/3/GDRDMA
worker-0:5747:5829 [7] NCCL INFO Channel 01/0 : 7[7] -> 15[7] [receive] via NET/IBext/3/GDRDMA
worker-0:5747:5829 [7] NCCL INFO Channel 02/0 : 7[7] -> 15[7] [receive] via NET/IBext/3/GDRDMA
worker-0:5747:5829 [7] NCCL INFO Channel 03/0 : 7[7] -> 15[7] [receive] via NET/IBext/3/GDRDMA
worker-0:5747:5829 [7] NCCL INFO Channel 04/0 : 7[7] -> 15[7] [receive] via NET/IBext/3/GDRDMA
worker-0:5747:5829 [7] NCCL INFO Channel 05/0 : 7[7] -> 15[7] [receive] via NET/IBext/3/GDRDMA
worker-0:5747:5829 [7] NCCL INFO Channel 06/0 : 7[7] -> 15[7] [receive] via NET/IBext/3/GDRDMA
worker-0:5747:5829 [7] NCCL INFO Channel 08/0 : 7[7] -> 15[7] [receive] via NET/IBext/3/GDRDMA
worker-0:5747:5829 [7] NCCL INFO Channel 09/0 : 7[7] -> 15[7] [receive] via NET/IBext/3/GDRDMA
worker-0:5747:5829 [7] NCCL INFO Channel 10/0 : 7[7] -> 15[7] [receive] via NET/IBext/3/GDRDMA
worker-0:5747:5829 [7] NCCL INFO Channel 11/0 : 7[7] -> 15[7] [receive] via NET/IBext/3/GDRDMA
worker-0:5747:5829 [7] NCCL INFO Channel 12/0 : 7[7] -> 15[7] [receive] via NET/IBext/3/GDRDMA
worker-0:5747:5829 [7] NCCL INFO Channel 13/0 : 7[7] -> 15[7] [receive] via NET/IBext/3/GDRDMA
worker-0:5747:5829 [7] NCCL INFO Channel 14/0 : 7[7] -> 15[7] [receive] via NET/IBext/3/GDRDMA
worker-0:5747:5829 [7] NCCL INFO Channel 00/0 : 15[7] -> 7[7] [send] via NET/IBext/3/GDRDMA
worker-0:5747:5829 [7] NCCL INFO Channel 01/0 : 15[7] -> 7[7] [send] via NET/IBext/3/GDRDMA
worker-0:5747:5829 [7] NCCL INFO Channel 02/0 : 15[7] -> 7[7] [send] via NET/IBext/3/GDRDMA
worker-0:5747:5829 [7] NCCL INFO Channel 03/0 : 15[7] -> 7[7] [send] via NET/IBext/3/GDRDMA
worker-0:5747:5829 [7] NCCL INFO Channel 04/0 : 15[7] -> 7[7] [send] via NET/IBext/3/GDRDMA
worker-0:5747:5829 [7] NCCL INFO Channel 05/0 : 15[7] -> 7[7] [send] via NET/IBext/3/GDRDMA
worker-0:5747:5829 [7] NCCL INFO Channel 06/0 : 15[7] -> 7[7] [send] via NET/IBext/3/GDRDMA
worker-0:5747:5829 [7] NCCL INFO Channel 08/0 : 15[7] -> 7[7] [send] via NET/IBext/3/GDRDMA
worker-0:5747:5829 [7] NCCL INFO Channel 09/0 : 15[7] -> 7[7] [send] via NET/IBext/3/GDRDMA
worker-0:5747:5829 [7] NCCL INFO Channel 10/0 : 15[7] -> 7[7] [send] via NET/IBext/3/GDRDMA
worker-0:5747:5829 [7] NCCL INFO Channel 11/0 : 15[7] -> 7[7] [send] via NET/IBext/3/GDRDMA
worker-0:5747:5829 [7] NCCL INFO Channel 12/0 : 15[7] -> 7[7] [send] via NET/IBext/3/GDRDMA
worker-0:5747:5829 [7] NCCL INFO Channel 13/0 : 15[7] -> 7[7] [send] via NET/IBext/3/GDRDMA
worker-0:5747:5829 [7] NCCL INFO Channel 14/0 : 15[7] -> 7[7] [send] via NET/IBext/3/GDRDMA
worker-0:5747:5829 [7] NCCL INFO Connected NVLS tree
worker-0:5747:5829 [7] NCCL INFO threadThresholds 8/8/64 | 128/8/64 | 512 | 512
worker-0:5747:5829 [7] NCCL INFO 16 coll channels, 16 nvls channels, 16 p2p channels, 2 p2p channels per peer
worker-0:5747:5829 [7] NCCL INFO comm 0x563e6e6cbbe0 rank 15 nranks 16 cudaDev 7 nvmlDev 7 busId b7000 commId 0xfd5d9e8febee040d - Init COMPLETE
worker-0:5760:5824 [5] NCCL INFO Channel 11/0 : 13[5]Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is None and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is 1024 and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is None and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is 1024 and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is None and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is 1024 and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is None and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is 1024 and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is None and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is 1024 and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is None and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is 1024 and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is None and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is 1024 and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is None and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is 1024 and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is None and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is 1024 and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is None and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is 1024 and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is None and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is 1024 and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is None and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is 1024 and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is None and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is 1024 and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is None and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is 1024 and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is None and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is 1024 and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is None and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is 1024 and using 5 heads.
DiffusionWrapper has 865.91 M params.
 -> 14[6] via P2P/CUMEM
worker-0:5760:5824 [5] NCCL INFO Channel 12/0 : 13[5] -> 14[6] via P2P/CUMEM
worker-0:5760:5824 [5] NCCL INFO Channel 13/0 : 13[5] -> 14[6] via P2P/CUMEM
worker-0:5760:5824 [5] NCCL INFO Channel 15/0 : 13[5] -> 14[6] via P2P/CUMEM
worker-0:5760:5824 [5] NCCL INFO Channel 05/0 : 5[5] -> 13[5] [receive] via NET/IBext/1/GDRDMA
worker-0:5760:5824 [5] NCCL INFO Channel 13/0 : 5[5] -> 13[5] [receive] via NET/IBext/1/GDRDMA
worker-0:5760:5824 [5] NCCL INFO Channel 05/0 : 13[5] -> 5[5] [send] via NET/IBext/1/GDRDMA
worker-0:5760:5824 [5] NCCL INFO Channel 13/0 : 13[5] -> 5[5] [send] via NET/IBext/1/GDRDMA
worker-0:5760:5824 [5] NCCL INFO Channel 04/0 : 13[5] -> 12[4] via P2P/CUMEM
worker-0:5760:5824 [5] NCCL INFO Channel 12/0 : 13[5] -> 12[4] via P2P/CUMEM
worker-0:5760:5824 [5] NCCL INFO Connected all trees
worker-0:5760:5824 [5] NCCL INFO NVLS comm 0x5606545756f0 headRank 5 nHeads 8 buffSize 4194304 memSize 2097152 nvlsPerRankSize 201326592 nvlsTotalSize 1610612736
worker-0:5760:5824 [5] NCCL INFO Channel 00/0 : 5[5] -> 13[5] [receive] via NET/IBext/1/GDRDMA
worker-0:5760:5824 [5] NCCL INFO Channel 01/0 : 5[5] -> 13[5] [receive] via NET/IBext/1/GDRDMA
worker-0:5760:5824 [5] NCCL INFO Channel 02/0 : 5[5] -> 13[5] [receive] via NET/IBext/1/GDRDMA
worker-0:5760:5824 [5] NCCL INFO Channel 03/0 : 5[5] -> 13[5] [receive] via NET/IBext/1/GDRDMA
worker-0:5760:5824 [5] NCCL INFO Channel 04/0 : 5[5] -> 13[5] [receive] via NET/IBext/1/GDRDMA
worker-0:5760:5824 [5] NCCL INFO Channel 06/0 : 5[5] -> 13[5] [receive] via NET/IBext/1/GDRDMA
worker-0:5760:5824 [5] NCCL INFO Channel 07/0 : 5[5] -> 13[5] [receive] via NET/IBext/1/GDRDMA
worker-0:5760:5824 [5] NCCL INFO Channel 08/0 : 5[5] -> 13[5] [receive] via NET/IBext/1/GDRDMA
worker-0:5760:5824 [5] NCCL INFO Channel 09/0 : 5[5] -> 13[5] [receive] via NET/IBext/1/GDRDMA
worker-0:5760:5824 [5] NCCL INFO Channel 10/0 : 5[5] -> 13[5] [receive] via NET/IBext/1/GDRDMA
worker-0:5760:5824 [5] NCCL INFO Channel 11/0 : 5[5] -> 13[5] [receive] via NET/IBext/1/GDRDMA
worker-0:5760:5824 [5] NCCL INFO Channel 12/0 : 5[5] -> 13[5] [receive] via NET/IBext/1/GDRDMA
worker-0:5760:5824 [5] NCCL INFO Channel 14/0 : 5[5] -> 13[5] [receive] via NET/IBext/1/GDRDMA
worker-0:5760:5824 [5] NCCL INFO Channel 15/0 : 5[5] -> 13[5] [receive] via NET/IBext/1/GDRDMA
worker-0:5760:5824 [5] NCCL INFO Channel 00/0 : 13[5] -> 5[5] [send] via NET/IBext/1/GDRDMA
worker-0:5760:5824 [5] NCCL INFO Channel 01/0 : 13[5] -> 5[5] [send] via NET/IBext/1/GDRDMA
worker-0:5760:5824 [5] NCCL INFO Channel 02/0 : 13[5] -> 5[5] [send] via NET/IBext/1/GDRDMA
worker-0:5760:5824 [5] NCCL INFO Channel 03/0 : 13[5] -> 5[5] [send] via NET/IBext/1/GDRDMA
worker-0:5760:5824 [5] NCCL INFO Channel 04/0 : 13[5] -> 5[5] [send] via NET/IBext/1/GDRDMA
worker-0:5760:5824 [5] NCCL INFO Channel 06/0 : 13[5] -> 5[5] [send] via NET/IBext/1/GDRDMA
worker-0:5760:5824 [5] NCCL INFO Channel 07/0 : 13[5] -> 5[5] [send] via NET/IBext/1/GDRDMA
worker-0:5760:5824 [5] NCCL INFO Channel 08/0 : 13[5] -> 5[5] [send] via NET/IBext/1/GDRDMA
worker-0:5760:5824 [5] NCCL INFO Channel 09/0 : 13[5] -> 5[5] [send] via NET/IBext/1/GDRDMA
worker-0:5760:5824 [5] NCCL INFO Channel 10/0 : 13[5] -> 5[5] [send] via NET/IBext/1/GDRDMA
worker-0:5760:5824 [5] NCCL INFO Channel 11/0 : 13[5] -> 5[5] [send] via NET/IBext/1/GDRDMA
worker-0:5760:5824 [5] NCCL INFO Channel 12/0 : 13[5] -> 5[5] [send] via NET/IBext/1/GDRDMA
worker-0:5760:5824 [5] NCCL INFO Channel 14/0 : 13[5] -> 5[5] [send] via NET/IBext/1/GDRDMA
worker-0:5760:5824 [5] NCCL INFO Channel 15/0 : 13[5] -> 5[5] [send] via NET/IBext/1/GDRDMA
worker-0:5760:5824 [5] NCCL INFO Connected NVLS tree
worker-0:5760:5824 [5] NCCL INFO threadThresholds 8/8/64 | 128/8/64 | 512 | 512
worker-0:5760:5824 [5] NCCL INFO 16 coll channels, 16 nvls channels, 16 p2p channels, 2 p2p channels per peer
worker-0:5760:5824 [5] NCCL INFO comm 0x5606545756f0 rank 13 nranks 16 cudaDev 5 nvmlDev 5 busId af000 commId 0xfd5d9e8febee040d - Init COMPLETE
worker-0:5751:5834 [1] NCCL INFO Channel 12/0 : 9[1] -> 10[2] Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is None and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is 1024 and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is None and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is 1024 and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is None and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is 1024 and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is None and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is 1024 and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is None and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is 1024 and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is None and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is 1024 and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is None and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is 1024 and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is None and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is 1024 and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is None and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is 1024 and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is None and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is 1024 and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is None and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is 1024 and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is None and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is 1024 and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is None and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is 1024 and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is None and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is 1024 and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is None and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is 1024 and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is None and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is 1024 and using 5 heads.
DiffusionWrapper has 865.91 M params.
worker-0:5752:5835 [3] NCCL INFO Channel 10/0 : 11[3] -> 12[4] vSetting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is None and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is 1024 and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is None and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is 1024 and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is None and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is 1024 and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is None and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is 1024 and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is None and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is 1024 and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is None and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is 1024 and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is None and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is 1024 and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is None and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is 1024 and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is None and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is 1024 and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is None and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is 1024 and using 20 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is None and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is 1024 and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is None and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is 1024 and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is None and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is 1024 and using 10 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is None and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is 1024 and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is None and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is 1024 and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is None and using 5 heads.
Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is 1024 and using 5 heads.
DiffusionWrapper has 865.91 M params.
ia P2P/CUMEM
worker-0:5752:5835 [3] NCCL INFO Channel 11/0 : 11[3] -> 12[4] via P2P/CUMEM
worker-0:5752:5835 [3] NCCL INFO Channel 13/0 : 11[3] -> 12[4] via P2P/CUMEM
worker-0:5752:5835 [3] NCCL INFO Channel 14/0 : 11[3] -> 12[4] via P2P/CUMEM
worker-0:5752:5835 [3] NCCL INFO Channel 15/0 : 11[3] -> 12[4] via P2P/CUMEM
worker-0:5752:5835 [3] NCCL INFO Channel 03/0 : 3[3] -> 11[3] [receive] via NET/IBext/7/GDRDMA
worker-0:5752:5835 [3] NCCL INFO Channel 11/0 : 3[3] -> 11[3] [receive] via NET/IBext/7/GDRDMA
worker-0:5752:5835 [3] NCCL INFO Channel 03/0 : 11[3] -> 3[3] [send] via NET/IBext/7/GDRDMA
worker-0:5752:5835 [3] NCCL INFO Channel 11/0 : 11[3] -> 3[3] [send] via NET/IBext/7/GDRDMA
worker-0:5752:5835 [3] NCCL INFO Channel 02/0 : 11[3] -> 10[2] via P2P/CUMEM
via P2P/CUMEM
worker-0:5751:5834 [1] NCCL INFO Channel 13/0 : 9[1] -> 10[2] via P2P/CUMEM
worker-0:5751:5834 [1] NCCL INFO Channel 14/0 : 9[1] -> 10[2] via P2P/CUMEM
worker-0:5751:5834 [1] NCCL INFO Channel 15/0 : 9[1] -> 10[2] via P2P/CUMEM
worker-0:5751:5834 [1] NCCL INFO Channel 01/0 : 1[1] -> 9[1] [receive] via NET/IBext/5/GDRDMA
worker-0:5751:5834 [1] NCCL INFO Channel 09/0 : 1[1] -> 9[1] [receive] via NET/IBext/5/GDRDMA
worker-0:5751:5834 [1] NCCL INFO Channel 01/0 : 9[1] -> 1[1] [send] via NET/IBext/5/GDRDMA
worker-0:5751:5834 [1] NCCL INFO Channel 09/0 : 9[1] -> 1[1] [send] via NET/IBext/5/GDRDMA
worker-0:5751:5834 [1] NCCL INFO Channel 00/0 : 9[1] -> 8[0] via P2P/CUMEM
worker-0:5751:5834 [1] NCCL INFO Channel 08/0 : 9[1] -> 8[0] via P2P/CUMEM
worker-0:5751:5834 [1] NCCL INFO Connected all trees
worker-0:5751:5834 [1] NCCL INFO NVLS comm 0x559a6e72c030 headRank 1 nHeads 8 buffSize 4194304 memSize 2097152 nvlsPerRankSize 201326592 nvlsTotalSize 1610612736
worker-0:5751:5834 [1] NCCL INFO Channel 00/0 : 1[1] -> 9[1] [receive] via NET/IBext/5/GDRDMA
worker-0:5751:5834 [1] NCCL INFO Channel 02/0 : 1[1] -> 9[1] [receive] via NET/IBext/5/GDRDMA
worker-0:5751:5834 [1] NCCL INFO Channel 03/0 : 1[1] -> 9[1] [receive] via NET/IBext/5/GDRDMA
worker-0:5751:5834 [1] NCCL INFO Channel 04/0 : 1[1] -> 9[1] [receive] via NET/IBext/5/GDRDMA
worker-0:5751:5834 [1] NCCL INFO Channel 05/0 : 1[1] -> 9[1] [receive] via NET/IBext/5/GDRDMA
worker-0:5751:5834 [1] NCCL INFO Channel 06/0 : 1[1] -> 9[1] [receive] via NET/IBext/5/GDRDMA
worker-0:5751:5834 [1] NCCL INFO Channel 07/0 : 1[1] -> 9[1] [receive] via NET/IBext/5/GDRDMA
worker-0:5751:5834 [1] NCCL INFO Channel 08/0 : 1[1] -> 9[1] [receive] via NET/IBext/5/GDRDMA
worker-0:5751:5834 [1] NCCL INFO Channel 10/0 : 1[1] -> 9[1] [receive] via NET/IBext/5/GDRDMA
worker-0:5751:5834 [1] NCCL INFO Channel 11/0 : 1[1] -> 9[1] [receive] via NET/IBext/5/GDRDMA
worker-0:5751:5834 [1] NCCL INFO Channel 12/0 : 1[1] -> 9[1] [receive] via NET/IBext/5/GDRDMA
worker-0:5751:5834 [1] NCCL INFO Channel 13/0 : 1[1] -> 9[1] [receive] via NET/IBext/5/GDRDMA
worker-0:5751:5834 [1] NCCL INFO Channel 14/0 : 1[1] -> 9[1] [receive] via NET/IBext/5/GDRDMA
worker-0:5751:5834 [1] NCCL INFO Channel 15/0 : 1[1] -> 9[1] [receive] via NET/IBext/5/GDRDMA
worker-0:5751:5834 [1] NCCL INFO Channel 00/0 : 9[1] -> 1[1] [send] via NET/IBext/5/GDRDMA
worker-0:5751:5834 [1] NCCL INFO Channel 02/0 : 9[1] -> 1[1] [send] via NET/IBext/5/GDRDMA
worker-0:5751:5834 [1] NCCL INFO Channel 03/0 : 9[1] -> 1[1] [send] via NET/IBext/5/GDRDMA
worker-0:5751:5834 [1] NCCL INFO Channel 04/0 : 9[1] -> 1[1] [send] via NET/IBext/5/GDRDMA
worker-0:5751:5834 [1] NCCL INFO Channel 05/0 : 9[1] -> 1[1] [send] via NET/IBext/5/GDRDMA
worker-0:5751:5834 [1] NCCL INFO Channel 06/0 : 9[1] -> 1[1] [send] via NET/IBext/5/GDRDMA
worker-0:5751:5834 [1] NCCL INFO Channel 07/0 : 9[1] -> 1[1] [send] via NET/IBext/5/GDRDMA
worker-0:5751:5834 [1] NCCL INFO Channel 08/0 : 9[1] -> 1[1] [send] via NET/IBext/5/GDRDMA
worker-0:5751:5834 [1] NCCL INFO Channel 10/0 : 9[1] -> 1[1] [send] via NET/IBext/5/GDRDMA
worker-0:5751:5834 [1] NCCL INFO Channel 11/0 : 9[1] -> 1[1] [send] via NET/IBext/5/GDRDMA
worker-0:5751:5834 [1] NCCL INFO Channel 12/0 : 9[1] -> 1[1] [send] via NET/IBext/5/GDRDMA
worker-0:5751:5834 [1] NCCL INFO Channel 13/0 : 9[1] -> 1[1] [send] via NET/IBext/5/GDRDMA
worker-0:5751:5834 [1] NCCL INFO Channel 14/0 : 9[1] -> 1[1] [send] via NET/IBext/5/GDRDMA
worker-0:5751:5834 [1] NCCL INFO Channel 15/0 : 9[1] -> 1[1] [send] via NET/IBext/5/GDRDMA
worker-0:5751:5834 [1] NCCL INFO Connected NVLS tree
worker-0:5751:5834 [1] NCCL INFO threadThresholds 8/8/64 | 128/8/64 | 512 | 512
worker-0:5751:5834 [1] NCCL INFO 16 coll channels, 16 nvls channels, 16 p2p channels, 2 p2p channels per peer
worker-0:5751:5834 [1] NCCL INFO comm 0x559a6e72c030 rank 9 nranks 16 cudaDev 1 nvmlDev 1 busId 91000 commId 0xfd5d9e8febee040d - Init COMPLETE
worker-0:5752:5835 [3] NCCL INFO Channel 10/0 : 11[3] -> 10[2] via P2P/CUMEM
worker-0:5752:5835 [3] NCCL INFO Connected all trees
worker-0:5752:5835 [3] NCCL INFO NVLS comm 0x55af9c131630 headRank 3 nHeads 8 buffSize 4194304 memSize 2097152 nvlsPerRankSize 201326592 nvlsTotalSize 1610612736
worker-0:5752:5835 [3] NCCL INFO Channel 00/0 : 3[3] -> 11[3] [receive] via NET/IBext/7/GDRDMA
worker-0:5752:5835 [3] NCCL INFO Channel 01/0 : 3[3] -> 11[3] [receive] via NET/IBext/7/GDRDMA
worker-0:5752:5835 [3] NCCL INFO Channel 02/0 : 3[3] -> 11[3] [receive] via NET/IBext/7/GDRDMA
worker-0:5752:5835 [3] NCCL INFO Channel 04/0 : 3[3] -> 11[3] [receive] via NET/IBext/7/GDRDMA
worker-0:5752:5835 [3] NCCL INFO Channel 05/0 : 3[3] -> 11[3] [receive] via NET/IBext/7/GDRDMA
worker-0:5752:5835 [3] NCCL INFO Channel 06/0 : 3[3] -> 11[3] [receive] via NET/IBext/7/GDRDMA
worker-0:5752:5835 [3] NCCL INFO Channel 07/0 : 3[3] -> 11[3] [receive] via NET/IBext/7/GDRDMA
worker-0:5752:5835 [3] NCCL INFO Channel 08/0 : 3[3] -> 11[3] [receive] via NET/IBext/7/GDRDMA
worker-0:5752:5835 [3] NCCL INFO Channel 09/0 : 3[3] -> 11[3] [receive] via NET/IBext/7/GDRDMA
worker-0:5752:5835 [3] NCCL INFO Channel 10/0 : 3[3] -> 11[3] [receive] via NET/IBext/7/GDRDMA
worker-0:5752:5835 [3] NCCL INFO Channel 12/0 : 3[3] -> 11[3] [receive] via NET/IBext/7/GDRDMA
worker-0:5752:5835 [3] NCCL INFO Channel 13/0 : 3[3] -> 11[3] [receive] via NET/IBext/7/GDRDMA
worker-0:5752:5835 [3] NCCL INFO Channel 14/0 : 3[3] -> 11[3] [receive] via NET/IBext/7/GDRDMA
worker-0:5752:5835 [3] NCCL INFO Channel 15/0 : 3[3] -> 11[3] [receive] via NET/IBext/7/GDRDMA
worker-0:5752:5835 [3] NCCL INFO Channel 00/0 : 11[3] -> 3[3] [send] via NET/IBext/7/GDRDMA
worker-0:5752:5835 [3] NCCL INFO Channel 01/0 : 11[3] -> 3[3] [send] via NET/IBext/7/GDRDMA
worker-0:5752:5835 [3] NCCL INFO Channel 02/0 : 11[3] -> 3[3] [send] via NET/IBext/7/GDRDMA
worker-0:5752:5835 [3] NCCL INFO Channel 04/0 : 11[3] -> 3[3] [send] via NET/IBext/7/GDRDMA
worker-0:5752:5835 [3] NCCL INFO Channel 05/0 : 11[3] -> 3[3] [send] via NET/IBext/7/GDRDMA
worker-0:5752:5835 [3] NCCL INFO Channel 06/0 : 11[3] -> 3[3] [send] via NET/IBext/7/GDRDMA
worker-0:5752:5835 [3] NCCL INFO Channel 07/0 : 11[3] -> 3[3] [send] via NET/IBext/7/GDRDMA
worker-0:5752:5835 [3] NCCL INFO Channel 08/0 : 11[3] -> 3[3] [send] via NET/IBext/7/GDRDMA
worker-0:5752:5835 [3] NCCL INFO Channel 09/0 : 11[3] -> 3[3] [send] via NET/IBext/7/GDRDMA
worker-0:5752:5835 [3] NCCL INFO Channel 10/0 : 11[3] -> 3[3] [send] via NET/IBext/7/GDRDMA
worker-0:5752:5835 [3] NCCL INFO Channel 12/0 : 11[3] -> 3[3] [send] via NET/IBext/7/GDRDMA
worker-0:5752:5835 [3] NCCL INFO Channel 13/0 : 11[3] -> 3[3] [send] via NET/IBext/7/GDRDMA
worker-0:5752:5835 [3] NCCL INFO Channel 14/0 : 11[3] -> 3[3] [send] via NET/IBext/7/GDRDMA
worker-0:5752:5835 [3] NCCL INFO Channel 15/0 : 11[3] -> 3[3] [send] via NET/IBext/7/GDRDMA
worker-0:5752:5835 [3] NCCL INFO Connected NVLS tree
worker-0:5752:5835 [3] NCCL INFO threadThresholds 8/8/64 | 128/8/64 | 512 | 512
worker-0:5752:5835 [3] NCCL INFO 16 coll channels, 16 nvls channels, 16 p2p channels, 2 p2p channels per peer
worker-0:5752:5835 [3] NCCL INFO comm 0x55af9c131630 rank 11 nranks 16 cudaDev 3 nvmlDev 3 busId 99000 commId 0xfd5d9e8febee040d - Init COMPLETE
:::MLLOG {"namespace": "", "time_ms": 1718487895148, "event_type": "INTERVAL_START", "key": "block_start", "value": "training_step", "metadata": {"file": "mlperf_logging_utils.py", "lineno": 108, "step_num": 0}}
/usr/local/lib/python3.10/dist-packages/lightning/pytorch/utilities/data.py:84: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 8. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
/usr/local/lib/python3.10/dist-packages/lightning/pytorch/trainer/connectors/logger_connector/result.py:232: UserWarning: You called `self.log('global_step', ...)` in your `training_step` but the value needs to be floating point. Converting it to torch.float32.
  warning_cache.warn(
:::MLLOG {"namespace": "", "time_ms": 1718488049754, "event_type": "POINT_IN_TIME", "key": "loss", "value": 0.9320611953735352, "metadata": {"file": "mlperf_logging_utils.py", "lineno": 114, "step_num": 100}}
:::MLLOG {"namespace": "", "time_ms": 1718488049759, "event_type": "POINT_IN_TIME", "key": "lr_abs", "value": 1.5840144159999998e-06, "metadata": {"file": "mlperf_logging_utils.py", "lineno": 115, "step_num": 100}}
:::MLLOG {"namespace": "", "time_ms": 1718488049760, "event_type": "INTERVAL_END", "key": "block_stop", "value": "training_step", "metadata": {"file": "mlperf_logging_utils.py", "lineno": 116, "step_num": 100}}
:::MLLOG {"namespace": "", "time_ms": 1718488049797, "event_type": "INTERVAL_START", "key": "block_start", "value": "training_step", "metadata": {"file": "mlperf_logging_utils.py", "lineno": 108, "step_num": 100}}
:::MLLOG {"namespace": "", "time_ms": 1718488197966, "event_type": "POINT_IN_TIME", "key": "loss", "value": 0.7779831886291504, "metadata": {"file": "mlperf_logging_utils.py", "lineno": 114, "step_num": 200}}
:::MLLOG {"namespace": "", "time_ms": 1718488197971, "event_type": "POINT_IN_TIME", "key": "lr_abs", "value": 3.1840128159999994e-06, "metadata": {"file": "mlperf_logging_utils.py", "lineno": 115, "step_num": 200}}
:::MLLOG {"namespace": "", "time_ms": 1718488197973, "event_type": "INTERVAL_END", "key": "block_stop", "value": "training_step", "metadata": {"file": "mlperf_logging_utils.py", "lineno": 116, "step_num": 200}}
:::MLLOG {"namespace": "", "time_ms": 1718488198007, "event_type": "INTERVAL_START", "key": "block_start", "value": "training_step", "metadata": {"file": "mlperf_logging_utils.py", "lineno": 108, "step_num": 200}}
:::MLLOG {"namespace": "", "time_ms": 1718488346358, "event_type": "POINT_IN_TIME", "key": "loss", "value": 0.5977096557617188, "metadata": {"file": "mlperf_logging_utils.py", "lineno": 114, "step_num": 300}}
:::MLLOG {"namespace": "", "time_ms": 1718488346365, "event_type": "POINT_IN_TIME", "key": "lr_abs", "value": 4.784011215999999e-06, "metadata": {"file": "mlperf_logging_utils.py", "lineno": 115, "step_num": 300}}
:::MLLOG {"namespace": "", "time_ms": 1718488346366, "event_type": "INTERVAL_END", "key": "block_stop", "value": "training_step", "metadata": {"file": "mlperf_logging_utils.py", "lineno": 116, "step_num": 300}}
:::MLLOG {"namespace": "", "time_ms": 1718488346402, "event_type": "INTERVAL_START", "key": "block_start", "value": "training_step", "metadata": {"file": "mlperf_logging_utils.py", "lineno": 108, "step_num": 300}}
:::MLLOG {"namespace": "", "time_ms": 1718488494401, "event_type": "POINT_IN_TIME", "key": "loss", "value": 0.639862060546875, "metadata": {"file": "mlperf_logging_utils.py", "lineno": 114, "step_num": 400}}
:::MLLOG {"namespace": "", "time_ms": 1718488494407, "event_type": "POINT_IN_TIME", "key": "lr_abs", "value": 6.384009615999999e-06, "metadata": {"file": "mlperf_logging_utils.py", "lineno": 115, "step_num": 400}}
:::MLLOG {"namespace": "", "time_ms": 1718488494409, "event_type": "INTERVAL_END", "key": "block_stop", "value": "training_step", "metadata": {"file": "mlperf_logging_utils.py", "lineno": 116, "step_num": 400}}
:::MLLOG {"namespace": "", "time_ms": 1718488494455, "event_type": "INTERVAL_START", "key": "block_start", "value": "training_step", "metadata": {"file": "mlperf_logging_utils.py", "lineno": 108, "step_num": 400}}
:::MLLOG {"namespace": "", "time_ms": 1718488612309, "event_type": "POINT_IN_TIME", "key": "loss", "value": 0.6092671155929565, "metadata": {"file": "mlperf_logging_utils.py", "lineno": 114, "step_num": 500}}
:::MLLOG {"namespace": "", "time_ms": 1718488612620, "event_type": "POINT_IN_TIME", "key": "lr_abs", "value": 7.984008015999999e-06, "metadata": {"file": "mlperf_logging_utils.py", "lineno": 115, "step_num": 500}}
:::MLLOG {"namespace": "", "time_ms": 1718488612837, "event_type": "INTERVAL_END", "key": "block_stop", "value": "training_step", "metadata": {"file": "mlperf_logging_utils.py", "lineno": 116, "step_num": 500}}
:::MLLOG {"namespace": "", "time_ms": 1718488612872, "event_type": "INTERVAL_START", "key": "block_start", "value": "training_step", "metadata": {"file": "mlperf_logging_utils.py", "lineno": 108, "step_num": 500}}
:::MLLOG {"namespace": "", "time_ms": 1718488717228, "event_type": "POINT_IN_TIME", "key": "loss", "value": 0.5568075180053711, "metadata": {"file": "mlperf_logging_utils.py", "lineno": 114, "step_num": 600}}
:::MLLOG {"namespace": "", "time_ms": 1718488717251, "event_type": "POINT_IN_TIME", "key": "lr_abs", "value": 9.584006416e-06, "metadata": {"file": "mlperf_logging_utils.py", "lineno": 115, "step_num": 600}}
:::MLLOG {"namespace": "", "time_ms": 1718488717253, "event_type": "INTERVAL_END", "key": "block_stop", "value": "training_step", "metadata": {"file": "mlperf_logging_utils.py", "lineno": 116, "step_num": 600}}
:::MLLOG {"namespace": "", "time_ms": 1718488717358, "event_type": "INTERVAL_START", "key": "block_start", "value": "training_step", "metadata": {"file": "mlperf_logging_utils.py", "lineno": 108, "step_num": 600}}
:::MLLOG {"namespace": "", "time_ms": 1718488820004, "event_type": "POINT_IN_TIME", "key": "loss", "value": 0.614466667175293, "metadata": {"file": "mlperf_logging_utils.py", "lineno": 114, "step_num": 700}}
:::MLLOG {"namespace": "", "time_ms": 1718488820022, "event_type": "POINT_IN_TIME", "key": "lr_abs", "value": 1.1184004815999999e-05, "metadata": {"file": "mlperf_logging_utils.py", "lineno": 115, "step_num": 700}}
:::MLLOG {"namespace": "", "time_ms": 1718488820024, "event_type": "INTERVAL_END", "key": "block_stop", "value": "training_step", "metadata": {"file": "mlperf_logging_utils.py", "lineno": 116, "step_num": 700}}
:::MLLOG {"namespace": "", "time_ms": 1718488820062, "event_type": "INTERVAL_START", "key": "block_start", "value": "training_step", "metadata": {"file": "mlperf_logging_utils.py", "lineno": 108, "step_num": 700}}
:::MLLOG {"namespace": "", "time_ms": 1718488924461, "event_type": "POINT_IN_TIME", "key": "loss", "value": 0.4875093996524811, "metadata": {"file": "mlperf_logging_utils.py", "lineno": 114, "step_num": 800}}
:::MLLOG {"namespace": "", "time_ms": 1718488924466, "event_type": "POINT_IN_TIME", "key": "lr_abs", "value": 1.2784003215999998e-05, "metadata": {"file": "mlperf_logging_utils.py", "lineno": 115, "step_num": 800}}
:::MLLOG {"namespace": "", "time_ms": 1718488924467, "event_type": "INTERVAL_END", "key": "block_stop", "value": "training_step", "metadata": {"file": "mlperf_logging_utils.py", "lineno": 116, "step_num": 800}}
:::MLLOG {"namespace": "", "time_ms": 1718488924519, "event_type": "INTERVAL_START", "key": "block_start", "value": "training_step", "metadata": {"file": "mlperf_logging_utils.py", "lineno": 108, "step_num": 800}}
:::MLLOG {"namespace": "", "time_ms": 1718489032781, "event_type": "POINT_IN_TIME", "key": "loss", "value": 0.45187750458717346, "metadata": {"file": "mlperf_logging_utils.py", "lineno": 114, "step_num": 900}}
:::MLLOG {"namespace": "", "time_ms": 1718489032786, "event_type": "POINT_IN_TIME", "key": "lr_abs", "value": 1.4384001615999999e-05, "metadata": {"file": "mlperf_logging_utils.py", "lineno": 115, "step_num": 900}}
:::MLLOG {"namespace": "", "time_ms": 1718489032787, "event_type": "INTERVAL_END", "key": "block_stop", "value": "training_step", "metadata": {"file": "mlperf_logging_utils.py", "lineno": 116, "step_num": 900}}
:::MLLOG {"namespace": "", "time_ms": 1718489032829, "event_type": "INTERVAL_START", "key": "block_start", "value": "training_step", "metadata": {"file": "mlperf_logging_utils.py", "lineno": 108, "step_num": 900}}
:::MLLOG {"namespace": "", "time_ms": 1718489137454, "event_type": "POINT_IN_TIME", "key": "loss", "value": 0.40687620639801025, "metadata": {"file": "mlperf_logging_utils.py", "lineno": 114, "step_num": 1000}}
:::MLLOG {"namespace": "", "time_ms": 1718489137465, "event_type": "POINT_IN_TIME", "key": "lr_abs", "value": 1.5984000016e-05, "metadata": {"file": "mlperf_logging_utils.py", "lineno": 115, "step_num": 1000}}
:::MLLOG {"namespace": "", "time_ms": 1718489137466, "event_type": "INTERVAL_END", "key": "block_stop", "value": "training_step", "metadata": {"file": "mlperf_logging_utils.py", "lineno": 116, "step_num": 1000}}
:::MLLOG {"namespace": "", "time_ms": 1718489321637, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1000, "metadata": {"file": "mlperf_logging_utils.py", "lineno": 119}}
:::MLLOG {"namespace": "", "time_ms": 1718489322588, "event_type": "INTERVAL_START", "key": "block_start", "value": "validation_step", "metadata": {"file": "mlperf_logging_utils.py", "lineno": 142, "step_num": 0}}
:::MLLOG {"namespace": "", "time_ms": 1718489388549, "event_type": "INTERVAL_END", "key": "block_stop", "value": "validation_step", "metadata": {"file": "mlperf_logging_utils.py", "lineno": 147, "step_num": 0}}
:::MLLOG {"namespace": "", "time_ms": 1718489424648, "event_type": "INTERVAL_START", "key": "block_start", "value": "validation_step", "metadata": {"file": "mlperf_logging_utils.py", "lineno": 142, "step_num": 10}}
:::MLLOG {"namespace": "", "time_ms": 1718489428649, "event_type": "INTERVAL_END", "key": "block_stop", "value": "validation_step", "metadata": {"file": "mlperf_logging_utils.py", "lineno": 147, "step_num": 10}}
:::MLLOG {"namespace": "", "time_ms": 1718489464689, "event_type": "INTERVAL_START", "key": "block_start", "value": "validation_step", "metadata": {"file": "mlperf_logging_utils.py", "lineno": 142, "step_num": 20}}
:::MLLOG {"namespace": "", "time_ms": 1718489468679, "event_type": "INTERVAL_END", "key": "block_stop", "value": "validation_step", "metadata": {"file": "mlperf_logging_utils.py", "lineno": 147, "step_num": 20}}
:::MLLOG {"namespace": "", "time_ms": 1718489504753, "event_type": "INTERVAL_START", "key": "block_start", "value": "validation_step", "metadata": {"file": "mlperf_logging_utils.py", "lineno": 142, "step_num": 30}}
:::MLLOG {"namespace": "", "time_ms": 1718489508755, "event_type": "INTERVAL_END", "key": "block_stop", "value": "validation_step", "metadata": {"file": "mlperf_logging_utils.py", "lineno": 147, "step_num": 30}}
:::MLLOG {"namespace": "", "time_ms": 1718489544872, "event_type": "INTERVAL_START", "key": "block_start", "value": "validation_step", "metadata": {"file": "mlperf_logging_utils.py", "lineno": 142, "step_num": 40}}
:::MLLOG {"namespace": "", "time_ms": 1718489548878, "event_type": "INTERVAL_END", "key": "block_stop", "value": "validation_step", "metadata": {"file": "mlperf_logging_utils.py", "lineno": 147, "step_num": 40}}
:::MLLOG {"namespace": "", "time_ms": 1718489584968, "event_type": "INTERVAL_START", "key": "block_start", "value": "validation_step", "metadata": {"file": "mlperf_logging_utils.py", "lineno": 142, "step_num": 50}}
:::MLLOG {"namespace": "", "time_ms": 1718489588962, "event_type": "INTERVAL_END", "key": "block_stop", "value": "validation_step", "metadata": {"file": "mlperf_logging_utils.py", "lineno": 147, "step_num": 50}}
:::MLLOG {"namespace": "", "time_ms": 1718489625056, "event_type": "INTERVAL_START", "key": "block_start", "value": "validation_step", "metadata": {"file": "mlperf_logging_utils.py", "lineno": 142, "step_num": 60}}
:::MLLOG {"namespace": "", "time_ms": 1718489629063, "event_type": "INTERVAL_END", "key": "block_stop", "value": "validation_step", "metadata": {"file": "mlperf_logging_utils.py", "lineno": 147, "step_num": 60}}
:::MLLOG {"namespace": "", "time_ms": 1718489665167, "event_type": "INTERVAL_START", "key": "block_start", "value": "validation_step", "metadata": {"file": "mlperf_logging_utils.py", "lineno": 142, "step_num": 70}}
:::MLLOG {"namespace": "", "time_ms": 1718489669177, "event_type": "INTERVAL_END", "key": "block_stop", "value": "validation_step", "metadata": {"file": "mlperf_logging_utils.py", "lineno": 147, "step_num": 70}}
:::MLLOG {"namespace": "", "time_ms": 1718489705361, "event_type": "INTERVAL_START", "key": "block_start", "value": "validation_step", "metadata": {"file": "mlperf_logging_utils.py", "lineno": 142, "step_num": 80}}
:::MLLOG {"namespace": "", "time_ms": 1718489709364, "event_type": "INTERVAL_END", "key": "block_stop", "value": "validation_step", "metadata": {"file": "mlperf_logging_utils.py", "lineno": 147, "step_num": 80}}
:::MLLOG {"namespace": "", "time_ms": 1718489745598, "event_type": "INTERVAL_START", "key": "block_start", "value": "validation_step", "metadata": {"file": "mlperf_logging_utils.py", "lineno": 142, "step_num": 90}}
:::MLLOG {"namespace": "", "time_ms": 1718489749628, "event_type": "INTERVAL_END", "key": "block_stop", "value": "validation_step", "metadata": {"file": "mlperf_logging_utils.py", "lineno": 147, "step_num": 90}}
:::MLLOG {"namespace": "", "time_ms": 1718489785763, "event_type": "INTERVAL_START", "key": "block_start", "value": "validation_step", "metadata": {"file": "mlperf_logging_utils.py", "lineno": 142, "step_num": 100}}
:::MLLOG {"namespace": "", "time_ms": 1718489789815, "event_type": "INTERVAL_END", "key": "block_stop", "value": "validation_step", "metadata": {"file": "mlperf_logging_utils.py", "lineno": 147, "step_num": 100}}
:::MLLOG {"namespace": "", "time_ms": 1718489825990, "event_type": "INTERVAL_START", "key": "block_start", "value": "validation_step", "metadata": {"file": "mlperf_logging_utils.py", "lineno": 142, "step_num": 110}}
:::MLLOG {"namespace": "", "time_ms": 1718489830015, "event_type": "INTERVAL_END", "key": "block_stop", "value": "validation_step", "metadata": {"file": "mlperf_logging_utils.py", "lineno": 147, "step_num": 110}}
:::MLLOG {"namespace": "", "time_ms": 1718489866181, "event_type": "INTERVAL_START", "key": "block_start", "value": "validation_step", "metadata": {"file": "mlperf_logging_utils.py", "lineno": 142, "step_num": 120}}
:::MLLOG {"namespace": "", "time_ms": 1718489870187, "event_type": "INTERVAL_END", "key": "block_stop", "value": "validation_step", "metadata": {"file": "mlperf_logging_utils.py", "lineno": 147, "step_num": 120}}
:::MLLOG {"namespace": "", "time_ms": 1718489906348, "event_type": "INTERVAL_START", "key": "block_start", "value": "validation_step", "metadata": {"file": "mlperf_logging_utils.py", "lineno": 142, "step_num": 130}}
:::MLLOG {"namespace": "", "time_ms": 1718489910405, "event_type": "INTERVAL_END", "key": "block_stop", "value": "validation_step", "metadata": {"file": "mlperf_logging_utils.py", "lineno": 147, "step_num": 130}}
:::MLLOG {"namespace": "", "time_ms": 1718489946557, "event_type": "INTERVAL_START", "key": "block_start", "value": "validation_step", "metadata": {"file": "mlperf_logging_utils.py", "lineno": 142, "step_num": 140}}
:::MLLOG {"namespace": "", "time_ms": 1718489950568, "event_type": "INTERVAL_END", "key": "block_stop", "value": "validation_step", "metadata": {"file": "mlperf_logging_utils.py", "lineno": 147, "step_num": 140}}
:::MLLOG {"namespace": "", "time_ms": 1718489986786, "event_type": "INTERVAL_START", "key": "block_start", "value": "validation_step", "metadata": {"file": "mlperf_logging_utils.py", "lineno": 142, "step_num": 150}}
:::MLLOG {"namespace": "", "time_ms": 1718489990807, "event_type": "INTERVAL_END", "key": "block_stop", "value": "validation_step", "metadata": {"file": "mlperf_logging_utils.py", "lineno": 147, "step_num": 150}}
:::MLLOG {"namespace": "", "time_ms": 1718490026981, "event_type": "INTERVAL_START", "key": "block_start", "value": "validation_step", "metadata": {"file": "mlperf_logging_utils.py", "lineno": 142, "step_num": 160}}
:::MLLOG {"namespace": "", "time_ms": 1718490031015, "event_type": "INTERVAL_END", "key": "block_stop", "value": "validation_step", "metadata": {"file": "mlperf_logging_utils.py", "lineno": 147, "step_num": 160}}
:::MLLOG {"namespace": "", "time_ms": 1718490067184, "event_type": "INTERVAL_START", "key": "block_start", "value": "validation_step", "metadata": {"file": "mlperf_logging_utils.py", "lineno": 142, "step_num": 170}}
:::MLLOG {"namespace": "", "time_ms": 1718490071196, "event_type": "INTERVAL_END", "key": "block_stop", "value": "validation_step", "metadata": {"file": "mlperf_logging_utils.py", "lineno": 147, "step_num": 170}}
:::MLLOG {"namespace": "", "time_ms": 1718490107360, "event_type": "INTERVAL_START", "key": "block_start", "value": "validation_step", "metadata": {"file": "mlperf_logging_utils.py", "lineno": 142, "step_num": 180}}
:::MLLOG {"namespace": "", "time_ms": 1718490111386, "event_type": "INTERVAL_END", "key": "block_stop", "value": "validation_step", "metadata": {"file": "mlperf_logging_utils.py", "lineno": 147, "step_num": 180}}
:::MLLOG {"namespace": "", "time_ms": 1718490147568, "event_type": "INTERVAL_START", "key": "block_start", "value": "validation_step", "metadata": {"file": "mlperf_logging_utils.py", "lineno": 142, "step_num": 190}}
:::MLLOG {"namespace": "", "time_ms": 1718490151589, "event_type": "INTERVAL_END", "key": "block_stop", "value": "validation_step", "metadata": {"file": "mlperf_logging_utils.py", "lineno": 147, "step_num": 190}}
:::MLLOG {"namespace": "", "time_ms": 1718490187880, "event_type": "INTERVAL_START", "key": "block_start", "value": "validation_step", "metadata": {"file": "mlperf_logging_utils.py", "lineno": 142, "step_num": 200}}
:::MLLOG {"namespace": "", "time_ms": 1718490191891, "event_type": "INTERVAL_END", "key": "block_stop", "value": "validation_step", "metadata": {"file": "mlperf_logging_utils.py", "lineno": 147, "step_num": 200}}
:::MLLOG {"namespace": "", "time_ms": 1718490228128, "event_type": "INTERVAL_START", "key": "block_start", "value": "validation_step", "metadata": {"file": "mlperf_logging_utils.py", "lineno": 142, "step_num": 210}}
:::MLLOG {"namespace": "", "time_ms": 1718490232202, "event_type": "INTERVAL_END", "key": "block_stop", "value": "validation_step", "metadata": {"file": "mlperf_logging_utils.py", "lineno": 147, "step_num": 210}}
:::MLLOG {"namespace": "", "time_ms": 1718490268342, "event_type": "INTERVAL_START", "key": "block_start", "value": "validation_step", "metadata": {"file": "mlperf_logging_utils.py", "lineno": 142, "step_num": 220}}
:::MLLOG {"namespace": "", "time_ms": 1718490272365, "event_type": "INTERVAL_END", "key": "block_stop", "value": "validation_step", "metadata": {"file": "mlperf_logging_utils.py", "lineno": 147, "step_num": 220}}
Traceback (most recent call last):
  File "/usr/local/lib/python3.10/dist-packages/lightning/pytorch/trainer/call.py", line 38, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/lightning/pytorch/trainer/trainer.py", line 650, in _fit_impl
    self._run(model, ckpt_path=self.ckpt_path)
  File "/usr/local/lib/python3.10/dist-packages/lightning/pytorch/trainer/trainer.py", line 1112, in _run
    results = self._run_stage()
  File "/usr/local/lib/python3.10/dist-packages/lightning/pytorch/trainer/trainer.py", line 1191, in _run_stage
    self._run_train()
  File "/usr/local/lib/python3.10/dist-packages/lightning/pytorch/trainer/trainer.py", line 1214, in _run_train
    self.fit_loop.run()
  File "/usr/local/lib/python3.10/dist-packages/lightning/pytorch/loops/loop.py", line 199, in run
    self.advance(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/lightning/pytorch/loops/fit_loop.py", line 267, in advance
    self._outputs = self.epoch_loop.run(self._data_fetcher)
  File "/usr/local/lib/python3.10/dist-packages/lightning/pytorch/loops/loop.py", line 200, in run
    self.on_advance_end()
  File "/usr/local/lib/python3.10/dist-packages/lightning/pytorch/loops/epoch/training_epoch_loop.py", line 250, in on_advance_end
    self._run_validation()
  File "/usr/local/lib/python3.10/dist-packages/lightning/pytorch/loops/epoch/training_epoch_loop.py", line 308, in _run_validation
    self.val_loop.run()
  File "/usr/local/lib/python3.10/dist-packages/lightning/pytorch/loops/loop.py", line 199, in run
    self.advance(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/lightning/pytorch/loops/dataloader/evaluation_loop.py", line 152, in advance
    dl_outputs = self.epoch_loop.run(self._data_fetcher, dl_max_batches, kwargs)
  File "/usr/local/lib/python3.10/dist-packages/lightning/pytorch/loops/loop.py", line 199, in run
    self.advance(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/lightning/pytorch/loops/epoch/evaluation_epoch_loop.py", line 137, in advance
    output = self._evaluation_step(**kwargs)
  File "/usr/local/lib/python3.10/dist-packages/lightning/pytorch/loops/epoch/evaluation_epoch_loop.py", line 234, in _evaluation_step
    output = self.trainer._call_strategy_hook(hook_name, *kwargs.values())
  File "/usr/local/lib/python3.10/dist-packages/lightning/pytorch/trainer/trainer.py", line 1494, in _call_strategy_hook
    output = fn(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/lightning/pytorch/strategies/ddp.py", line 359, in validation_step
    return self.model(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1510, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1519, in _call_impl
    return forward_call(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/distributed.py", line 1509, in forward
    else self._run_ddp_forward(*inputs, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/distributed.py", line 1345, in _run_ddp_forward
    return self.module(*inputs, **kwargs)  # type: ignore[index]
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1510, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1519, in _call_impl
    return forward_call(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/lightning/pytorch/overrides/base.py", line 110, in forward
    return self._forward_module.validation_step(*inputs, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
  File "/workdir/ldm/models/diffusion/ddpm.py", line 585, in validation_step
    samples, _ = self.sampler.sample(S=self.validation_sampler_steps,
  File "/usr/local/lib/python3.10/dist-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
  File "/workdir/ldm/models/diffusion/ddim.py", line 104, in sample
    samples, intermediates = self.ddim_sampling(conditioning, size,
  File "/usr/local/lib/python3.10/dist-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
  File "/workdir/ldm/models/diffusion/ddim.py", line 165, in ddim_sampling
    outs = self.p_sample_ddim(img, cond, ts, index=index, use_original_steps=ddim_use_original_steps,
  File "/usr/local/lib/python3.10/dist-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
  File "/workdir/ldm/models/diffusion/ddim.py", line 230, in p_sample_ddim
    a_t = torch.full((b, 1, 1, 1), alphas[index], device=device)
RuntimeError: CUDA error: unspecified launch failure
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/workdir/main.py", line 671, in <module>
    trainer.fit(model, data)
  File "/usr/local/lib/python3.10/dist-packages/lightning/pytorch/trainer/trainer.py", line 608, in fit
    call._call_and_handle_interrupt(
  File "/usr/local/lib/python3.10/dist-packages/lightning/pytorch/trainer/call.py", line 63, in _call_and_handle_interrupt
    trainer._teardown()
  File "/usr/local/lib/python3.10/dist-packages/lightning/pytorch/trainer/trainer.py", line 1175, in _teardown
    self.strategy.teardown()
  File "/usr/local/lib/python3.10/dist-packages/lightning/pytorch/strategies/ddp.py", line 490, in teardown
    super().teardown()
  File "/usr/local/lib/python3.10/dist-packages/lightning/pytorch/strategies/parallel.py", line 125, in teardown
    super().teardown()
  File "/usr/local/lib/python3.10/dist-packages/lightning/pytorch/strategies/strategy.py", line 492, in teardown
    _optimizers_to_device(self.optimizers, torch.device("cpu"))
  File "/usr/local/lib/python3.10/dist-packages/lightning/fabric/utilities/optimizer.py", line 28, in _optimizers_to_device
    _optimizer_to_device(opt, device)
  File "/usr/local/lib/python3.10/dist-packages/lightning/fabric/utilities/optimizer.py", line 34, in _optimizer_to_device
    optimizer.state[p] = apply_to_collection(v, Tensor, move_data_to_device, device)
  File "/usr/local/lib/python3.10/dist-packages/lightning_utilities/core/apply_func.py", line 70, in apply_to_collection
    return {k: function(v, *args, **kwargs) for k, v in data.items()}
  File "/usr/local/lib/python3.10/dist-packages/lightning_utilities/core/apply_func.py", line 70, in <dictcomp>
    return {k: function(v, *args, **kwargs) for k, v in data.items()}
  File "/usr/local/lib/python3.10/dist-packages/lightning/fabric/utilities/apply_func.py", line 101, in move_data_to_device
    return apply_to_collection(batch, dtype=_TransferableDataType, function=batch_to)
  File "/usr/local/lib/python3.10/dist-packages/lightning_utilities/core/apply_func.py", line 64, in apply_to_collection
    return function(data, *args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/lightning/fabric/utilities/apply_func.py", line 95, in batch_to
    data_output = data.to(device, **kwargs)
RuntimeError: CUDA error: unspecified launch failure
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

[rank11]:[W CUDAGuardImpl.h:115] Warning: CUDA warning: unspecified launch failure (function destroyEvent)
terminate called after throwing an instance of 'c10::Error'
  what():  CUDA error: unspecified launch failure
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Exception raised from c10_cuda_check_implementation at /opt/pytorch/pytorch/c10/cuda/CUDAException.cpp:44 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x99 (0x7fa82cd9c8f9 in /usr/local/lib/python3.10/dist-packages/torch/lib/libc10.so)
frame #1: c10::detail::torchCheckFail(char const*, char const*, unsigned int, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&) + 0xe0 (0x7fa82cd51bb6 in /usr/local/lib/python3.10/dist-packages/torch/lib/libc10.so)
frame #2: c10::cuda::c10_cuda_check_implementation(int, char const*, char const*, int, bool) + 0x3c2 (0x7fa837d8ce12 in /usr/local/lib/python3.10/dist-packages/torch/lib/libc10_cuda.so)
frame #3: <unknown function> + 0x1914e (0x7fa837d5a14e in /usr/local/lib/python3.10/dist-packages/torch/lib/libc10_cuda.so)
frame #4: <unknown function> + 0x1b7ed (0x7fa837d5c7ed in /usr/local/lib/python3.10/dist-packages/torch/lib/libc10_cuda.so)
frame #5: <unknown function> + 0x1bbc5 (0x7fa837d5cbc5 in /usr/local/lib/python3.10/dist-packages/torch/lib/libc10_cuda.so)
frame #6: <unknown function> + 0x483b00 (0x7fa82bbf0b00 in /usr/local/lib/python3.10/dist-packages/torch/lib/libtorch_python.so)
frame #7: c10::TensorImpl::~TensorImpl() + 0x9 (0x7fa82cd78419 in /usr/local/lib/python3.10/dist-packages/torch/lib/libc10.so)
frame #8: c10d::Reducer::~Reducer() + 0x32a (0x7fa82578be1a in /usr/local/lib/python3.10/dist-packages/torch/lib/libtorch_cpu.so)
frame #9: <unknown function> + 0xbaf2a2 (0x7fa82c31c2a2 in /usr/local/lib/python3.10/dist-packages/torch/lib/libtorch_python.so)
frame #10: <unknown function> + 0x3af29a (0x7fa82bb1c29a in /usr/local/lib/python3.10/dist-packages/torch/lib/libtorch_python.so)
frame #11: <unknown function> + 0xbb3a51 (0x7fa82c320a51 in /usr/local/lib/python3.10/dist-packages/torch/lib/libtorch_python.so)
frame #12: <unknown function> + 0x3b9cdd (0x7fa82bb26cdd in /usr/local/lib/python3.10/dist-packages/torch/lib/libtorch_python.so)
frame #13: <unknown function> + 0x3babc1 (0x7fa82bb27bc1 in /usr/local/lib/python3.10/dist-packages/torch/lib/libtorch_python.so)
<omitting python frames>
frame #43: <unknown function> + 0x29d90 (0x7fa83bec2d90 in /usr/lib/x86_64-linux-gnu/libc.so.6)
frame #44: __libc_start_main + 0x80 (0x7fa83bec2e40 in /usr/lib/x86_64-linux-gnu/libc.so.6)

:::MLLOG {"namespace": "", "time_ms": 1718490308625, "event_type": "INTERVAL_START", "key": "block_start", "value": "validation_step", "metadata": {"file": "mlperf_logging_utils.py", "lineno": 142, "step_num": 230}}
:::MLLOG {"namespace": "", "time_ms": 1718490312641, "event_type": "INTERVAL_END", "key": "block_stop", "value": "validation_step", "metadata": {"file": "mlperf_logging_utils.py", "lineno": 147, "step_num": 230}}
[rank10]:[E ProcessGroupNCCL.cpp:754] [Rank 10] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=71974, OpType=ALLGATHER, NumelIn=3840000, NumelOut=61440000, Timeout(ms)=1800000) ran for 1800699 milliseconds before timing out.
[rank10]:[E ProcessGroupNCCL.cpp:768] Some NCCL operations have failed or timed out. Due to the asynchronous nature of CUDA kernels, subsequent GPU operations might run on corrupted/incomplete data.
[rank10]:[E ProcessGroupNCCL.cpp:774] To avoid data inconsistency, we are taking the entire process down.
[rank10]:[E ProcessGroupNCCL.cpp:1282] [Rank 10] NCCL watchdog thread terminated with exception: [Rank 10] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=71974, OpType=ALLGATHER, NumelIn=3840000, NumelOut=61440000, Timeout(ms)=1800000) ran for 1800699 milliseconds before timing out.
Exception raised from checkTimeout at /opt/pytorch/pytorch/torch/csrc/distributed/c10d/ProcessGroupNCCL.cpp:756 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x99 (0x7f69fdc858f9 in /usr/local/lib/python3.10/dist-packages/torch/lib/libc10.so)
frame #1: c10d::ProcessGroupNCCL::WorkNCCL::checkTimeout(c10::optional<std::chrono::duration<long, std::ratio<1l, 1000l> > >) + 0x1f2 (0x7f699fb58142 in /usr/local/lib/python3.10/dist-packages/torch/lib/libtorch_cuda.so)
frame #2: c10d::ProcessGroupNCCL::workCleanupLoop() + 0x178 (0x7f699fb5e538 in /usr/local/lib/python3.10/dist-packages/torch/lib/libtorch_cuda.so)
frame #3: c10d::ProcessGroupNCCL::ncclCommWatchdog() + 0x8e (0x7f699fb5eb2e in /usr/local/lib/python3.10/dist-packages/torch/lib/libtorch_cuda.so)
frame #4: <unknown function> + 0xdc253 (0x7f69fd8b0253 in /usr/lib/x86_64-linux-gnu/libstdc++.so.6)
frame #5: <unknown function> + 0x94ac3 (0x7f6a0ce80ac3 in /usr/lib/x86_64-linux-gnu/libc.so.6)
frame #6: <unknown function> + 0x126a40 (0x7f6a0cf12a40 in /usr/lib/x86_64-linux-gnu/libc.so.6)

terminate called after throwing an instance of 'c10::DistBackendError'
  what():  [Rank 10] NCCL watchdog thread terminated with exception: [Rank 10] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=71974, OpType=ALLGATHER, NumelIn=3840000, NumelOut=61440000, Timeout(ms)=1800000) ran for 1800699 milliseconds before timing out.
Exception raised from checkTimeout at /opt/pytorch/pytorch/torch/csrc/distributed/c10d/ProcessGroupNCCL.cpp:756 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x99 (0x7f69fdc858f9 in /usr/local/lib/python3.10/dist-packages/torch/lib/libc10.so)
frame #1: c10d::ProcessGroupNCCL::WorkNCCL::checkTimeout(c10::optional<std::chrono::duration<long, std::ratio<1l, 1000l> > >) + 0x1f2 (0x7f699fb58142 in /usr/local/lib/python3.10/dist-packages/torch/lib/libtorch_cuda.so)
frame #2: c10d::ProcessGroupNCCL::workCleanupLoop() + 0x178 (0x7f699fb5e538 in /usr/local/lib/python3.10/dist-packages/torch/lib/libtorch_cuda.so)
frame #3: c10d::ProcessGroupNCCL::ncclCommWatchdog() + 0x8e (0x7f699fb5eb2e in /usr/local/lib/python3.10/dist-packages/torch/lib/libtorch_cuda.so)
frame #4: <unknown function> + 0xdc253 (0x7f69fd8b0253 in /usr/lib/x86_64-linux-gnu/libstdc++.so.6)
frame #5: <unknown function> + 0x94ac3 (0x7f6a0ce80ac3 in /usr/lib/x86_64-linux-gnu/libc.so.6)
frame #6: <unknown function> + 0x126a40 (0x7f6a0cf12a40 in /usr/lib/x86_64-linux-gnu/libc.so.6)

Exception raised from ncclCommWatchdog at /opt/pytorch/pytorch/torch/csrc/distributed/c10d/ProcessGroupNCCL.cpp:1286 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x99 (0x7f69fdc858f9 in /usr/local/lib/python3.10/dist-packages/torch/lib/libc10.so)
frame #1: <unknown function> + 0xf59d3e (0x7f699fb86d3e in /usr/local/lib/python3.10/dist-packages/torch/lib/libtorch_cuda.so)
frame #2: <unknown function> + 0xc91879 (0x7f699f8be879 in /usr/local/lib/python3.10/dist-packages/torch/lib/libtorch_cuda.so)
frame #3: <unknown function> + 0xdc253 (0x7f69fd8b0253 in /usr/lib/x86_64-linux-gnu/libstdc++.so.6)
frame #4: <unknown function> + 0x94ac3 (0x7f6a0ce80ac3 in /usr/lib/x86_64-linux-gnu/libc.so.6)
frame #5: <unknown function> + 0x126a40 (0x7f6a0cf12a40 in /usr/lib/x86_64-linux-gnu/libc.so.6)

[rank12]:[E ProcessGroupNCCL.cpp:754] [Rank 12] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=71974, OpType=ALLGATHER, NumelIn=3840000, NumelOut=61440000, Timeout(ms)=1800000) ran for 1800136 milliseconds before timing out.
[rank12]:[E ProcessGroupNCCL.cpp:768] Some NCCL operations have failed or timed out. Due to the asynchronous nature of CUDA kernels, subsequent GPU operations might run on corrupted/incomplete data.
[rank12]:[E ProcessGroupNCCL.cpp:774] To avoid data inconsistency, we are taking the entire process down.
[rank12]:[E ProcessGroupNCCL.cpp:1282] [Rank 12] NCCL watchdog thread terminated with exception: [Rank 12] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=71974, OpType=ALLGATHER, NumelIn=3840000, NumelOut=61440000, Timeout(ms)=1800000) ran for 1800136 milliseconds before timing out.
Exception raised from checkTimeout at /opt/pytorch/pytorch/torch/csrc/distributed/c10d/ProcessGroupNCCL.cpp:756 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x99 (0x7f4d41f9c8f9 in /usr/local/lib/python3.10/dist-packages/torch/lib/libc10.so)
frame #1: c10d::ProcessGroupNCCL::WorkNCCL::checkTimeout(c10::optional<std::chrono::duration<long, std::ratio<1l, 1000l> > >) + 0x1f2 (0x7f4ce3d58142 in /usr/local/lib/python3.10/dist-packages/torch/lib/libtorch_cuda.so)
frame #2: c10d::ProcessGroupNCCL::workCleanupLoop() + 0x178 (0x7f4ce3d5e538 in /usr/local/lib/python3.10/dist-packages/torch/lib/libtorch_cuda.so)
frame #3: c10d::ProcessGroupNCCL::ncclCommWatchdog() + 0x8e (0x7f4ce3d5eb2e in /usr/local/lib/python3.10/dist-packages/torch/lib/libtorch_cuda.so)
frame #4: <unknown function> + 0xdc253 (0x7f4d41ab0253 in /usr/lib/x86_64-linux-gnu/libstdc++.so.6)
frame #5: <unknown function> + 0x94ac3 (0x7f4d510ceac3 in /usr/lib/x86_64-linux-gnu/libc.so.6)
frame #6: <unknown function> + 0x126a40 (0x7f4d51160a40 in /usr/lib/x86_64-linux-gnu/libc.so.6)

terminate called after throwing an instance of 'c10::DistBackendError'
  what():  [Rank 12] NCCL watchdog thread terminated with exception: [Rank 12] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=71974, OpType=ALLGATHER, NumelIn=3840000, NumelOut=61440000, Timeout(ms)=1800000) ran for 1800136 milliseconds before timing out.
Exception raised from checkTimeout at /opt/pytorch/pytorch/torch/csrc/distributed/c10d/ProcessGroupNCCL.cpp:756 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x99 (0x7f4d41f9c8f9 in /usr/local/lib/python3.10/dist-packages/torch/lib/libc10.so)
frame #1: c10d::ProcessGroupNCCL::WorkNCCL::checkTimeout(c10::optional<std::chrono::duration<long, std::ratio<1l, 1000l> > >) + 0x1f2 (0x7f4ce3d58142 in /usr/local/lib/python3.10/dist-packages/torch/lib/libtorch_cuda.so)
frame #2: c10d::ProcessGroupNCCL::workCleanupLoop() + 0x178 (0x7f4ce3d5e538 in /usr/local/lib/python3.10/dist-packages/torch/lib/libtorch_cuda.so)
frame #3: c10d::ProcessGroupNCCL::ncclCommWatchdog() + 0x8e (0x7f4ce3d5eb2e in /usr/local/lib/python3.10/dist-packages/torch/lib/libtorch_cuda.so)
frame #4: <unknown function> + 0xdc253 (0x7f4d41ab0253 in /usr/lib/x86_64-linux-gnu/libstdc++.so.6)
frame #5: <unknown function> + 0x94ac3 (0x7f4d510ceac3 in /usr/lib/x86_64-linux-gnu/libc.so.6)
frame #6: <unknown function> + 0x126a40 (0x7f4d51160a40 in /usr/lib/x86_64-linux-gnu/libc.so.6)

Exception raised from ncclCommWatchdog at /opt/pytorch/pytorch/torch/csrc/distributed/c10d/ProcessGroupNCCL.cpp:1286 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x99 (0x7f4d41f9c8f9 in /usr/local/lib/python3.10/dist-packages/torch/lib/libc10.so)
frame #1: <unknown function> + 0xf59d3e (0x7f4ce3d86d3e in /usr/local/lib/python3.10/dist-packages/torch/lib/libtorch_cuda.so)
frame #2: <unknown function> + 0xc91879 (0x7f4ce3abe879 in /usr/local/lib/python3.10/dist-packages/torch/lib/libtorch_cuda.so)
frame #3: <unknown function> + 0xdc253 (0x7f4d41ab0253 in /usr/lib/x86_64-linux-gnu/libstdc++.so.6)
frame #4: <unknown function> + 0x94ac3 (0x7f4d510ceac3 in /usr/lib/x86_64-linux-gnu/libc.so.6)
frame #5: <unknown function> + 0x126a40 (0x7f4d51160a40 in /usr/lib/x86_64-linux-gnu/libc.so.6)

[rank0]:[E ProcessGroupNCCL.cpp:754] [Rank 0] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=71974, OpType=ALLGATHER, NumelIn=3840000, NumelOut=61440000, Timeout(ms)=1800000) ran for 1800367 milliseconds before timing out.
[rank0]:[E ProcessGroupNCCL.cpp:768] Some NCCL operations have failed or timed out. Due to the asynchronous nature of CUDA kernels, subsequent GPU operations might run on corrupted/incomplete data.
[rank0]:[E ProcessGroupNCCL.cpp:774] To avoid data inconsistency, we are taking the entire process down.
[rank0]:[E ProcessGroupNCCL.cpp:1282] [Rank 0] NCCL watchdog thread terminated with exception: [Rank 0] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=71974, OpType=ALLGATHER, NumelIn=3840000, NumelOut=61440000, Timeout(ms)=1800000) ran for 1800367 milliseconds before timing out.
Exception raised from checkTimeout at /opt/pytorch/pytorch/torch/csrc/distributed/c10d/ProcessGroupNCCL.cpp:756 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x99 (0x7f034e99c8f9 in /usr/local/lib/python3.10/dist-packages/torch/lib/libc10.so)
frame #1: c10d::ProcessGroupNCCL::WorkNCCL::checkTimeout(c10::optional<std::chrono::duration<long, std::ratio<1l, 1000l> > >) + 0x1f2 (0x7f02f0758142 in /usr/local/lib/python3.10/dist-packages/torch/lib/libtorch_cuda.so)
frame #2: c10d::ProcessGroupNCCL::workCleanupLoop() + 0x178 (0x7f02f075e538 in /usr/local/lib/python3.10/dist-packages/torch/lib/libtorch_cuda.so)
frame #3: c10d::ProcessGroupNCCL::ncclCommWatchdog() + 0x8e (0x7f02f075eb2e in /usr/local/lib/python3.10/dist-packages/torch/lib/libtorch_cuda.so)
frame #4: <unknown function> + 0xdc253 (0x7f034e4b0253 in /usr/lib/x86_64-linux-gnu/libstdc++.so.6)
frame #5: <unknown function> + 0x94ac3 (0x7f035dae4ac3 in /usr/lib/x86_64-linux-gnu/libc.so.6)
frame #6: <unknown function> + 0x126a40 (0x7f035db76a40 in /usr/lib/x86_64-linux-gnu/libc.so.6)

terminate called after throwing an instance of 'c10::DistBackendError'
  what():  [Rank 0] NCCL watchdog thread terminated with exception: [Rank 0] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=71974, OpType=ALLGATHER, NumelIn=3840000, NumelOut=61440000, Timeout(ms)=1800000) ran for 1800367 milliseconds before timing out.
Exception raised from checkTimeout at /opt/pytorch/pytorch/torch/csrc/distributed/c10d/ProcessGroupNCCL.cpp:756 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x99 (0x7f034e99c8f9 in /usr/local/lib/python3.10/dist-packages/torch/lib/libc10.so)
frame #1: c10d::ProcessGroupNCCL::WorkNCCL::checkTimeout(c10::optional<std::chrono::duration<long, std::ratio<1l, 1000l> > >) + 0x1f2 (0x7f02f0758142 in /usr/local/lib/python3.10/dist-packages/torch/lib/libtorch_cuda.so)
frame #2: c10d::ProcessGroupNCCL::workCleanupLoop() + 0x178 (0x7f02f075e538 in /usr/local/lib/python3.10/dist-packages/torch/lib/libtorch_cuda.so)
frame #3: c10d::ProcessGroupNCCL::ncclCommWatchdog() + 0x8e (0x7f02f075eb2e in /usr/local/lib/python3.10/dist-packages/torch/lib/libtorch_cuda.so)
frame #4: <unknown function> + 0xdc253 (0x7f034e4b0253 in /usr/lib/x86_64-linux-gnu/libstdc++.so.6)
frame #5: <unknown function> + 0x94ac3 (0x7f035dae4ac3 in /usr/lib/x86_64-linux-gnu/libc.so.6)
frame #6: <unknown function> + 0x126a40 (0x7f035db76a40 in /usr/lib/x86_64-linux-gnu/libc.so.6)

Exception raised from ncclCommWatchdog at /opt/pytorch/pytorch/torch/csrc/distributed/c10d/ProcessGroupNCCL.cpp:1286 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x99 (0x7f034e99c8f9 in /usr/local/lib/python3.10/dist-packages/torch/lib/libc10.so)
frame #1: <unknown function> + 0xf59d3e (0x7f02f0786d3e in /usr/local/lib/python3.10/dist-packages/torch/lib/libtorch_cuda.so)
frame #2: <unknown function> + 0xc91879 (0x7f02f04be879 in /usr/local/lib/python3.10/dist-packages/torch/lib/libtorch_cuda.so)
frame #3: <unknown function> + 0xdc253 (0x7f034e4b0253 in /usr/lib/x86_64-linux-gnu/libstdc++.so.6)
frame #4: <unknown function> + 0x94ac3 (0x7f035dae4ac3 in /usr/lib/x86_64-linux-gnu/libc.so.6)
frame #5: <unknown function> + 0x126a40 (0x7f035db76a40 in /usr/lib/x86_64-linux-gnu/libc.so.6)

[rank8]:[E ProcessGroupNCCL.cpp:754] [Rank 8] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=71974, OpType=ALLGATHER, NumelIn=3840000, NumelOut=61440000, Timeout(ms)=1800000) ran for 1800988 milliseconds before timing out.
[rank8]:[E ProcessGroupNCCL.cpp:768] Some NCCL operations have failed or timed out. Due to the asynchronous nature of CUDA kernels, subsequent GPU operations might run on corrupted/incomplete data.
[rank8]:[E ProcessGroupNCCL.cpp:774] To avoid data inconsistency, we are taking the entire process down.
[rank8]:[E ProcessGroupNCCL.cpp:1282] [Rank 8] NCCL watchdog thread terminated with exception: [Rank 8] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=71974, OpType=ALLGATHER, NumelIn=3840000, NumelOut=61440000, Timeout(ms)=1800000) ran for 1800988 milliseconds before timing out.
Exception raised from checkTimeout at /opt/pytorch/pytorch/torch/csrc/distributed/c10d/ProcessGroupNCCL.cpp:756 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x99 (0x7fa7230858f9 in /usr/local/lib/python3.10/dist-packages/torch/lib/libc10.so)
frame #1: c10d::ProcessGroupNCCL::WorkNCCL::checkTimeout(c10::optional<std::chrono::duration<long, std::ratio<1l, 1000l> > >) + 0x1f2 (0x7fa6c4f58142 in /usr/local/lib/python3.10/dist-packages/torch/lib/libtorch_cuda.so)
frame #2: c10d::ProcessGroupNCCL::workCleanupLoop() + 0x178 (0x7fa6c4f5e538 in /usr/local/lib/python3.10/dist-packages/torch/lib/libtorch_cuda.so)
frame #3: c10d::ProcessGroupNCCL::ncclCommWatchdog() + 0x8e (0x7fa6c4f5eb2e in /usr/local/lib/python3.10/dist-packages/torch/lib/libtorch_cuda.so)
frame #4: <unknown function> + 0xdc253 (0x7fa722cb0253 in /usr/lib/x86_64-linux-gnu/libstdc++.so.6)
frame #5: <unknown function> + 0x94ac3 (0x7fa7321eaac3 in /usr/lib/x86_64-linux-gnu/libc.so.6)
frame #6: <unknown function> + 0x126a40 (0x7fa73227ca40 in /usr/lib/x86_64-linux-gnu/libc.so.6)

terminate called after throwing an instance of 'c10::DistBackendError'
  what():  [Rank 8] NCCL watchdog thread terminated with exception: [Rank 8] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=71974, OpType=ALLGATHER, NumelIn=3840000, NumelOut=61440000, Timeout(ms)=1800000) ran for 1800988 milliseconds before timing out.
Exception raised from checkTimeout at /opt/pytorch/pytorch/torch/csrc/distributed/c10d/ProcessGroupNCCL.cpp:756 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x99 (0x7fa7230858f9 in /usr/local/lib/python3.10/dist-packages/torch/lib/libc10.so)
frame #1: c10d::ProcessGroupNCCL::WorkNCCL::checkTimeout(c10::optional<std::chrono::duration<long, std::ratio<1l, 1000l> > >) + 0x1f2 (0x7fa6c4f58142 in /usr/local/lib/python3.10/dist-packages/torch/lib/libtorch_cuda.so)
frame #2: c10d::ProcessGroupNCCL::workCleanupLoop() + 0x178 (0x7fa6c4f5e538 in /usr/local/lib/python3.10/dist-packages/torch/lib/libtorch_cuda.so)
frame #3: c10d::ProcessGroupNCCL::ncclCommWatchdog() + 0x8e (0x7fa6c4f5eb2e in /usr/local/lib/python3.10/dist-packages/torch/lib/libtorch_cuda.so)
frame #4: <unknown function> + 0xdc253 (0x7fa722cb0253 in /usr/lib/x86_64-linux-gnu/libstdc++.so.6)
frame #5: <unknown function> + 0x94ac3 (0x7fa7321eaac3 in /usr/lib/x86_64-linux-gnu/libc.so.6)
frame #6: <unknown function> + 0x126a40 (0x7fa73227ca40 in /usr/lib/x86_64-linux-gnu/libc.so.6)

Exception raised from ncclCommWatchdog at /opt/pytorch/pytorch/torch/csrc/distributed/c10d/ProcessGroupNCCL.cpp:1286 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x99 (0x7fa7230858f9 in /usr/local/lib/python3.10/dist-packages/torch/lib/libc10.so)
frame #1: <unknown function> + 0xf59d3e (0x7fa6c4f86d3e in /usr/local/lib/python3.10/dist-packages/torch/lib/libtorch_cuda.so)
frame #2: <unknown function> + 0xc91879 (0x7fa6c4cbe879 in /usr/local/lib/python3.10/dist-packages/torch/lib/libtorch_cuda.so)
frame #3: <unknown function> + 0xdc253 (0x7fa722cb0253 in /usr/lib/x86_64-linux-gnu/libstdc++.so.6)
frame #4: <unknown function> + 0x94ac3 (0x7fa7321eaac3 in /usr/lib/x86_64-linux-gnu/libc.so.6)
frame #5: <unknown function> + 0x126a40 (0x7fa73227ca40 in /usr/lib/x86_64-linux-gnu/libc.so.6)

[rank14]:[E ProcessGroupNCCL.cpp:754] [Rank 14] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=71974, OpType=ALLGATHER, NumelIn=3840000, NumelOut=61440000, Timeout(ms)=1800000) ran for 1800134 milliseconds before timing out.
[rank14]:[E ProcessGroupNCCL.cpp:768] Some NCCL operations have failed or timed out. Due to the asynchronous nature of CUDA kernels, subsequent GPU operations might run on corrupted/incomplete data.
[rank14]:[E ProcessGroupNCCL.cpp:774] To avoid data inconsistency, we are taking the entire process down.
[rank14]:[E ProcessGroupNCCL.cpp:1282] [Rank 14] NCCL watchdog thread terminated with exception: [Rank 14] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=71974, OpType=ALLGATHER, NumelIn=3840000, NumelOut=61440000, Timeout(ms)=1800000) ran for 1800134 milliseconds before timing out.
Exception raised from checkTimeout at /opt/pytorch/pytorch/torch/csrc/distributed/c10d/ProcessGroupNCCL.cpp:756 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x99 (0x7fee8179c8f9 in /usr/local/lib/python3.10/dist-packages/torch/lib/libc10.so)
frame #1: c10d::ProcessGroupNCCL::WorkNCCL::checkTimeout(c10::optional<std::chrono::duration<long, std::ratio<1l, 1000l> > >) + 0x1f2 (0x7fee23558142 in /usr/local/lib/python3.10/dist-packages/torch/lib/libtorch_cuda.so)
frame #2: c10d::ProcessGroupNCCL::workCleanupLoop() + 0x178 (0x7fee2355e538 in /usr/local/lib/python3.10/dist-packages/torch/lib/libtorch_cuda.so)
frame #3: c10d::ProcessGroupNCCL::ncclCommWatchdog() + 0x8e (0x7fee2355eb2e in /usr/local/lib/python3.10/dist-packages/torch/lib/libtorch_cuda.so)
frame #4: <unknown function> + 0xdc253 (0x7fee812b0253 in /usr/lib/x86_64-linux-gnu/libstdc++.so.6)
frame #5: <unknown function> + 0x94ac3 (0x7fee90998ac3 in /usr/lib/x86_64-linux-gnu/libc.so.6)
frame #6: <unknown function> + 0x126a40 (0x7fee90a2aa40 in /usr/lib/x86_64-linux-gnu/libc.so.6)

terminate called after throwing an instance of 'c10::DistBackendError'
  what():  [Rank 14] NCCL watchdog thread terminated with exception: [Rank 14] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=71974, OpType=ALLGATHER, NumelIn=3840000, NumelOut=61440000, Timeout(ms)=1800000) ran for 1800134 milliseconds before timing out.
Exception raised from checkTimeout at /opt/pytorch/pytorch/torch/csrc/distributed/c10d/ProcessGroupNCCL.cpp:756 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x99 (0x7fee8179c8f9 in /usr/local/lib/python3.10/dist-packages/torch/lib/libc10.so)
frame #1: c10d::ProcessGroupNCCL::WorkNCCL::checkTimeout(c10::optional<std::chrono::duration<long, std::ratio<1l, 1000l> > >) + 0x1f2 (0x7fee23558142 in /usr/local/lib/python3.10/dist-packages/torch/lib/libtorch_cuda.so)
frame #2: c10d::ProcessGroupNCCL::workCleanupLoop() + 0x178 (0x7fee2355e538 in /usr/local/lib/python3.10/dist-packages/torch/lib/libtorch_cuda.so)
frame #3: c10d::ProcessGroupNCCL::ncclCommWatchdog() + 0x8e (0x7fee2355eb2e in /usr/local/lib/python3.10/dist-packages/torch/lib/libtorch_cuda.so)
frame #4: <unknown function> + 0xdc253 (0x7fee812b0253 in /usr/lib/x86_64-linux-gnu/libstdc++.so.6)
frame #5: <unknown function> + 0x94ac3 (0x7fee90998ac3 in /usr/lib/x86_64-linux-gnu/libc.so.6)
frame #6: <unknown function> + 0x126a40 (0x7fee90a2aa40 in /usr/lib/x86_64-linux-gnu/libc.so.6)

Exception raised from ncclCommWatchdog at /opt/pytorch/pytorch/torch/csrc/distributed/c10d/ProcessGroupNCCL.cpp:1286 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x99 (0x7fee8179c8f9 in /usr/local/lib/python3.10/dist-packages/torch/lib/libc10.so)
frame #1: <unknown function> + 0xf59d3e (0x7fee23586d3e in /usr/local/lib/python3.10/dist-packages/torch/lib/libtorch_cuda.so)
frame #2: <unknown function> + 0xc91879 (0x7fee232be879 in /usr/local/lib/python3.10/dist-packages/torch/lib/libtorch_cuda.so)
frame #3: <unknown function> + 0xdc253 (0x7fee812b0253 in /usr/lib/x86_64-linux-gnu/libstdc++.so.6)
frame #4: <unknown function> + 0x94ac3 (0x7fee90998ac3 in /usr/lib/x86_64-linux-gnu/libc.so.6)
frame #5: <unknown function> + 0x126a40 (0x7fee90a2aa40 in /usr/lib/x86_64-linux-gnu/libc.so.6)

[rank3]:[E ProcessGroupNCCL.cpp:754] [Rank 3] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=71974, OpType=ALLGATHER, NumelIn=3840000, NumelOut=61440000, Timeout(ms)=1800000) ran for 1800172 milliseconds before timing out.
[rank3]:[E ProcessGroupNCCL.cpp:768] Some NCCL operations have failed or timed out. Due to the asynchronous nature of CUDA kernels, subsequent GPU operations might run on corrupted/incomplete data.
[rank3]:[E ProcessGroupNCCL.cpp:774] To avoid data inconsistency, we are taking the entire process down.
[rank3]:[E ProcessGroupNCCL.cpp:1282] [Rank 3] NCCL watchdog thread terminated with exception: [Rank 3] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=71974, OpType=ALLGATHER, NumelIn=3840000, NumelOut=61440000, Timeout(ms)=1800000) ran for 1800172 milliseconds before timing out.
Exception raised from checkTimeout at /opt/pytorch/pytorch/torch/csrc/distributed/c10d/ProcessGroupNCCL.cpp:756 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x99 (0x7fa5ada858f9 in /usr/local/lib/python3.10/dist-packages/torch/lib/libc10.so)
frame #1: c10d::ProcessGroupNCCL::WorkNCCL::checkTimeout(c10::optional<std::chrono::duration<long, std::ratio<1l, 1000l> > >) + 0x1f2 (0x7fa54f958142 in /usr/local/lib/python3.10/dist-packages/torch/lib/libtorch_cuda.so)
frame #2: c10d::ProcessGroupNCCL::workCleanupLoop() + 0x178 (0x7fa54f95e538 in /usr/local/lib/python3.10/dist-packages/torch/lib/libtorch_cuda.so)
frame #3: c10d::ProcessGroupNCCL::ncclCommWatchdog() + 0x8e (0x7fa54f95eb2e in /usr/local/lib/python3.10/dist-packages/torch/lib/libtorch_cuda.so)
frame #4: <unknown function> + 0xdc253 (0x7fa5ad6b0253 in /usr/lib/x86_64-linux-gnu/libstdc++.so.6)
frame #5: <unknown function> + 0x94ac3 (0x7fa5bcc90ac3 in /usr/lib/x86_64-linux-gnu/libc.so.6)
frame #6: <unknown function> + 0x126a40 (0x7fa5bcd22a40 in /usr/lib/x86_64-linux-gnu/libc.so.6)

terminate called after throwing an instance of 'c10::DistBackendError'
  what():  [Rank 3] NCCL watchdog thread terminated with exception: [Rank 3] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=71974, OpType=ALLGATHER, NumelIn=3840000, NumelOut=61440000, Timeout(ms)=1800000) ran for 1800172 milliseconds before timing out.
Exception raised from checkTimeout at /opt/pytorch/pytorch/torch/csrc/distributed/c10d/ProcessGroupNCCL.cpp:756 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x99 (0x7fa5ada858f9 in /usr/local/lib/python3.10/dist-packages/torch/lib/libc10.so)
frame #1: c10d::ProcessGroupNCCL::WorkNCCL::checkTimeout(c10::optional<std::chrono::duration<long, std::ratio<1l, 1000l> > >) + 0x1f2 (0x7fa54f958142 in /usr/local/lib/python3.10/dist-packages/torch/lib/libtorch_cuda.so)
frame #2: c10d::ProcessGroupNCCL::workCleanupLoop() + 0x178 (0x7fa54f95e538 in /usr/local/lib/python3.10/dist-packages/torch/lib/libtorch_cuda.so)
frame #3: c10d::ProcessGroupNCCL::ncclCommWatchdog() + 0x8e (0x7fa54f95eb2e in /usr/local/lib/python3.10/dist-packages/torch/lib/libtorch_cuda.so)
frame #4: <unknown function> + 0xdc253 (0x7fa5ad6b0253 in /usr/lib/x86_64-linux-gnu/libstdc++.so.6)
frame #5: <unknown function> + 0x94ac3 (0x7fa5bcc90ac3 in /usr/lib/x86_64-linux-gnu/libc.so.6)
frame #6: <unknown function> + 0x126a40 (0x7fa5bcd22a40 in /usr/lib/x86_64-linux-gnu/libc.so.6)

Exception raised from ncclCommWatchdog at /opt/pytorch/pytorch/torch/csrc/distributed/c10d/ProcessGroupNCCL.cpp:1286 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x99 (0x7fa5ada858f9 in /usr/local/lib/python3.10/dist-packages/torch/lib/libc10.so)
frame #1: <unknown function> + 0xf59d3e (0x7fa54f986d3e in /usr/local/lib/python3.10/dist-packages/torch/lib/libtorch_cuda.so)
frame #2: <unknown function> + 0xc91879 (0x7fa54f6be879 in /usr/local/lib/python3.10/dist-packages/torch/lib/libtorch_cuda.so)
frame #3: <unknown function> + 0xdc253 (0x7fa5ad6b0253 in /usr/lib/x86_64-linux-gnu/libstdc++.so.6)
frame #4: <unknown function> + 0x94ac3 (0x7fa5bcc90ac3 in /usr/lib/x86_64-linux-gnu/libc.so.6)
frame #5: <unknown function> + 0x126a40 (0x7fa5bcd22a40 in /usr/lib/x86_64-linux-gnu/libc.so.6)

[rank2]:[E ProcessGroupNCCL.cpp:754] [Rank 2] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=71974, OpType=ALLGATHER, NumelIn=3840000, NumelOut=61440000, Timeout(ms)=1800000) ran for 1800128 milliseconds before timing out.
[rank2]:[E ProcessGroupNCCL.cpp:768] Some NCCL operations have failed or timed out. Due to the asynchronous nature of CUDA kernels, subsequent GPU operations might run on corrupted/incomplete data.
[rank2]:[E ProcessGroupNCCL.cpp:774] To avoid data inconsistency, we are taking the entire process down.
[rank2]:[E ProcessGroupNCCL.cpp:1282] [Rank 2] NCCL watchdog thread terminated with exception: [Rank 2] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=71974, OpType=ALLGATHER, NumelIn=3840000, NumelOut=61440000, Timeout(ms)=1800000) ran for 1800128 milliseconds before timing out.
Exception raised from checkTimeout at /opt/pytorch/pytorch/torch/csrc/distributed/c10d/ProcessGroupNCCL.cpp:756 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x99 (0x7f01062858f9 in /usr/local/lib/python3.10/dist-packages/torch/lib/libc10.so)
frame #1: c10d::ProcessGroupNCCL::WorkNCCL::checkTimeout(c10::optional<std::chrono::duration<long, std::ratio<1l, 1000l> > >) + 0x1f2 (0x7f00a8158142 in /usr/local/lib/python3.10/dist-packages/torch/lib/libtorch_cuda.so)
frame #2: c10d::ProcessGroupNCCL::workCleanupLoop() + 0x178 (0x7f00a815e538 in /usr/local/lib/python3.10/dist-packages/torch/lib/libtorch_cuda.so)
frame #3: c10d::ProcessGroupNCCL::ncclCommWatchdog() + 0x8e (0x7f00a815eb2e in /usr/local/lib/python3.10/dist-packages/torch/lib/libtorch_cuda.so)
frame #4: <unknown function> + 0xdc253 (0x7f0105eb0253 in /usr/lib/x86_64-linux-gnu/libstdc++.so.6)
frame #5: <unknown function> + 0x94ac3 (0x7f011543eac3 in /usr/lib/x86_64-linux-gnu/libc.so.6)
frame #6: <unknown function> + 0x126a40 (0x7f01154d0a40 in /usr/lib/x86_64-linux-gnu/libc.so.6)

terminate called after throwing an instance of 'c10::DistBackendError'
  what():  [Rank 2] NCCL watchdog thread terminated with exception: [Rank 2] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=71974, OpType=ALLGATHER, NumelIn=3840000, NumelOut=61440000, Timeout(ms)=1800000) ran for 1800128 milliseconds before timing out.
Exception raised from checkTimeout at /opt/pytorch/pytorch/torch/csrc/distributed/c10d/ProcessGroupNCCL.cpp:756 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x99 (0x7f01062858f9 in /usr/local/lib/python3.10/dist-packages/torch/lib/libc10.so)
frame #1: c10d::ProcessGroupNCCL::WorkNCCL::checkTimeout(c10::optional<std::chrono::duration<long, std::ratio<1l, 1000l> > >) + 0x1f2 (0x7f00a8158142 in /usr/local/lib/python3.10/dist-packages/torch/lib/libtorch_cuda.so)
frame #2: c10d::ProcessGroupNCCL::workCleanupLoop() + 0x178 (0x7f00a815e538 in /usr/local/lib/python3.10/dist-packages/torch/lib/libtorch_cuda.so)
frame #3: c10d::ProcessGroupNCCL::ncclCommWatchdog() + 0x8e (0x7f00a815eb2e in /usr/local/lib/python3.10/dist-packages/torch/lib/libtorch_cuda.so)
frame #4: <unknown function> + 0xdc253 (0x7f0105eb0253 in /usr/lib/x86_64-linux-gnu/libstdc++.so.6)
frame #5: <unknown function> + 0x94ac3 (0x7f011543eac3 in /usr/lib/x86_64-linux-gnu/libc.so.6)
frame #6: <unknown function> + 0x126a40 (0x7f01154d0a40 in /usr/lib/x86_64-linux-gnu/libc.so.6)

Exception raised from ncclCommWatchdog at /opt/pytorch/pytorch/torch/csrc/distributed/c10d/ProcessGroupNCCL.cpp:1286 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x99 (0x7f01062858f9 in /usr/local/lib/python3.10/dist-packages/torch/lib/libc10.so)
frame #1: <unknown function> + 0xf59d3e (0x7f00a8186d3e in /usr/local/lib/python3.10/dist-packages/torch/lib/libtorch_cuda.so)
frame #2: <unknown function> + 0xc91879 (0x7f00a7ebe879 in /usr/local/lib/python3.10/dist-packages/torch/lib/libtorch_cuda.so)
frame #3: <unknown function> + 0xdc253 (0x7f0105eb0253 in /usr/lib/x86_64-linux-gnu/libstdc++.so.6)
frame #4: <unknown function> + 0x94ac3 (0x7f011543eac3 in /usr/lib/x86_64-linux-gnu/libc.so.6)
frame #5: <unknown function> + 0x126a40 (0x7f01154d0a40 in /usr/lib/x86_64-linux-gnu/libc.so.6)

[rank15]:[E ProcessGroupNCCL.cpp:754] [Rank 15] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=71974, OpType=ALLGATHER, NumelIn=3840000, NumelOut=61440000, Timeout(ms)=1800000) ran for 1800258 milliseconds before timing out.
[rank15]:[E ProcessGroupNCCL.cpp:768] Some NCCL operations have failed or timed out. Due to the asynchronous nature of CUDA kernels, subsequent GPU operations might run on corrupted/incomplete data.
[rank15]:[E ProcessGroupNCCL.cpp:774] To avoid data inconsistency, we are taking the entire process down.
[rank15]:[E ProcessGroupNCCL.cpp:1282] [Rank 15] NCCL watchdog thread terminated with exception: [Rank 15] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=71974, OpType=ALLGATHER, NumelIn=3840000, NumelOut=61440000, Timeout(ms)=1800000) ran for 1800258 milliseconds before timing out.
Exception raised from checkTimeout at /opt/pytorch/pytorch/torch/csrc/distributed/c10d/ProcessGroupNCCL.cpp:756 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x99 (0x7f154bb9c8f9 in /usr/local/lib/python3.10/dist-packages/torch/lib/libc10.so)
frame #1: c10d::ProcessGroupNCCL::WorkNCCL::checkTimeout(c10::optional<std::chrono::duration<long, std::ratio<1l, 1000l> > >) + 0x1f2 (0x7f14ed958142 in /usr/local/lib/python3.10/dist-packages/torch/lib/libtorch_cuda.so)
frame #2: c10d::ProcessGroupNCCL::workCleanupLoop() + 0x178 (0x7f14ed95e538 in /usr/local/lib/python3.10/dist-packages/torch/lib/libtorch_cuda.so)
frame #3: c10d::ProcessGroupNCCL::ncclCommWatchdog() + 0x8e (0x7f14ed95eb2e in /usr/local/lib/python3.10/dist-packages/torch/lib/libtorch_cuda.so)
frame #4: <unknown function> + 0xdc253 (0x7f154b6b0253 in /usr/lib/x86_64-linux-gnu/libstdc++.so.6)
frame #5: <unknown function> + 0x94ac3 (0x7f155ad5fac3 in /usr/lib/x86_64-linux-gnu/libc.so.6)
frame #6: <unknown function> + 0x126a40 (0x7f155adf1a40 in /usr/lib/x86_64-linux-gnu/libc.so.6)

terminate called after throwing an instance of 'c10::DistBackendError'
  what():  [Rank 15] NCCL watchdog thread terminated with exception: [Rank 15] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=71974, OpType=ALLGATHER, NumelIn=3840000, NumelOut=61440000, Timeout(ms)=1800000) ran for 1800258 milliseconds before timing out.
Exception raised from checkTimeout at /opt/pytorch/pytorch/torch/csrc/distributed/c10d/ProcessGroupNCCL.cpp:756 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x99 (0x7f154bb9c8f9 in /usr/local/lib/python3.10/dist-packages/torch/lib/libc10.so)
frame #1: c10d::ProcessGroupNCCL::WorkNCCL::checkTimeout(c10::optional<std::chrono::duration<long, std::ratio<1l, 1000l> > >) + 0x1f2 (0x7f14ed958142 in /usr/local/lib/python3.10/dist-packages/torch/lib/libtorch_cuda.so)
frame #2: c10d::ProcessGroupNCCL::workCleanupLoop() + 0x178 (0x7f14ed95e538 in /usr/local/lib/python3.10/dist-packages/torch/lib/libtorch_cuda.so)
frame #3: c10d::ProcessGroupNCCL::ncclCommWatchdog() + 0x8e (0x7f14ed95eb2e in /usr/local/lib/python3.10/dist-packages/torch/lib/libtorch_cuda.so)
frame #4: <unknown function> + 0xdc253 (0x7f154b6b0253 in /usr/lib/x86_64-linux-gnu/libstdc++.so.6)
frame #5: <unknown function> + 0x94ac3 (0x7f155ad5fac3 in /usr/lib/x86_64-linux-gnu/libc.so.6)
frame #6: <unknown function> + 0x126a40 (0x7f155adf1a40 in /usr/lib/x86_64-linux-gnu/libc.so.6)

Exception raised from ncclCommWatchdog at /opt/pytorch/pytorch/torch/csrc/distributed/c10d/ProcessGroupNCCL.cpp:1286 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x99 (0x7f154bb9c8f9 in /usr/local/lib/python3.10/dist-packages/torch/lib/libc10.so)
frame #1: <unknown function> + 0xf59d3e (0x7f14ed986d3e in /usr/local/lib/python3.10/dist-packages/torch/lib/libtorch_cuda.so)
frame #2: <unknown function> + 0xc91879 (0x7f14ed6be879 in /usr/local/lib/python3.10/dist-packages/torch/lib/libtorch_cuda.so)
frame #3: <unknown function> + 0xdc253 (0x7f154b6b0253 in /usr/lib/x86_64-linux-gnu/libstdc++.so.6)
frame #4: <unknown function> + 0x94ac3 (0x7f155ad5fac3 in /usr/lib/x86_64-linux-gnu/libc.so.6)
frame #5: <unknown function> + 0x126a40 (0x7f155adf1a40 in /usr/lib/x86_64-linux-gnu/libc.so.6)

[rank5]:[E ProcessGroupNCCL.cpp:754] [Rank 5] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=71974, OpType=ALLGATHER, NumelIn=3840000, NumelOut=61440000, Timeout(ms)=1800000) ran for 1800254 milliseconds before timing out.
[rank5]:[E ProcessGroupNCCL.cpp:768] Some NCCL operations have failed or timed out. Due to the asynchronous nature of CUDA kernels, subsequent GPU operations might run on corrupted/incomplete data.
[rank5]:[E ProcessGroupNCCL.cpp:774] To avoid data inconsistency, we are taking the entire process down.
[rank5]:[E ProcessGroupNCCL.cpp:1282] [Rank 5] NCCL watchdog thread terminated with exception: [Rank 5] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=71974, OpType=ALLGATHER, NumelIn=3840000, NumelOut=61440000, Timeout(ms)=1800000) ran for 1800254 milliseconds before timing out.
Exception raised from checkTimeout at /opt/pytorch/pytorch/torch/csrc/distributed/c10d/ProcessGroupNCCL.cpp:756 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x99 (0x7f474de858f9 in /usr/local/lib/python3.10/dist-packages/torch/lib/libc10.so)
frame #1: c10d::ProcessGroupNCCL::WorkNCCL::checkTimeout(c10::optional<std::chrono::duration<long, std::ratio<1l, 1000l> > >) + 0x1f2 (0x7f46efd58142 in /usr/local/lib/python3.10/dist-packages/torch/lib/libtorch_cuda.so)
frame #2: c10d::ProcessGroupNCCL::workCleanupLoop() + 0x178 (0x7f46efd5e538 in /usr/local/lib/python3.10/dist-packages/torch/lib/libtorch_cuda.so)
frame #3: c10d::ProcessGroupNCCL::ncclCommWatchdog() + 0x8e (0x7f46efd5eb2e in /usr/local/lib/python3.10/dist-packages/torch/lib/libtorch_cuda.so)
frame #4: <unknown function> + 0xdc253 (0x7f474dab0253 in /usr/lib/x86_64-linux-gnu/libstdc++.so.6)
frame #5: <unknown function> + 0x94ac3 (0x7f475cfbdac3 in /usr/lib/x86_64-linux-gnu/libc.so.6)
frame #6: <unknown function> + 0x126a40 (0x7f475d04fa40 in /usr/lib/x86_64-linux-gnu/libc.so.6)

terminate called after throwing an instance of 'c10::DistBackendError'
  what():  [Rank 5] NCCL watchdog thread terminated with exception: [Rank 5] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=71974, OpType=ALLGATHER, NumelIn=3840000, NumelOut=61440000, Timeout(ms)=1800000) ran for 1800254 milliseconds before timing out.
Exception raised from checkTimeout at /opt/pytorch/pytorch/torch/csrc/distributed/c10d/ProcessGroupNCCL.cpp:756 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x99 (0x7f474de858f9 in /usr/local/lib/python3.10/dist-packages/torch/lib/libc10.so)
frame #1: c10d::ProcessGroupNCCL::WorkNCCL::checkTimeout(c10::optional<std::chrono::duration<long, std::ratio<1l, 1000l> > >) + 0x1f2 (0x7f46efd58142 in /usr/local/lib/python3.10/dist-packages/torch/lib/libtorch_cuda.so)
frame #2: c10d::ProcessGroupNCCL::workCleanupLoop() + 0x178 (0x7f46efd5e538 in /usr/local/lib/python3.10/dist-packages/torch/lib/libtorch_cuda.so)
frame #3: c10d::ProcessGroupNCCL::ncclCommWatchdog() + 0x8e (0x7f46efd5eb2e in /usr/local/lib/python3.10/dist-packages/torch/lib/libtorch_cuda.so)
frame #4: <unknown function> + 0xdc253 (0x7f474dab0253 in /usr/lib/x86_64-linux-gnu/libstdc++.so.6)
frame #5: <unknown function> + 0x94ac3 (0x7f475cfbdac3 in /usr/lib/x86_64-linux-gnu/libc.so.6)
frame #6: <unknown function> + 0x126a40 (0x7f475d04fa40 in /usr/lib/x86_64-linux-gnu/libc.so.6)

Exception raised from ncclCommWatchdog at /opt/pytorch/pytorch/torch/csrc/distributed/c10d/ProcessGroupNCCL.cpp:1286 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x99 (0x7f474de858f9 in /usr/local/lib/python3.10/dist-packages/torch/lib/libc10.so)
frame #1: <unknown function> + 0xf59d3e (0x7f46efd86d3e in /usr/local/lib/python3.10/dist-packages/torch/lib/libtorch_cuda.so)
frame #2: <unknown function> + 0xc91879 (0x7f46efabe879 in /usr/local/lib/python3.10/dist-packages/torch/lib/libtorch_cuda.so)
frame #3: <unknown function> + 0xdc253 (0x7f474dab0253 in /usr/lib/x86_64-linux-gnu/libstdc++.so.6)
frame #4: <unknown function> + 0x94ac3 (0x7f475cfbdac3 in /usr/lib/x86_64-linux-gnu/libc.so.6)
frame #5: <unknown function> + 0x126a40 (0x7f475d04fa40 in /usr/lib/x86_64-linux-gnu/libc.so.6)

[rank4]:[E ProcessGroupNCCL.cpp:754] [Rank 4] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=71974, OpType=ALLGATHER, NumelIn=3840000, NumelOut=61440000, Timeout(ms)=1800000) ran for 1800394 milliseconds before timing out.
[rank4]:[E ProcessGroupNCCL.cpp:768] Some NCCL operations have failed or timed out. Due to the asynchronous nature of CUDA kernels, subsequent GPU operations might run on corrupted/incomplete data.
[rank4]:[E ProcessGroupNCCL.cpp:774] To avoid data inconsistency, we are taking the entire process down.
[rank4]:[E ProcessGroupNCCL.cpp:1282] [Rank 4] NCCL watchdog thread terminated with exception: [Rank 4] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=71974, OpType=ALLGATHER, NumelIn=3840000, NumelOut=61440000, Timeout(ms)=1800000) ran for 1800394 milliseconds before timing out.
Exception raised from checkTimeout at /opt/pytorch/pytorch/torch/csrc/distributed/c10d/ProcessGroupNCCL.cpp:756 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x99 (0x7f024a79c8f9 in /usr/local/lib/python3.10/dist-packages/torch/lib/libc10.so)
frame #1: c10d::ProcessGroupNCCL::WorkNCCL::checkTimeout(c10::optional<std::chrono::duration<long, std::ratio<1l, 1000l> > >) + 0x1f2 (0x7f01ec558142 in /usr/local/lib/python3.10/dist-packages/torch/lib/libtorch_cuda.so)
frame #2: c10d::ProcessGroupNCCL::workCleanupLoop() + 0x178 (0x7f01ec55e538 in /usr/local/lib/python3.10/dist-packages/torch/lib/libtorch_cuda.so)
frame #3: c10d::ProcessGroupNCCL::ncclCommWatchdog() + 0x8e (0x7f01ec55eb2e in /usr/local/lib/python3.10/dist-packages/torch/lib/libtorch_cuda.so)
frame #4: <unknown function> + 0xdc253 (0x7f024a2b0253 in /usr/lib/x86_64-linux-gnu/libstdc++.so.6)
frame #5: <unknown function> + 0x94ac3 (0x7f0259997ac3 in /usr/lib/x86_64-linux-gnu/libc.so.6)
frame #6: <unknown function> + 0x126a40 (0x7f0259a29a40 in /usr/lib/x86_64-linux-gnu/libc.so.6)

terminate called after throwing an instance of 'c10::DistBackendError'
  what():  [Rank 4] NCCL watchdog thread terminated with exception: [Rank 4] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=71974, OpType=ALLGATHER, NumelIn=3840000, NumelOut=61440000, Timeout(ms)=1800000) ran for 1800394 milliseconds before timing out.
Exception raised from checkTimeout at /opt/pytorch/pytorch/torch/csrc/distributed/c10d/ProcessGroupNCCL.cpp:756 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x99 (0x7f024a79c8f9 in /usr/local/lib/python3.10/dist-packages/torch/lib/libc10.so)
frame #1: c10d::ProcessGroupNCCL::WorkNCCL::checkTimeout(c10::optional<std::chrono::duration<long, std::ratio<1l, 1000l> > >) + 0x1f2 (0x7f01ec558142 in /usr/local/lib/python3.10/dist-packages/torch/lib/libtorch_cuda.so)
frame #2: c10d::ProcessGroupNCCL::workCleanupLoop() + 0x178 (0x7f01ec55e538 in /usr/local/lib/python3.10/dist-packages/torch/lib/libtorch_cuda.so)
frame #3: c10d::ProcessGroupNCCL::ncclCommWatchdog() + 0x8e (0x7f01ec55eb2e in /usr/local/lib/python3.10/dist-packages/torch/lib/libtorch_cuda.so)
frame #4: <unknown function> + 0xdc253 (0x7f024a2b0253 in /usr/lib/x86_64-linux-gnu/libstdc++.so.6)
frame #5: <unknown function> + 0x94ac3 (0x7f0259997ac3 in /usr/lib/x86_64-linux-gnu/libc.so.6)
frame #6: <unknown function> + 0x126a40 (0x7f0259a29a40 in /usr/lib/x86_64-linux-gnu/libc.so.6)

Exception raised from ncclCommWatchdog at /opt/pytorch/pytorch/torch/csrc/distributed/c10d/ProcessGroupNCCL.cpp:1286 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x99 (0x7f024a79c8f9 in /usr/local/lib/python3.10/dist-packages/torch/lib/libc10.so)
frame #1: <unknown function> + 0xf59d3e (0x7f01ec586d3e in /usr/local/lib/python3.10/dist-packages/torch/lib/libtorch_cuda.so)
frame #2: <unknown function> + 0xc91879 (0x7f01ec2be879 in /usr/local/lib/python3.10/dist-packages/torch/lib/libtorch_cuda.so)
frame #3: <unknown function> + 0xdc253 (0x7f024a2b0253 in /usr/lib/x86_64-linux-gnu/libstdc++.so.6)
frame #4: <unknown function> + 0x94ac3 (0x7f0259997ac3 in /usr/lib/x86_64-linux-gnu/libc.so.6)
frame #5: <unknown function> + 0x126a40 (0x7f0259a29a40 in /usr/lib/x86_64-linux-gnu/libc.so.6)

[rank7]:[E ProcessGroupNCCL.cpp:754] [Rank 7] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=71974, OpType=ALLGATHER, NumelIn=3840000, NumelOut=61440000, Timeout(ms)=1800000) ran for 1800985 milliseconds before timing out.
[rank7]:[E ProcessGroupNCCL.cpp:768] Some NCCL operations have failed or timed out. Due to the asynchronous nature of CUDA kernels, subsequent GPU operations might run on corrupted/incomplete data.
[rank7]:[E ProcessGroupNCCL.cpp:774] To avoid data inconsistency, we are taking the entire process down.
[rank7]:[E ProcessGroupNCCL.cpp:1282] [Rank 7] NCCL watchdog thread terminated with exception: [Rank 7] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=71974, OpType=ALLGATHER, NumelIn=3840000, NumelOut=61440000, Timeout(ms)=1800000) ran for 1800985 milliseconds before timing out.
Exception raised from checkTimeout at /opt/pytorch/pytorch/torch/csrc/distributed/c10d/ProcessGroupNCCL.cpp:756 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x99 (0x7f320ce858f9 in /usr/local/lib/python3.10/dist-packages/torch/lib/libc10.so)
frame #1: c10d::ProcessGroupNCCL::WorkNCCL::checkTimeout(c10::optional<std::chrono::duration<long, std::ratio<1l, 1000l> > >) + 0x1f2 (0x7f31aed58142 in /usr/local/lib/python3.10/dist-packages/torch/lib/libtorch_cuda.so)
frame #2: c10d::ProcessGroupNCCL::workCleanupLoop() + 0x178 (0x7f31aed5e538 in /usr/local/lib/python3.10/dist-packages/torch/lib/libtorch_cuda.so)
frame #3: c10d::ProcessGroupNCCL::ncclCommWatchdog() + 0x8e (0x7f31aed5eb2e in /usr/local/lib/python3.10/dist-packages/torch/lib/libtorch_cuda.so)
frame #4: <unknown function> + 0xdc253 (0x7f320cab0253 in /usr/lib/x86_64-linux-gnu/libstdc++.so.6)
frame #5: <unknown function> + 0x94ac3 (0x7f321c021ac3 in /usr/lib/x86_64-linux-gnu/libc.so.6)
frame #6: <unknown function> + 0x126a40 (0x7f321c0b3a40 in /usr/lib/x86_64-linux-gnu/libc.so.6)

terminate called after throwing an instance of 'c10::DistBackendError'
  what():  [Rank 7] NCCL watchdog thread terminated with exception: [Rank 7] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=71974, OpType=ALLGATHER, NumelIn=3840000, NumelOut=61440000, Timeout(ms)=1800000) ran for 1800985 milliseconds before timing out.
Exception raised from checkTimeout at /opt/pytorch/pytorch/torch/csrc/distributed/c10d/ProcessGroupNCCL.cpp:756 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x99 (0x7f320ce858f9 in /usr/local/lib/python3.10/dist-packages/torch/lib/libc10.so)
frame #1: c10d::ProcessGroupNCCL::WorkNCCL::checkTimeout(c10::optional<std::chrono::duration<long, std::ratio<1l, 1000l> > >) + 0x1f2 (0x7f31aed58142 in /usr/local/lib/python3.10/dist-packages/torch/lib/libtorch_cuda.so)
frame #2: c10d::ProcessGroupNCCL::workCleanupLoop() + 0x178 (0x7f31aed5e538 in /usr/local/lib/python3.10/dist-packages/torch/lib/libtorch_cuda.so)
frame #3: c10d::ProcessGroupNCCL::ncclCommWatchdog() + 0x8e (0x7f31aed5eb2e in /usr/local/lib/python3.10/dist-packages/torch/lib/libtorch_cuda.so)
frame #4: <unknown function> + 0xdc253 (0x7f320cab0253 in /usr/lib/x86_64-linux-gnu/libstdc++.so.6)
frame #5: <unknown function> + 0x94ac3 (0x7f321c021ac3 in /usr/lib/x86_64-linux-gnu/libc.so.6)
frame #6: <unknown function> + 0x126a40 (0x7f321c0b3a40 in /usr/lib/x86_64-linux-gnu/libc.so.6)

Exception raised from ncclCommWatchdog at /opt/pytorch/pytorch/torch/csrc/distributed/c10d/ProcessGroupNCCL.cpp:1286 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x99 (0x7f320ce858f9 in /usr/local/lib/python3.10/dist-packages/torch/lib/libc10.so)
frame #1: <unknown function> + 0xf59d3e (0x7f31aed86d3e in /usr/local/lib/python3.10/dist-packages/torch/lib/libtorch_cuda.so)
frame #2: <unknown function> + 0xc91879 (0x7f31aeabe879 in /usr/local/lib/python3.10/dist-packages/torch/lib/libtorch_cuda.so)
frame #3: <unknown function> + 0xdc253 (0x7f320cab0253 in /usr/lib/x86_64-linux-gnu/libstdc++.so.6)
frame #4: <unknown function> + 0x94ac3 (0x7f321c021ac3 in /usr/lib/x86_64-linux-gnu/libc.so.6)
frame #5: <unknown function> + 0x126a40 (0x7f321c0b3a40 in /usr/lib/x86_64-linux-gnu/libc.so.6)

[rank9]:[E ProcessGroupNCCL.cpp:754] [Rank 9] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=71974, OpType=ALLGATHER, NumelIn=3840000, NumelOut=61440000, Timeout(ms)=1800000) ran for 1800561 milliseconds before timing out.
[rank9]:[E ProcessGroupNCCL.cpp:768] Some NCCL operations have failed or timed out. Due to the asynchronous nature of CUDA kernels, subsequent GPU operations might run on corrupted/incomplete data.
[rank9]:[E ProcessGroupNCCL.cpp:774] To avoid data inconsistency, we are taking the entire process down.
[rank9]:[E ProcessGroupNCCL.cpp:1282] [Rank 9] NCCL watchdog thread terminated with exception: [Rank 9] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=71974, OpType=ALLGATHER, NumelIn=3840000, NumelOut=61440000, Timeout(ms)=1800000) ran for 1800561 milliseconds before timing out.
Exception raised from checkTimeout at /opt/pytorch/pytorch/torch/csrc/distributed/c10d/ProcessGroupNCCL.cpp:756 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x99 (0x7fd2194858f9 in /usr/local/lib/python3.10/dist-packages/torch/lib/libc10.so)
frame #1: c10d::ProcessGroupNCCL::WorkNCCL::checkTimeout(c10::optional<std::chrono::duration<long, std::ratio<1l, 1000l> > >) + 0x1f2 (0x7fd1bb358142 in /usr/local/lib/python3.10/dist-packages/torch/lib/libtorch_cuda.so)
frame #2: c10d::ProcessGroupNCCL::workCleanupLoop() + 0x178 (0x7fd1bb35e538 in /usr/local/lib/python3.10/dist-packages/torch/lib/libtorch_cuda.so)
frame #3: c10d::ProcessGroupNCCL::ncclCommWatchdog() + 0x8e (0x7fd1bb35eb2e in /usr/local/lib/python3.10/dist-packages/torch/lib/libtorch_cuda.so)
frame #4: <unknown function> + 0xdc253 (0x7fd2190b0253 in /usr/lib/x86_64-linux-gnu/libstdc++.so.6)
frame #5: <unknown function> + 0x94ac3 (0x7fd22861dac3 in /usr/lib/x86_64-linux-gnu/libc.so.6)
frame #6: <unknown function> + 0x126a40 (0x7fd2286afa40 in /usr/lib/x86_64-linux-gnu/libc.so.6)

terminate called after throwing an instance of 'c10::DistBackendError'
  what():  [Rank 9] NCCL watchdog thread terminated with exception: [Rank 9] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=71974, OpType=ALLGATHER, NumelIn=3840000, NumelOut=61440000, Timeout(ms)=1800000) ran for 1800561 milliseconds before timing out.
Exception raised from checkTimeout at /opt/pytorch/pytorch/torch/csrc/distributed/c10d/ProcessGroupNCCL.cpp:756 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x99 (0x7fd2194858f9 in /usr/local/lib/python3.10/dist-packages/torch/lib/libc10.so)
frame #1: c10d::ProcessGroupNCCL::WorkNCCL::checkTimeout(c10::optional<std::chrono::duration<long, std::ratio<1l, 1000l> > >) + 0x1f2 (0x7fd1bb358142 in /usr/local/lib/python3.10/dist-packages/torch/lib/libtorch_cuda.so)
frame #2: c10d::ProcessGroupNCCL::workCleanupLoop() + 0x178 (0x7fd1bb35e538 in /usr/local/lib/python3.10/dist-packages/torch/lib/libtorch_cuda.so)
frame #3: c10d::ProcessGroupNCCL::ncclCommWatchdog() + 0x8e (0x7fd1bb35eb2e in /usr/local/lib/python3.10/dist-packages/torch/lib/libtorch_cuda.so)
frame #4: <unknown function> + 0xdc253 (0x7fd2190b0253 in /usr/lib/x86_64-linux-gnu/libstdc++.so.6)
frame #5: <unknown function> + 0x94ac3 (0x7fd22861dac3 in /usr/lib/x86_64-linux-gnu/libc.so.6)
frame #6: <unknown function> + 0x126a40 (0x7fd2286afa40 in /usr/lib/x86_64-linux-gnu/libc.so.6)

Exception raised from ncclCommWatchdog at /opt/pytorch/pytorch/torch/csrc/distributed/c10d/ProcessGroupNCCL.cpp:1286 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x99 (0x7fd2194858f9 in /usr/local/lib/python3.10/dist-packages/torch/lib/libc10.so)
frame #1: <unknown function> + 0xf59d3e (0x7fd1bb386d3e in /usr/local/lib/python3.10/dist-packages/torch/lib/libtorch_cuda.so)
frame #2: <unknown function> + 0xc91879 (0x7fd1bb0be879 in /usr/local/lib/python3.10/dist-packages/torch/lib/libtorch_cuda.so)
frame #3: <unknown function> + 0xdc253 (0x7fd2190b0253 in /usr/lib/x86_64-linux-gnu/libstdc++.so.6)
frame #4: <unknown function> + 0x94ac3 (0x7fd22861dac3 in /usr/lib/x86_64-linux-gnu/libc.so.6)
frame #5: <unknown function> + 0x126a40 (0x7fd2286afa40 in /usr/lib/x86_64-linux-gnu/libc.so.6)

[rank1]:[E ProcessGroupNCCL.cpp:754] [Rank 1] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=71974, OpType=ALLGATHER, NumelIn=3840000, NumelOut=61440000, Timeout(ms)=1800000) ran for 1800130 milliseconds before timing out.
[rank1]:[E ProcessGroupNCCL.cpp:768] Some NCCL operations have failed or timed out. Due to the asynchronous nature of CUDA kernels, subsequent GPU operations might run on corrupted/incomplete data.
[rank1]:[E ProcessGroupNCCL.cpp:774] To avoid data inconsistency, we are taking the entire process down.
[rank1]:[E ProcessGroupNCCL.cpp:1282] [Rank 1] NCCL watchdog thread terminated with exception: [Rank 1] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=71974, OpType=ALLGATHER, NumelIn=3840000, NumelOut=61440000, Timeout(ms)=1800000) ran for 1800130 milliseconds before timing out.
Exception raised from checkTimeout at /opt/pytorch/pytorch/torch/csrc/distributed/c10d/ProcessGroupNCCL.cpp:756 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x99 (0x7f6685e858f9 in /usr/local/lib/python3.10/dist-packages/torch/lib/libc10.so)
frame #1: c10d::ProcessGroupNCCL::WorkNCCL::checkTimeout(c10::optional<std::chrono::duration<long, std::ratio<1l, 1000l> > >) + 0x1f2 (0x7f6627d58142 in /usr/local/lib/python3.10/dist-packages/torch/lib/libtorch_cuda.so)
frame #2: c10d::ProcessGroupNCCL::workCleanupLoop() + 0x178 (0x7f6627d5e538 in /usr/local/lib/python3.10/dist-packages/torch/lib/libtorch_cuda.so)
frame #3: c10d::ProcessGroupNCCL::ncclCommWatchdog() + 0x8e (0x7f6627d5eb2e in /usr/local/lib/python3.10/dist-packages/torch/lib/libtorch_cuda.so)
frame #4: <unknown function> + 0xdc253 (0x7f6685ab0253 in /usr/lib/x86_64-linux-gnu/libstdc++.so.6)
frame #5: <unknown function> + 0x94ac3 (0x7f669500eac3 in /usr/lib/x86_64-linux-gnu/libc.so.6)
frame #6: <unknown function> + 0x126a40 (0x7f66950a0a40 in /usr/lib/x86_64-linux-gnu/libc.so.6)

terminate called after throwing an instance of 'c10::DistBackendError'
  what():  [Rank 1] NCCL watchdog thread terminated with exception: [Rank 1] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=71974, OpType=ALLGATHER, NumelIn=3840000, NumelOut=61440000, Timeout(ms)=1800000) ran for 1800130 milliseconds before timing out.
Exception raised from checkTimeout at /opt/pytorch/pytorch/torch/csrc/distributed/c10d/ProcessGroupNCCL.cpp:756 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x99 (0x7f6685e858f9 in /usr/local/lib/python3.10/dist-packages/torch/lib/libc10.so)
frame #1: c10d::ProcessGroupNCCL::WorkNCCL::checkTimeout(c10::optional<std::chrono::duration<long, std::ratio<1l, 1000l> > >) + 0x1f2 (0x7f6627d58142 in /usr/local/lib/python3.10/dist-packages/torch/lib/libtorch_cuda.so)
frame #2: c10d::ProcessGroupNCCL::workCleanupLoop() + 0x178 (0x7f6627d5e538 in /usr/local/lib/python3.10/dist-packages/torch/lib/libtorch_cuda.so)
frame #3: c10d::ProcessGroupNCCL::ncclCommWatchdog() + 0x8e (0x7f6627d5eb2e in /usr/local/lib/python3.10/dist-packages/torch/lib/libtorch_cuda.so)
frame #4: <unknown function> + 0xdc253 (0x7f6685ab0253 in /usr/lib/x86_64-linux-gnu/libstdc++.so.6)
frame #5: <unknown function> + 0x94ac3 (0x7f669500eac3 in /usr/lib/x86_64-linux-gnu/libc.so.6)
frame #6: <unknown function> + 0x126a40 (0x7f66950a0a40 in /usr/lib/x86_64-linux-gnu/libc.so.6)

Exception raised from ncclCommWatchdog at /opt/pytorch/pytorch/torch/csrc/distributed/c10d/ProcessGroupNCCL.cpp:1286 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x99 (0x7f6685e858f9 in /usr/local/lib/python3.10/dist-packages/torch/lib/libc10.so)
frame #1: <unknown function> + 0xf59d3e (0x7f6627d86d3e in /usr/local/lib/python3.10/dist-packages/torch/lib/libtorch_cuda.so)
frame #2: <unknown function> + 0xc91879 (0x7f6627abe879 in /usr/local/lib/python3.10/dist-packages/torch/lib/libtorch_cuda.so)
frame #3: <unknown function> + 0xdc253 (0x7f6685ab0253 in /usr/lib/x86_64-linux-gnu/libstdc++.so.6)
frame #4: <unknown function> + 0x94ac3 (0x7f669500eac3 in /usr/lib/x86_64-linux-gnu/libc.so.6)
frame #5: <unknown function> + 0x126a40 (0x7f66950a0a40 in /usr/lib/x86_64-linux-gnu/libc.so.6)

[rank6]:[E ProcessGroupNCCL.cpp:754] [Rank 6] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=71974, OpType=ALLGATHER, NumelIn=3840000, NumelOut=61440000, Timeout(ms)=1800000) ran for 1800438 milliseconds before timing out.
[rank6]:[E ProcessGroupNCCL.cpp:768] Some NCCL operations have failed or timed out. Due to the asynchronous nature of CUDA kernels, subsequent GPU operations might run on corrupted/incomplete data.
[rank6]:[E ProcessGroupNCCL.cpp:774] To avoid data inconsistency, we are taking the entire process down.
[rank6]:[E ProcessGroupNCCL.cpp:1282] [Rank 6] NCCL watchdog thread terminated with exception: [Rank 6] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=71974, OpType=ALLGATHER, NumelIn=3840000, NumelOut=61440000, Timeout(ms)=1800000) ran for 1800438 milliseconds before timing out.
Exception raised from checkTimeout at /opt/pytorch/pytorch/torch/csrc/distributed/c10d/ProcessGroupNCCL.cpp:756 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x99 (0x7f02ed59c8f9 in /usr/local/lib/python3.10/dist-packages/torch/lib/libc10.so)
frame #1: c10d::ProcessGroupNCCL::WorkNCCL::checkTimeout(c10::optional<std::chrono::duration<long, std::ratio<1l, 1000l> > >) + 0x1f2 (0x7f028f358142 in /usr/local/lib/python3.10/dist-packages/torch/lib/libtorch_cuda.so)
frame #2: c10d::ProcessGroupNCCL::workCleanupLoop() + 0x178 (0x7f028f35e538 in /usr/local/lib/python3.10/dist-packages/torch/lib/libtorch_cuda.so)
frame #3: c10d::ProcessGroupNCCL::ncclCommWatchdog() + 0x8e (0x7f028f35eb2e in /usr/local/lib/python3.10/dist-packages/torch/lib/libtorch_cuda.so)
frame #4: <unknown function> + 0xdc253 (0x7f02ed0b0253 in /usr/lib/x86_64-linux-gnu/libstdc++.so.6)
frame #5: <unknown function> + 0x94ac3 (0x7f02fc7a9ac3 in /usr/lib/x86_64-linux-gnu/libc.so.6)
frame #6: <unknown function> + 0x126a40 (0x7f02fc83ba40 in /usr/lib/x86_64-linux-gnu/libc.so.6)

terminate called after throwing an instance of 'c10::DistBackendError'
  what():  [Rank 6] NCCL watchdog thread terminated with exception: [Rank 6] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=71974, OpType=ALLGATHER, NumelIn=3840000, NumelOut=61440000, Timeout(ms)=1800000) ran for 1800438 milliseconds before timing out.
Exception raised from checkTimeout at /opt/pytorch/pytorch/torch/csrc/distributed/c10d/ProcessGroupNCCL.cpp:756 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x99 (0x7f02ed59c8f9 in /usr/local/lib/python3.10/dist-packages/torch/lib/libc10.so)
frame #1: c10d::ProcessGroupNCCL::WorkNCCL::checkTimeout(c10::optional<std::chrono::duration<long, std::ratio<1l, 1000l> > >) + 0x1f2 (0x7f028f358142 in /usr/local/lib/python3.10/dist-packages/torch/lib/libtorch_cuda.so)
frame #2: c10d::ProcessGroupNCCL::workCleanupLoop() + 0x178 (0x7f028f35e538 in /usr/local/lib/python3.10/dist-packages/torch/lib/libtorch_cuda.so)
frame #3: c10d::ProcessGroupNCCL::ncclCommWatchdog() + 0x8e (0x7f028f35eb2e in /usr/local/lib/python3.10/dist-packages/torch/lib/libtorch_cuda.so)
frame #4: <unknown function> + 0xdc253 (0x7f02ed0b0253 in /usr/lib/x86_64-linux-gnu/libstdc++.so.6)
frame #5: <unknown function> + 0x94ac3 (0x7f02fc7a9ac3 in /usr/lib/x86_64-linux-gnu/libc.so.6)
frame #6: <unknown function> + 0x126a40 (0x7f02fc83ba40 in /usr/lib/x86_64-linux-gnu/libc.so.6)

Exception raised from ncclCommWatchdog at /opt/pytorch/pytorch/torch/csrc/distributed/c10d/ProcessGroupNCCL.cpp:1286 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x99 (0x7f02ed59c8f9 in /usr/local/lib/python3.10/dist-packages/torch/lib/libc10.so)
frame #1: <unknown function> + 0xf59d3e (0x7f028f386d3e in /usr/local/lib/python3.10/dist-packages/torch/lib/libtorch_cuda.so)
frame #2: <unknown function> + 0xc91879 (0x7f028f0be879 in /usr/local/lib/python3.10/dist-packages/torch/lib/libtorch_cuda.so)
frame #3: <unknown function> + 0xdc253 (0x7f02ed0b0253 in /usr/lib/x86_64-linux-gnu/libstdc++.so.6)
frame #4: <unknown function> + 0x94ac3 (0x7f02fc7a9ac3 in /usr/lib/x86_64-linux-gnu/libc.so.6)
frame #5: <unknown function> + 0x126a40 (0x7f02fc83ba40 in /usr/lib/x86_64-linux-gnu/libc.so.6)

[rank13]:[E ProcessGroupNCCL.cpp:754] [Rank 13] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=71974, OpType=ALLGATHER, NumelIn=3840000, NumelOut=61440000, Timeout(ms)=1800000) ran for 1800446 milliseconds before timing out.
[rank13]:[E ProcessGroupNCCL.cpp:768] Some NCCL operations have failed or timed out. Due to the asynchronous nature of CUDA kernels, subsequent GPU operations might run on corrupted/incomplete data.
[rank13]:[E ProcessGroupNCCL.cpp:774] To avoid data inconsistency, we are taking the entire process down.
[rank13]:[E ProcessGroupNCCL.cpp:1282] [Rank 13] NCCL watchdog thread terminated with exception: [Rank 13] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=71974, OpType=ALLGATHER, NumelIn=3840000, NumelOut=61440000, Timeout(ms)=1800000) ran for 1800446 milliseconds before timing out.
Exception raised from checkTimeout at /opt/pytorch/pytorch/torch/csrc/distributed/c10d/ProcessGroupNCCL.cpp:756 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x99 (0x7f68fbc858f9 in /usr/local/lib/python3.10/dist-packages/torch/lib/libc10.so)
frame #1: c10d::ProcessGroupNCCL::WorkNCCL::checkTimeout(c10::optional<std::chrono::duration<long, std::ratio<1l, 1000l> > >) + 0x1f2 (0x7f689db58142 in /usr/local/lib/python3.10/dist-packages/torch/lib/libtorch_cuda.so)
frame #2: c10d::ProcessGroupNCCL::workCleanupLoop() + 0x178 (0x7f689db5e538 in /usr/local/lib/python3.10/dist-packages/torch/lib/libtorch_cuda.so)
frame #3: c10d::ProcessGroupNCCL::ncclCommWatchdog() + 0x8e (0x7f689db5eb2e in /usr/local/lib/python3.10/dist-packages/torch/lib/libtorch_cuda.so)
frame #4: <unknown function> + 0xdc253 (0x7f68fb8b0253 in /usr/lib/x86_64-linux-gnu/libstdc++.so.6)
frame #5: <unknown function> + 0x94ac3 (0x7f690ae24ac3 in /usr/lib/x86_64-linux-gnu/libc.so.6)
frame #6: <unknown function> + 0x126a40 (0x7f690aeb6a40 in /usr/lib/x86_64-linux-gnu/libc.so.6)

terminate called after throwing an instance of 'c10::DistBackendError'
  what():  [Rank 13] NCCL watchdog thread terminated with exception: [Rank 13] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=71974, OpType=ALLGATHER, NumelIn=3840000, NumelOut=61440000, Timeout(ms)=1800000) ran for 1800446 milliseconds before timing out.
Exception raised from checkTimeout at /opt/pytorch/pytorch/torch/csrc/distributed/c10d/ProcessGroupNCCL.cpp:756 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x99 (0x7f68fbc858f9 in /usr/local/lib/python3.10/dist-packages/torch/lib/libc10.so)
frame #1: c10d::ProcessGroupNCCL::WorkNCCL::checkTimeout(c10::optional<std::chrono::duration<long, std::ratio<1l, 1000l> > >) + 0x1f2 (0x7f689db58142 in /usr/local/lib/python3.10/dist-packages/torch/lib/libtorch_cuda.so)
frame #2: c10d::ProcessGroupNCCL::workCleanupLoop() + 0x178 (0x7f689db5e538 in /usr/local/lib/python3.10/dist-packages/torch/lib/libtorch_cuda.so)
frame #3: c10d::ProcessGroupNCCL::ncclCommWatchdog() + 0x8e (0x7f689db5eb2e in /usr/local/lib/python3.10/dist-packages/torch/lib/libtorch_cuda.so)
frame #4: <unknown function> + 0xdc253 (0x7f68fb8b0253 in /usr/lib/x86_64-linux-gnu/libstdc++.so.6)
frame #5: <unknown function> + 0x94ac3 (0x7f690ae24ac3 in /usr/lib/x86_64-linux-gnu/libc.so.6)
frame #6: <unknown function> + 0x126a40 (0x7f690aeb6a40 in /usr/lib/x86_64-linux-gnu/libc.so.6)

Exception raised from ncclCommWatchdog at /opt/pytorch/pytorch/torch/csrc/distributed/c10d/ProcessGroupNCCL.cpp:1286 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x99 (0x7f68fbc858f9 in /usr/local/lib/python3.10/dist-packages/torch/lib/libc10.so)
frame #1: <unknown function> + 0xf59d3e (0x7f689db86d3e in /usr/local/lib/python3.10/dist-packages/torch/lib/libtorch_cuda.so)
frame #2: <unknown function> + 0xc91879 (0x7f689d8be879 in /usr/local/lib/python3.10/dist-packages/torch/lib/libtorch_cuda.so)
frame #3: <unknown function> + 0xdc253 (0x7f68fb8b0253 in /usr/lib/x86_64-linux-gnu/libstdc++.so.6)
frame #4: <unknown function> + 0x94ac3 (0x7f690ae24ac3 in /usr/lib/x86_64-linux-gnu/libc.so.6)
frame #5: <unknown function> + 0x126a40 (0x7f690aeb6a40 in /usr/lib/x86_64-linux-gnu/libc.so.6)

./run_and_time.sh: line 53:  5752 Aborted                 (core dumped) python main.py lightning.trainer.num_nodes=${NUM_NODES} lightning.trainer.devices=${GPUS_PER_NODE} -m train --ckpt ${CHECKPOINT} --logdir ${RESULTS_DIR} -b ${CONFIG}
srun: error: worker-0: task 11: Exited with exit code 134
srun: Job step aborted: Waiting up to 32 seconds for job step to finish.
srun: got SIGCONT
slurmstepd: error: *** STEP 839.0 ON worker-1 CANCELLED AT 2024-06-15T23:37:08 ***
slurmstepd: error: *** JOB 839 ON worker-1 CANCELLED AT 2024-06-15T23:37:08 ***
srun: forcing job termination
srun: error: Timed out waiting for job step to complete
