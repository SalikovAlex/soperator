# Usage of quote-wrapping for string literals in this example acts like a visual mark for referring to other resources
# like user-created PVCs or 3rd-party annotations

apiVersion: slurm.nebius.ai/v1
kind: SlurmCluster
metadata:
  namespace: dstaroff
  name: slurm1
spec:
  crVersion: 0.1.15
  pause: false
  populateJail:
    image: cr.nemax.nebius.cloud/crnbu823dealq64cp1s6/populate_jail:0.1.15
    k8sNodeFilterName: "gpu"
  ncclSettings:
    topologyType: "auto"
  periodicChecks:
    ncclBenchmark:
      enabled: true
      schedule: "0 */3 * * *" # Run every 3 hours
      activeDeadlineSeconds: 1800 # k8s CronJob timeout seconds (30 min)
      successfulJobsHistoryLimit: 3
      failedJobsHistoryLimit: 3
      image: cr.nemax.nebius.cloud/crnbu823dealq64cp1s6/nccl_benchmark:0.1.15
      periodicCheckNCCLSettings:
        minBytes: "512Kb"
        maxBytes: "512Mb"
        stepFactor: "2"
        timeout: "20:00" # 20 minutes
        thresholdMoreThan: "0"
        useInfiniband: true
      failureActions:
        #setK8SNodeStatus: "GpuSlow"
        setSlurmNodeDrainState: false
      k8sNodeFilterName: "no-gpu"
  k8sNodeFilters:
    - name: gpu
      affinity:
        nodeAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
            nodeSelectorTerms:
              - matchExpressions:
                  - key: "nebius.com/node-group-id"
                    operator: In
                    values:
                      - "f2mek81b68gi5k66dsfg"
      tolerations:
        - key: nvidia.com/gpu
          operator: Exists
          effect: NoSchedule
    - name: no-gpu
      affinity:
        nodeAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
            nodeSelectorTerms:
              - matchExpressions:
                  - key: "nebius.com/node-group-id"
                    operator: In
                    values:
                      - "f2md1q6j5mq7mju9agk2"
  volumeSources:
    - name: controller-spool
      persistentVolumeClaim:
        claimName: "controller-spool"
        readOnly: false
    - name: jail
      persistentVolumeClaim:
        claimName: "jail"
        readOnly: false
        #- name: datasets
        #  persistentVolumeClaim:
        #    claimName: slurm-example-customer-datasets
        #    readOnly: false
        #- name: checkpoints
        #  persistentVolumeClaim:
        #    claimName: slurm-example-customer-checkpoints
        #    readOnly: false
        #- name: ml-config
        #  configMap:
        #    name: slurm-example-customer-ml-configs
  secrets:
    mungeKey:
      name: "munge-key"
      key: "munge.key"
  slurmNodes:
    controller:
      size: 1
      k8sNodeFilterName: "no-gpu"
      slurmctld:
        image: "cr.nemax.nebius.cloud/crnbu823dealq64cp1s6/controller_slurmctld:0.1.15"
        port: 6817
        resources:
          cpu: 1000m
          memory: 10Gi
          ephemeral-storage: 10Gi
      munge:
        image: "cr.nemax.nebius.cloud/crnbu823dealq64cp1s6/munge:0.1.15"
        resources:
          cpu: 1000m
          memory: 1Gi
          ephemeral-storage: 5Gi
      volumes:
        spool:
          volumeSourceName: "controller-spool"
        jail:
          volumeSourceName: "jail"
    worker:
      size: 1
      k8sNodeFilterName: "gpu"
      slurmd:
        image: "cr.nemax.nebius.cloud/crnbu823dealq64cp1s6/worker_slurmd:0.1.15"
        port: 6818
        resources:
          cpu: 1000m
          memory: 10Gi
          ephemeral-storage: 10Gi
          nvidia.com/gpu: 2
      munge:
        image: "cr.nemax.nebius.cloud/crnbu823dealq64cp1s6/munge:0.1.15"
      volumes:
        spool:
          volumeClaimTemplateSpec:
            storageClassName: "nebius-network-ssd"
            accessModes: ["ReadWriteOnce"]
            resources:
              requests:
                storage: 50Gi
        jail:
          volumeSourceName: "jail"
        jailSubMounts: []
        #- name: datasets
        #  mountPath: "/mnt/datasets"
        #  volumeSourceName: "datasets"
        #- name: checkpoints
        #  mountPath: "/mnt/checkpoints"
        #  volumeSourceName: "checkpoints"
        #- name: ml-configs
        #  mountPath: "/etc/ml-config"
        #  volumeSourceName: "ml-configs"
    login:
      size: 1
      k8sNodeFilterName: "no-gpu"
      sshd:
        image: "cr.nemax.nebius.cloud/crnbu823dealq64cp1s6/login_sshd:0.1.15"
        port: 22
        resources:
          cpu: 1000m
          memory: 1Gi
          ephemeral-storage: 1Gi
      sshRootPublicKeys:
        - "ssh-ed25519 AAAAC3NzaC1lZDI1NTE5AAAAIKzxkjzPQ4EyZSjan4MLGFSA18idpZicoKW7HC4YmwgN rdjjke@gmail.com"
        - "ssh-ed25519 AAAAC3NzaC1lZDI1NTE5AAAAICL8scMKnwu+Y9S6XDACacZ54+qu+YRo2y4IeXSPjTuo pavel@sofrony.ru"
      sshdServiceType: "LoadBalancer"
      munge:
        image: "cr.nemax.nebius.cloud/crnbu823dealq64cp1s6/munge:0.1.15"
      volumes:
        jail:
          volumeSourceName: "jail"
        jailSubMounts: []
        #- name: "datasets"
        #  mountPath: "/mnt/datasets"
        #  volumeSourceName: "datasets"
        #- name: "checkpoints"
        #  mountPath: "/mnt/checkpoints"
        #  volumeSourceName: "checkpoints"
        #- name: "ml-configs"
        #  mountPath: "/etc/ml-config"
        #  volumeSourceName: "ml-configs"
